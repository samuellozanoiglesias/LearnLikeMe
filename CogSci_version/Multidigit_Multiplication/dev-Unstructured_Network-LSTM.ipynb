{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711e908c-a200-4499-a72c-e7d32a573bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytz\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479ae9ba-7455-4e6e-86a4-b87a5dd1df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network parameters\n",
    "def initialize_random_weights(mean, std, shape = ()):\n",
    "    return np.random.normal(loc=mean, scale=std, size=shape)\n",
    "        \n",
    "# Function to generate dataset with multiplication\n",
    "def generate_dataset_with_zeros(size, n_max=10):\n",
    "    # Generate two columns of random numbers between 0 and 9\n",
    "    column_1 = np.random.randint(0, n_max, size)\n",
    "    column_2 = np.random.randint(0, n_max, size)\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_without_zeros(size, n_max=10):\n",
    "    # Generate two columns of random numbers between 1 and 9\n",
    "    column_1 = np.random.randint(1, n_max, size)\n",
    "    column_2 = np.random.randint(1, n_max, size)\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_test_dataset(n_max=10):\n",
    "    # Create the columns\n",
    "    column_1 = list(range(n_max)) * n_max  # Numbers from 0 to 9 repeated 10 times\n",
    "    column_2 = [i for i in range(n_max) for _ in range(n_max)]  # Numbers from 0 to 9 repeated sequentially 10 times\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def decimal_to_binary(n, bits):\n",
    "    if 0 <= n < 2**bits:\n",
    "        # Convert the number to a binary string and then to an array of integers (0 and 1)\n",
    "        return np.array(list(format(n, f'0{bits}b'))).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(\"Number out of range\")\n",
    "\n",
    "# Function to convert binary number to decimal\n",
    "def binary_to_decimal(binary_vector, bits):\n",
    "    # Ensure the vector has the correct number of elements\n",
    "    if len(binary_vector) != bits:\n",
    "        raise ValueError(f\"The vector must have exactly {bits} elements.\")\n",
    "\n",
    "    # Calculate the decimal number\n",
    "    decimal = 0\n",
    "    for i in range(bits):\n",
    "        decimal += binary_vector[i] * (2 ** (bits - 1 - i))\n",
    "\n",
    "    return decimal\n",
    "\n",
    "def transform_to_tridimensional_matrix(dataset, bits_init=4, bits_end=7):\n",
    "    rows, cols = dataset.shape\n",
    "    if cols != 3:\n",
    "        raise ValueError(\"The dataset must have exactly 3 columns.\")\n",
    "\n",
    "    # Initialize the three matrices\n",
    "    matrix_column_1 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_2 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_3 = np.zeros((rows, bits_end), dtype=np.int8)\n",
    "\n",
    "    # Fill the matrices with the binary representation of each column\n",
    "    for i in range(rows):\n",
    "        matrix_column_1[i] = decimal_to_binary(dataset.iloc[i, 0], bits_init)\n",
    "        matrix_column_2[i] = decimal_to_binary(dataset.iloc[i, 1], bits_init)\n",
    "        matrix_column_3[i] = decimal_to_binary(dataset.iloc[i, 2], bits_end)\n",
    "\n",
    "    return matrix_column_1, matrix_column_2, matrix_column_3\n",
    "    \n",
    "def prepare_dataset(level, size=1, couples_included=[]): \n",
    "    if level == -3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = couples_included\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == -2:\n",
    "        dataset = generate_dataset_with_zeros(size)\n",
    "        return dataset\n",
    "        \n",
    "    elif level == -1:\n",
    "        dataset = generate_dataset_without_zeros(size)\n",
    "        return dataset\n",
    "\n",
    "    elif level == 0:\n",
    "        couples_not_included = [(3, 3), (5, 5), (6, 6), (7, 7), (9, 9), (3, 6), (3, 7), (6, 3), (7, 3), (5, 7), (7, 5), (6, 7), (7, 6)]\n",
    "        dataset = pd.DataFrame()\n",
    "        while len(dataset) < size:\n",
    "            column_1 = np.random.randint(1, 10, size)\n",
    "            column_2 = np.random.randint(1, 10, size)\n",
    "            temp_dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "            temp_dataset = temp_dataset[~temp_dataset[['Column_1', 'Column_2']].apply(tuple, axis=1).isin(couples_not_included)]\n",
    "            dataset = pd.concat([dataset, temp_dataset])\n",
    "        dataset = dataset.iloc[:size].reset_index(drop=True)\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 1:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = [(5, 5), (9, 9)]\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 2:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = [(3, 3), (6, 6), (3, 6), (6, 3), (5, 7), (7, 5)]\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = [(3, 7), (6, 7), (7, 3), (7, 6)]\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 4:\n",
    "        column_1 = [7] * size\n",
    "        column_2 = [7] * size\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 5:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = [(3, 3), (5, 5), (6, 6), (7, 7), (9, 9), (3, 6), (3, 7), (6, 3), (7, 3), (5, 7), (7, 5), (6, 7), (7, 6)]\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8f25046-e24b-4c0e-bf25-b69cf35d6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(model, level, epochs=10, steps_per_epoch=100, batch_size=100):\n",
    "    decimal_dataset_train = prepare_dataset(level, size=steps_per_epoch*batch_size)\n",
    "    x_train_1, x_train_2, y_train = transform_to_tridimensional_matrix(decimal_dataset_train)\n",
    "    x_train = np.concatenate([x_train_1, x_train_2], axis=1)\n",
    "    \n",
    "    decimal_dataset_test = generate_test_dataset(n_max=11)\n",
    "    x_val_1, x_val_2, y_val = transform_to_tridimensional_matrix(decimal_dataset_test)\n",
    "    x_val = np.concatenate([x_val_1, x_val_2], axis=1)\n",
    "    \n",
    "    x_train = np.expand_dims(x_train, axis=1)\n",
    "    x_val = np.expand_dims(x_val, axis=1)\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    x_val = x_val.astype(np.float32)\n",
    "    y_val = y_val.astype(np.float32)\n",
    "    validation_data = (x_val, y_val)\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_data,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87f9592e-6443-49e6-935b-d8cce89ae252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_neural_network(model, visualize_errors = 0, real_test = 0):\n",
    "    if real_test == 0:\n",
    "        carryover_list = [(3, 3), (5, 5), (6, 6), (7, 7), (9, 9), (3, 6), (3, 7), (6, 3), (7, 3), (5, 7), (7, 5), (6, 7), (7, 6)]\n",
    "        decimal_dataset = generate_test_dataset()\n",
    "    elif real_test == 1:\n",
    "        carryover_list = [(3, 3), (5, 5), (6, 6), (7, 7), (9, 9), (3, 6), (3, 7), (6, 3), (7, 3), (5, 7), (7, 5), (6, 7), (7, 6),\n",
    "                             (5, 10), (10, 5), (7, 10), (10, 7), (10, 10), (10, 11), (11, 10), (3, 11), (11, 3), (5, 11), (11, 5),\n",
    "                             (6, 11), (11, 6), (7, 11), (11, 7), (9, 11), (11, 9), (11, 11)]\n",
    "        decimal_dataset = generate_test_dataset(n_max=12)\n",
    "\n",
    "    x_test_1, x_test_2, y_train = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    x_test = np.concatenate([x_test_1, x_test_2], axis=1)\n",
    "    x_test = np.expand_dims(x_test, axis=1)\n",
    "    predictions = trainable_model.predict(x_test)\n",
    "    rounded_predictions = np.round(predictions).astype(int)\n",
    "\n",
    "    correct_predictions_count = 0\n",
    "    carryover_mistakes = 0  \n",
    "    test_size = x_test.shape[0]\n",
    "\n",
    "    for i in range(test_size):\n",
    "        if np.all(rounded_predictions[i] == y_train[i]):  # Check if the prediction matches the expected output\n",
    "            correct_predictions_count += 1\n",
    "        else:\n",
    "            if (decimal_dataset.iloc[i,0], decimal_dataset.iloc[i,1]) in carryover_list:\n",
    "                carryover_mistakes += 1\n",
    "            if visualize_errors == 1:\n",
    "                print(f'Mistake: {decimal_dataset.iloc[i,0]} times {decimal_dataset.iloc[i,1]}.')\n",
    "\n",
    "    return test_size, correct_predictions_count, carryover_mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33821305-4306-4e87-bb7a-5a82cdfa524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundingLayer(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return K.round(inputs)  # Round to 0 and 1\n",
    "\n",
    "def generate_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "    initializer1 = tf.keras.initializers.GlorotNormal()\n",
    "    model = tf.keras.Sequential()\n",
    "    inputs = tf.keras.Input(shape=(None, 8))\n",
    "\n",
    "    # Construir las capas a partir de 'inputs'\n",
    "    x = tf.keras.layers.LSTM(128, return_sequences=True, kernel_initializer=initializer1)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.05)(x)\n",
    "    x = tf.keras.layers.LSTM(512)(x)\n",
    "    x = tf.keras.layers.Dropout(0.05)(x)\n",
    "    x = tf.keras.layers.LSTM(256)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.05)(x)\n",
    "    x = tf.keras.layers.LSTM(128)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.05)(x)\n",
    "    outputs = tf.keras.layers.Dense(7, activation='sigmoid')(x)\n",
    "\n",
    "    # Crear el modelo completo\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a34381a1-f636-4620-8ca6-1f8a8f849161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">70,144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m70,144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,047</span> (277.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,047\u001b[0m (277.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,047</span> (277.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,047\u001b[0m (277.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainable_model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85daf55b-da26-4126-8c75-09dcd2915511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1576 - loss: 0.2065 - val_accuracy: 0.1818 - val_loss: 0.1443\n",
      "Epoch 2/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.2068 - loss: 0.1168 - val_accuracy: 0.2975 - val_loss: 0.1051\n",
      "Epoch 3/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.2805 - loss: 0.0813 - val_accuracy: 0.3388 - val_loss: 0.0857\n",
      "Epoch 4/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.3120 - loss: 0.0597 - val_accuracy: 0.3884 - val_loss: 0.0715\n",
      "Epoch 5/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3360 - loss: 0.0453 - val_accuracy: 0.3554 - val_loss: 0.0605\n",
      "Epoch 6/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3423 - loss: 0.0355 - val_accuracy: 0.3636 - val_loss: 0.0535\n",
      "Epoch 7/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3422 - loss: 0.0292 - val_accuracy: 0.3554 - val_loss: 0.0490\n",
      "Epoch 8/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3505 - loss: 0.0250 - val_accuracy: 0.3388 - val_loss: 0.0457\n",
      "Epoch 9/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3512 - loss: 0.0220 - val_accuracy: 0.3471 - val_loss: 0.0431\n",
      "Epoch 10/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3492 - loss: 0.0192 - val_accuracy: 0.3471 - val_loss: 0.0410\n",
      "Epoch 11/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3459 - loss: 0.0165 - val_accuracy: 0.3471 - val_loss: 0.0391\n",
      "Epoch 12/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3418 - loss: 0.0145 - val_accuracy: 0.3388 - val_loss: 0.0380\n",
      "Epoch 13/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3400 - loss: 0.0130 - val_accuracy: 0.3306 - val_loss: 0.0370\n",
      "Epoch 14/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3352 - loss: 0.0121 - val_accuracy: 0.3388 - val_loss: 0.0365\n",
      "Epoch 15/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3351 - loss: 0.0113 - val_accuracy: 0.3223 - val_loss: 0.0359\n",
      "Epoch 16/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3304 - loss: 0.0106 - val_accuracy: 0.3223 - val_loss: 0.0356\n",
      "Epoch 17/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3255 - loss: 0.0102 - val_accuracy: 0.3306 - val_loss: 0.0354\n",
      "Epoch 18/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.3298 - loss: 0.0099 - val_accuracy: 0.3306 - val_loss: 0.0353\n",
      "Epoch 19/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.3317 - loss: 0.0096 - val_accuracy: 0.3306 - val_loss: 0.0351\n",
      "Epoch 20/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3327 - loss: 0.0094 - val_accuracy: 0.3388 - val_loss: 0.0350\n",
      "Epoch 21/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3346 - loss: 0.0092 - val_accuracy: 0.3140 - val_loss: 0.0348\n",
      "Epoch 22/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3312 - loss: 0.0091 - val_accuracy: 0.3223 - val_loss: 0.0347\n",
      "Epoch 23/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3290 - loss: 0.0090 - val_accuracy: 0.3306 - val_loss: 0.0347\n",
      "Epoch 24/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.3318 - loss: 0.0089 - val_accuracy: 0.3223 - val_loss: 0.0343\n",
      "Epoch 25/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3306 - loss: 0.0089 - val_accuracy: 0.3306 - val_loss: 0.0343\n",
      "Epoch 26/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3348 - loss: 0.0088 - val_accuracy: 0.3223 - val_loss: 0.0340\n",
      "Epoch 27/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3327 - loss: 0.0088 - val_accuracy: 0.3140 - val_loss: 0.0342\n",
      "Epoch 28/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.3396 - loss: 0.0087 - val_accuracy: 0.3471 - val_loss: 0.0339\n",
      "Epoch 29/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3393 - loss: 0.0087 - val_accuracy: 0.3388 - val_loss: 0.0338\n",
      "Epoch 30/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3388 - loss: 0.0087 - val_accuracy: 0.3471 - val_loss: 0.0337\n",
      "Epoch 31/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3439 - loss: 0.0087 - val_accuracy: 0.3471 - val_loss: 0.0336\n",
      "Epoch 32/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3386 - loss: 0.0086 - val_accuracy: 0.3388 - val_loss: 0.0339\n",
      "Epoch 33/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3464 - loss: 0.0086 - val_accuracy: 0.3471 - val_loss: 0.0338\n",
      "Epoch 34/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.3441 - loss: 0.0086 - val_accuracy: 0.3471 - val_loss: 0.0339\n",
      "Epoch 35/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3454 - loss: 0.0086 - val_accuracy: 0.3554 - val_loss: 0.0335\n",
      "Epoch 36/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3418 - loss: 0.0086 - val_accuracy: 0.3471 - val_loss: 0.0339\n",
      "Epoch 37/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3507 - loss: 0.0086 - val_accuracy: 0.3554 - val_loss: 0.0339\n",
      "Epoch 38/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3483 - loss: 0.0086 - val_accuracy: 0.3471 - val_loss: 0.0336\n",
      "Epoch 39/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3424 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0332\n",
      "Epoch 40/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.3446 - loss: 0.0085 - val_accuracy: 0.3306 - val_loss: 0.0339\n",
      "Epoch 41/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3326 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0333\n",
      "Epoch 42/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3347 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0335\n",
      "Epoch 43/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.3416 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0333\n",
      "Epoch 44/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3351 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0338\n",
      "Epoch 45/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3462 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0335\n",
      "Epoch 46/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3412 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0333\n",
      "Epoch 47/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3542 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0335\n",
      "Epoch 48/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3524 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0333\n",
      "Epoch 49/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.3535 - loss: 0.0085 - val_accuracy: 0.3802 - val_loss: 0.0339\n",
      "Epoch 50/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3514 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0339\n",
      "Epoch 51/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3463 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0330\n",
      "Epoch 52/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3528 - loss: 0.0085 - val_accuracy: 0.3223 - val_loss: 0.0325\n",
      "Epoch 53/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3495 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0322\n",
      "Epoch 54/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3481 - loss: 0.0085 - val_accuracy: 0.3306 - val_loss: 0.0330\n",
      "Epoch 55/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3412 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0334\n",
      "Epoch 56/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.3501 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0323\n",
      "Epoch 57/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3480 - loss: 0.0085 - val_accuracy: 0.3306 - val_loss: 0.0336\n",
      "Epoch 58/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3478 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0326\n",
      "Epoch 59/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3509 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0329\n",
      "Epoch 60/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3610 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0328\n",
      "Epoch 61/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3540 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0332\n",
      "Epoch 62/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3664 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0337\n",
      "Epoch 63/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3494 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0333\n",
      "Epoch 64/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3595 - loss: 0.0085 - val_accuracy: 0.3802 - val_loss: 0.0324\n",
      "Epoch 65/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.3537 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0343\n",
      "Epoch 66/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3595 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0341\n",
      "Epoch 67/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3550 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0325\n",
      "Epoch 68/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3475 - loss: 0.0085 - val_accuracy: 0.3306 - val_loss: 0.0320\n",
      "Epoch 69/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.3542 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0344\n",
      "Epoch 70/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3615 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0340\n",
      "Epoch 71/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3639 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0345\n",
      "Epoch 72/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.3531 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0344\n",
      "Epoch 73/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3527 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0343\n",
      "Epoch 74/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3594 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0342\n",
      "Epoch 75/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3521 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0338\n",
      "Epoch 76/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3529 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0330\n",
      "Epoch 77/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3553 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0329\n",
      "Epoch 78/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3432 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0330\n",
      "Epoch 79/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3505 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0333\n",
      "Epoch 80/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3659 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0340\n",
      "Epoch 81/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3595 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0327\n",
      "Epoch 82/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.3545 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0334\n",
      "Epoch 83/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3574 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0327\n",
      "Epoch 84/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.3570 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0328\n",
      "Epoch 85/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3580 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0333\n",
      "Epoch 86/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3549 - loss: 0.0085 - val_accuracy: 0.3140 - val_loss: 0.0329\n",
      "Epoch 87/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.3529 - loss: 0.0085 - val_accuracy: 0.3802 - val_loss: 0.0327\n",
      "Epoch 88/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3633 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0324\n",
      "Epoch 89/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3616 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0326\n",
      "Epoch 90/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3536 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0332\n",
      "Epoch 91/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.3593 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0328\n",
      "Epoch 92/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3502 - loss: 0.0085 - val_accuracy: 0.3306 - val_loss: 0.0326\n",
      "Epoch 93/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.3411 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0327\n",
      "Epoch 94/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3451 - loss: 0.0085 - val_accuracy: 0.3223 - val_loss: 0.0315\n",
      "Epoch 95/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.3429 - loss: 0.0085 - val_accuracy: 0.3306 - val_loss: 0.0324\n",
      "Epoch 96/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3512 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0345\n",
      "Epoch 97/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3664 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0336\n",
      "Epoch 98/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3706 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0329\n",
      "Epoch 99/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.3594 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0327\n",
      "Epoch 100/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.3686 - loss: 0.0085 - val_accuracy: 0.3802 - val_loss: 0.0336\n",
      "Epoch 101/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3741 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0327\n",
      "Epoch 102/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3667 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0328\n",
      "Epoch 103/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.3609 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0338\n",
      "Epoch 104/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3622 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0336\n",
      "Epoch 105/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.3623 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0332\n",
      "Epoch 106/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.3628 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0330\n",
      "Epoch 107/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3670 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0339\n",
      "Epoch 108/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3775 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0321\n",
      "Epoch 109/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3750 - loss: 0.0085 - val_accuracy: 0.3967 - val_loss: 0.0330\n",
      "Epoch 110/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3858 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0334\n",
      "Epoch 111/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3708 - loss: 0.0085 - val_accuracy: 0.3802 - val_loss: 0.0323\n",
      "Epoch 112/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.3735 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0328\n",
      "Epoch 113/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.3751 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0333\n",
      "Epoch 114/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3827 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0341\n",
      "Epoch 115/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.3805 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0339\n",
      "Epoch 116/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.3474 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0340\n",
      "Epoch 117/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.3520 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0353\n",
      "Epoch 118/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.3625 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0356\n",
      "Epoch 119/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.3643 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0350\n",
      "Epoch 120/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3672 - loss: 0.0085 - val_accuracy: 0.3967 - val_loss: 0.0340\n",
      "Epoch 121/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.3711 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0342\n",
      "Epoch 122/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3496 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0334\n",
      "Epoch 123/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3513 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0343\n",
      "Epoch 124/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3626 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0339\n",
      "Epoch 125/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3652 - loss: 0.0085 - val_accuracy: 0.3802 - val_loss: 0.0339\n",
      "Epoch 126/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3740 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0335\n",
      "Epoch 127/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3658 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0350\n",
      "Epoch 128/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3555 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0338\n",
      "Epoch 129/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3610 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0323\n",
      "Epoch 130/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3748 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0332\n",
      "Epoch 131/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3670 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0334\n",
      "Epoch 132/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3706 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0331\n",
      "Epoch 133/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3829 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0343\n",
      "Epoch 134/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3668 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0341\n",
      "Epoch 135/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3806 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0331\n",
      "Epoch 136/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3786 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0337\n",
      "Epoch 137/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3797 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0332\n",
      "Epoch 138/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3743 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0352\n",
      "Epoch 139/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3849 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0333\n",
      "Epoch 140/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3701 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0337\n",
      "Epoch 141/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3717 - loss: 0.0085 - val_accuracy: 0.3884 - val_loss: 0.0333\n",
      "Epoch 142/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3658 - loss: 0.0085 - val_accuracy: 0.3719 - val_loss: 0.0340\n",
      "Epoch 143/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.3679 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0341\n",
      "Epoch 144/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3764 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0337\n",
      "Epoch 145/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.3639 - loss: 0.0085 - val_accuracy: 0.3471 - val_loss: 0.0327\n",
      "Epoch 146/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.3605 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0331\n",
      "Epoch 147/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3649 - loss: 0.0085 - val_accuracy: 0.3388 - val_loss: 0.0331\n",
      "Epoch 148/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.3492 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0344\n",
      "Epoch 149/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.3582 - loss: 0.0085 - val_accuracy: 0.3554 - val_loss: 0.0334\n",
      "Epoch 150/150\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.3561 - loss: 0.0085 - val_accuracy: 0.3636 - val_loss: 0.0334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x173c2eb96d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neural_network(trainable_model, level=-2, epochs=150, steps_per_epoch=300, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58f1f40f-8308-4075-826c-acae4794bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Out of 100, 94 were predicted correctly in the current model, with 6 mistakes in examples with carryover.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step\n",
      "Out of 144, 107 were predicted correctly in the current model, with 24 mistakes in examples with carryover.\n"
     ]
    }
   ],
   "source": [
    "visualize_errors = 0\n",
    "\n",
    "for real_test in range(0, 2):\n",
    "    test_size, correct_predictions_count, carryover_mistakes = test_neural_network(trainable_model, visualize_errors=visualize_errors, real_test=real_test)\n",
    "    print(f\"Out of {test_size}, {correct_predictions_count} were predicted correctly in the current model, with {carryover_mistakes} mistakes in examples with carryover.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc26e289-04a9-4cdb-80f3-92f5f3e6b0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
