{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98558e0d-b53a-412c-81a9-9bb54f749c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:21:51.672805: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-03 17:21:51.688648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733242911.707064  726620 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733242911.712670  726620 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 17:21:51.731497: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W0000 00:00:1733242913.594093  726620 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "from tensorflow.keras.models import Model, load_model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Lambda, Concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.initializers import GlorotUniform, RandomUniform, Constant\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5220b5d7-767d-4616-9750-922b01af448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow no está utilizando la GPU\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay GPUs disponibles\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow está utilizando la GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow no está utilizando la GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c8a971-a305-48fe-94a9-40be4a3f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los módulos preentrenados (unit_module y carry_module)\n",
    "unit_addition_model = load_model('unit_addition_module.keras')\n",
    "unit_carry_model = load_model('unit_carry_module.keras')\n",
    "unit_addition_model.trainable = False\n",
    "unit_carry_model.trainable = False\n",
    "unit_addition_model.name = 'unit_addition_model'\n",
    "unit_carry_model.name = 'unit_carry_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92293af0-33a3-408d-98e3-a37a680a8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar los datos\n",
    "def generate_final_data():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for a_dec in range(10):\n",
    "        for a_unit in range(10):\n",
    "            for b_dec in range(10):\n",
    "                for b_unit in range(10):\n",
    "                    x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "                    sum_units = (a_unit + b_unit) % 10\n",
    "                    carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "                    sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "                    carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "                    y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    return jnp.array(x_data), jnp.array(y_data)\n",
    "\n",
    "# Función para crear parámetros entrenables (v_0, ..., v_11)\n",
    "def init_params(epsilon=0):\n",
    "    w_values_init = jnp.array([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0], dtype=jnp.float32)\n",
    "    u_values_init = jnp.array([0, 1, 0, 0], dtype=jnp.float32)\n",
    "    v_values_init = jnp.array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=jnp.float32)\n",
    "    key = random.PRNGKey(0)\n",
    "    keys = random.split(key, 16 + 4 + 12)  # Total 32 claves necesarias\n",
    "    w_params = {f'w{i}': random.normal(keys[i], (1,)) * epsilon + w_values_init[i] for i in range(16)}\n",
    "    u_params = {f'u{i}': random.normal(keys[16 + i], (1,)) * epsilon + u_values_init[i] for i in range(4)}\n",
    "    v_params = {f'v{i}': random.normal(keys[20 + i], (1,)) * epsilon + v_values_init[i] for i in range(12)}\n",
    "    params = {**w_params, **u_params, **v_params}\n",
    "    return params\n",
    "\n",
    "# Modelo dinámico en JAX\n",
    "def model(params, x):\n",
    "    # Extraer unidades y decenas de los valores de entrada\n",
    "    unit_input_1 = (params['w0'] * x[0]) + (params['w1'] * x[1]) + (params['w2'] * x[2]) + (params['w3'] * x[3])\n",
    "    unit_input_2 = (params['w4'] * x[0]) + (params['w5'] * x[1]) + (params['w6'] * x[2]) + (params['w7'] * x[3])\n",
    "    \n",
    "    # Llamar a los modelos unit_module y carry_module\n",
    "    units_input = jnp.array([unit_input_1, unit_input_2])\n",
    "    units_input = units_input[None, None, :]\n",
    "    unit_output = jnp.array(unit_addition_model(units_input))  # Salida para unidades\n",
    "    unit_carry_output = jnp.array(unit_carry_model(units_input))  # Salida de acarreo de unidades\n",
    "\n",
    "    # Tomar el valor máximo de las predicciones (argmax en JAX)\n",
    "    unit_val = jnp.argmax(unit_output, axis=-1)\n",
    "    carry_unit_val = jnp.argmax(unit_carry_output, axis=-1) \n",
    "    \n",
    "    dec_input_1 = (params['w8'] * x[0]) + (params['w9'] * x[1]) + (params['w10'] * x[2]) + (params['w11'] * x[3]) + (params['u0'] * unit_val[0]) + (params['u1'] * carry_unit_val[0])\n",
    "    dec_input_2 = (params['w12'] * x[0]) + (params['w13'] * x[1]) + (params['w14'] * x[2]) + (params['w15'] * x[3]) + (params['u2'] * unit_val[0]) + (params['u3'] * carry_unit_val[0])\n",
    "\n",
    "    # Llamar a los modelos unit_module y carry_module\n",
    "    decs_input = jnp.array([dec_input_1, dec_input_2])\n",
    "    decs_input = decs_input[None, None, :]\n",
    "    dec_output = jnp.array(dec_addition_model(decs_input))  # Salida para decenas\n",
    "    dec_carry_output = jnp.array(dec_carry_model(decs_input))  # Salida de acarreo de decenas\n",
    "\n",
    "    # Tomar el valor máximo de las predicciones (argmax en JAX)    \n",
    "    dec_val = jnp.argmax(dec_output, axis=-1)\n",
    "    carry_dec_val = jnp.argmax(dec_carry_output, axis=-1)\n",
    "\n",
    "    # Calcular las salidas combinadas con los parámetros v\n",
    "    salida_1 = (params['v0'] * carry_dec_val) + (params['v1'] * dec_val) + (params['v2'] * carry_unit_val) + (params['v3'] * unit_val)\n",
    "    salida_2 = (params['v4'] * carry_dec_val) + (params['v5'] * dec_val) + (params['v6'] * carry_unit_val) + (params['v7'] * unit_val)\n",
    "    salida_3 = (params['v8'] * carry_dec_val) + (params['v9'] * dec_val) + (params['v10'] * carry_unit_val) + (params['v11'] * unit_val)\n",
    "\n",
    "    return salida_1, salida_2, salida_3\n",
    "\n",
    "# Función de pérdida\n",
    "def loss_fn(params, x, y):\n",
    "    y_pred_1, y_pred_2, y_pred_3 = model(params, x)\n",
    "    return jnp.mean((y_pred_1 - y[0]) ** 2) + jnp.mean((y_pred_2 - y[1]) ** 2) + jnp.mean((y_pred_3 - y[2]) ** 2)\n",
    "    \n",
    "# Función para entrenar el modelo\n",
    "def update_params(params, x, y, lr):\n",
    "    # Asegúrate de usar JAX para los gradientes y operaciones\n",
    "    gradients = grad(loss_fn)(params, x, y)\n",
    "    step_loss = loss_fn(params, x, y)\n",
    "    new_params = jax.tree.map(lambda p, g: p - lr * g, params, gradients)\n",
    "    return new_params, step_loss\n",
    "\n",
    "\n",
    "def train_model(params, x_train, y_train, lr=0.01, epochs=100):\n",
    "    final_loss = 0\n",
    "    # Convertir x_train y y_train a arrays de JAX (si aún no lo son)\n",
    "    x_train = jnp.array(x_train)\n",
    "    y_train = jnp.array(y_train)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    for epoch in range(epochs):  # Número de épocas\n",
    "        params, step_loss = update_params(params, x_train[epoch], y_train[epoch], lr)\n",
    "        final_loss += step_loss\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {step_loss}\")\n",
    "        \n",
    "    final_loss = final_loss / epochs\n",
    "    return params, final_loss\n",
    "\n",
    "# Función para imprimir las predicciones y el loss en cada época\n",
    "def print_predictions_and_loss(epoch, predictions, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples = x_train.shape[0]\n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(predictions[j][i])) for j in range(3)]\n",
    "        \n",
    "        # Concatenar las predicciones en un número de 3 dígitos\n",
    "        concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "        \n",
    "        # Generar la salida esperada, concatenando los valores reales de y_train\n",
    "        expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))\n",
    "        \n",
    "        # Comprobar si la predicción es igual a la salida esperada\n",
    "        if concatenated_pred == expected_output:\n",
    "            pred_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}:\")\n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Si todas las predicciones son correctas, detener el entrenamiento\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente! Deteniendo entrenamiento.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def predictions(params, x_train, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples = x_train.shape[0]   \n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        prediction = model(params, x_train[i])\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(prediction[j].item())) for j in range(3)]\n",
    "        \n",
    "        # Concatenar las predicciones en un número de 3 dígitos\n",
    "        concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "        \n",
    "        # Generar la salida esperada, concatenando los valores reales de y_train\n",
    "        expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))\n",
    "        \n",
    "        # Comprobar si la predicción es igual a la salida esperada\n",
    "        if concatenated_pred == expected_output:\n",
    "            pred_count += 1\n",
    "\n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente!\")\n",
    "\n",
    "def count_predictions(params, x_train, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples =  x_train.shape[0]   \n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        prediction = model(params, x_train[i])\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(prediction[j].item())) for j in range(3)]\n",
    "        \n",
    "        if normalized_pred[0] == y_train[i,0]:\n",
    "            if normalized_pred[1] == y_train[i,1]:\n",
    "                if normalized_pred[2] == y_train[i,2]:\n",
    "                    pred_count += 1\n",
    "\n",
    "        if (normalized_pred[0] != y_train[i,0]) or (normalized_pred[1]!= y_train[i,1]) or (normalized_pred[2] != y_train[i,2]):\n",
    "            print(f'Error en la suma: {x_train[i]}')\n",
    "            break\n",
    "            \n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc503a87-d87f-4f4b-8895-10a1fa7d18b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All input arrays must have the same shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_726188/1213290899.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_final_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcount_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_726188/3261868194.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(params, x_train, y_train)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mpred_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mtotal_examples\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Obtener las predicciones para la unidad, decena y acarreo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mnormalized_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_726188/3261868194.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(params, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Tomar el valor máximo de las predicciones (argmax en JAX)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0munit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcarry_unit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit_carry_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mdecs_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarry_unit_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mdecs_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecs_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_addition_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecs_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Salida para decenas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CURRICULUM_LEARNING/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(object, dtype, copy, order, ndmin, device)\u001b[0m\n\u001b[1;32m   5413\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5414\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_array_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5415\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5417\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5418\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5419\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5420\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0m_supports_buffer_protocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CURRICULUM_LEARNING/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[1;32m   4470\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_canonicalize_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4471\u001b[0m     \u001b[0mnew_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4472\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4473\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mshape0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4474\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All input arrays must have the same shape.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4475\u001b[0m       \u001b[0mnew_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All input arrays must have the same shape."
     ]
    }
   ],
   "source": [
    "x_train, y_train = generate_final_data()\n",
    "params = init_params()\n",
    "\n",
    "count_predictions(params, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc3db32-3fc1-4ab5-92a3-494ec92ae651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] [0.] [0.]\n"
     ]
    }
   ],
   "source": [
    "x = [0, 1, 9, 9]\n",
    "y_train = [1, 0, 0]\n",
    "params = init_params()\n",
    "\n",
    "units_input = jnp.array([x[1], x[3]])\n",
    "units_input = units_input[None, None, :]\n",
    "\n",
    "# Llamar a los modelos unit_module y carry_module\n",
    "unit_output = jnp.array(unit_addition_model(units_input))  # Salida para unidades\n",
    "unit_carry_output = jnp.array(unit_carry_model(units_input))  # Salida de acarreo de unidades\n",
    "# Tomar el valor máximo de las predicciones (argmax en JAX)\n",
    "unit_val = jnp.argmax(unit_output, axis=-1)\n",
    "carry_unit_val = jnp.argmax(unit_carry_output, axis=-1)\n",
    "\n",
    "decs_input = jnp.array([x[0], x[2], carry_unit_val[0]])\n",
    "decs_input = decs_input[None, None, :]\n",
    "\n",
    "dec_output = jnp.array(dec_addition_model(decs_input))  # Salida para decenas\n",
    "dec_carry_output = jnp.array(dec_carry_model(decs_input))  # Salida de acarreo de decenas\n",
    "\n",
    "dec_val = jnp.argmax(dec_output, axis=-1)\n",
    "carry_dec_val = jnp.argmax(dec_carry_output, axis=-1)\n",
    "# Calcular las salidas combinadas con los parámetros v\n",
    "salida_1 = (params['v0'] * carry_dec_val) + (params['v1'] * dec_val) + (params['v2'] * carry_unit_val) + (params['v3'] * unit_val)\n",
    "salida_2 = (params['v4'] * carry_dec_val) + (params['v5'] * dec_val) + (params['v6'] * carry_unit_val) + (params['v7'] * unit_val)\n",
    "salida_3 = (params['v8'] * carry_dec_val) + (params['v9'] * dec_val) + (params['v10'] * carry_unit_val) + (params['v11'] * unit_val)\n",
    "\n",
    "print(salida_1, salida_2, salida_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86181597-c941-4886-a28a-b612e940a339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00961376-49a8-4c0c-a8c1-3cbbf5932901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823fcaf-c605-412b-8039-51e9fc244133",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_final_data()\n",
    "params = init_params()\n",
    "x=x_train[0]\n",
    "print(jnp.array([x[1], x[3]]))\n",
    "new_params, final_loss = train_model(params, x_train, y_train, lr=0.01, epochs=100)\n",
    "print(final_loss)\n",
    "\n",
    "# Hacer predicciones después del entrenamiento\n",
    "predictions = model(params, x_train)\n",
    "print(\"Predicciones:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf51e8-d461-46ae-b59e-9bb29eab7081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc3aa9-c848-4beb-b1e2-a02a13abe0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c287a4bf-c7e2-4819-97f0-a50075e074e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Multiply.call().\n\n\u001b[1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'sparse'\u001b[0m\n\nArguments received by Multiply.call():\n  • args=(['tf.Tensor(shape=(1,), dtype=float32)', '<KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_22>'],)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dynamic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrainable_variables:\n",
      "Cell \u001b[1;32mIn[32], line 53\u001b[0m, in \u001b[0;36mbuild_dynamic_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m carry_dec_val \u001b[38;5;241m=\u001b[39m Lambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39margmax(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))(carry_output_dec)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Calcular las salidas finales combinando los valores ponderados\u001b[39;00m\n\u001b[0;32m     52\u001b[0m salida_1 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mMultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv_split\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarry_dec_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     54\u001b[0m     Multiply()([v_split[\u001b[38;5;241m1\u001b[39m], dec_val]),\n\u001b[0;32m     55\u001b[0m     Multiply()([v_split[\u001b[38;5;241m2\u001b[39m], carry_unit_val]),\n\u001b[0;32m     56\u001b[0m     Multiply()([v_split[\u001b[38;5;241m3\u001b[39m], unit_val]),\n\u001b[0;32m     57\u001b[0m ])\n\u001b[0;32m     58\u001b[0m salida_2 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[0;32m     59\u001b[0m     Multiply()([v_split[\u001b[38;5;241m4\u001b[39m], carry_dec_val]),\n\u001b[0;32m     60\u001b[0m     Multiply()([v_split[\u001b[38;5;241m5\u001b[39m], dec_val]),\n\u001b[0;32m     61\u001b[0m     Multiply()([v_split[\u001b[38;5;241m6\u001b[39m], carry_unit_val]),\n\u001b[0;32m     62\u001b[0m     Multiply()([v_split[\u001b[38;5;241m7\u001b[39m], unit_val]),\n\u001b[0;32m     63\u001b[0m ])\n\u001b[0;32m     64\u001b[0m salida_3 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[0;32m     65\u001b[0m     Multiply()([v_split[\u001b[38;5;241m8\u001b[39m], carry_dec_val]),\n\u001b[0;32m     66\u001b[0m     Multiply()([v_split[\u001b[38;5;241m9\u001b[39m], dec_val]),\n\u001b[0;32m     67\u001b[0m     Multiply()([v_split[\u001b[38;5;241m10\u001b[39m], carry_unit_val]),\n\u001b[0;32m     68\u001b[0m     Multiply()([v_split[\u001b[38;5;241m11\u001b[39m], unit_val]),\n\u001b[0;32m     69\u001b[0m ])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:260\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    254\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    255\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    256\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling Multiply.call().\n\n\u001b[1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'sparse'\u001b[0m\n\nArguments received by Multiply.call():\n  • args=(['tf.Tensor(shape=(1,), dtype=float32)', '<KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_22>'],)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "model = build_dynamic_model()\n",
    "model.summary()\n",
    "\n",
    "for var in model.trainable_variables:\n",
    "    if var.name == \"v_values:0\":\n",
    "        print(\"Valores iniciales de v_values:\", var.numpy())\n",
    "\n",
    "\n",
    "# Predicciones\n",
    "total_examples = x_train.shape[0]\n",
    "pred_count = 0\n",
    "\n",
    "# Realizar las predicciones para todos los ejemplos\n",
    "predictions = model.predict(x_train)\n",
    "\n",
    "# Si `predictions` contiene múltiples arrays (uno por salida del modelo):\n",
    "if isinstance(predictions, list):\n",
    "    # Concatenamos las predicciones en columnas\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {f\"Salida_{i+1}\": pred.flatten() for i, pred in enumerate(predictions)}\n",
    "    )\n",
    "else:\n",
    "    # Si `predictions` es un solo array\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Guardar como archivo CSV\n",
    "predictions_df.to_csv(\"predicciones_completas.csv\", index=False)\n",
    "\n",
    "# Inicializar listas para almacenar las predicciones y las salidas reales\n",
    "predicted_values = []\n",
    "expected_values = []\n",
    "\n",
    "for i in range(total_examples):\n",
    "    # Normalizar y redondear la predicción (cada salida del modelo)\n",
    "    normalized_pred = [\n",
    "        np.round(predictions[0][i]).astype(int),  # Primer valor del primer array\n",
    "        np.round(predictions[1][i]).astype(int),  # Primer valor del segundo array\n",
    "        np.round(predictions[2][i]).astype(int)   # Primer valor del tercer array\n",
    "    ]\n",
    "    \n",
    "    # Concatenar los tres elementos en normalized_pred como un solo número\n",
    "    concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "\n",
    "    # Comparar la predicción con la salida real\n",
    "    expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))  # Convertir la salida esperada en un número\n",
    "    \n",
    "    # Almacenar en las listas\n",
    "    predicted_values.append(concatenated_pred)\n",
    "    expected_values.append(expected_output)\n",
    "    \n",
    "    if concatenated_pred == expected_output:\n",
    "        pred_count += 1    \n",
    "\n",
    "print(f'Predicciones correctas: {pred_count} de {total_examples}.')\n",
    "\n",
    "# Crear un DataFrame con los datos\n",
    "data = {\n",
    "    \"Predicción\": predicted_values,\n",
    "    \"Valor Esperado\": expected_values\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar como archivo CSV\n",
    "df.to_csv(\"predicciones.csv\", index=False)\n",
    "\n",
    "print(f\"Archivo 'predicciones.csv' guardado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a153281-79cc-4133-9ce0-23d3f23d69ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c21301-93a0-4872-afbf-83700fbaf840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bf7f3-08d0-4374-9d8f-8149152c663e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f327801-4ba5-41cb-a654-53b6490c6169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb73e7-6710-44ad-a5f7-8a31e738acd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46548b-ff3f-49a5-a801-5de9ef66bf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcacb6-7fff-4886-8f33-47d9fed37126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13946a60-c632-45a3-92a2-bc8079f0618d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8a1ea-e598-41d2-9e41-7c7ce7d995bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (CURRICULUM_LEARNING)",
   "language": "python",
   "name": "curriculum_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
