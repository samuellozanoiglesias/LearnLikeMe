{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e67e4db-f139-4bde-b30e-e68e37779b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad\n",
    "from jax.nn import relu, sigmoid\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import pytz\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e32cf2-490d-4527-af07-dd4e51758135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random_weights(mean, std, shape = ()):\n",
    "    return np.random.normal(loc=mean, scale=std, size=shape)\n",
    "\n",
    "# We use a sinusoidal function to approximate odd numbers by their immediately preceding even number and preserve differentiability\n",
    "def lower_even(x):\n",
    "    return x - 0.5 * (1 - jnp.cos(jnp.pi * x))\n",
    "\n",
    "# We use a sinusoidal function to approximate 0 for evens and 1 for odds while preserving differentiability\n",
    "def differentiable_even_or_odd(x):\n",
    "    return ((2 * x ** 3) / 3) - 3 * x ** 2 + ((10 * x) / 3)\n",
    "\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "\n",
    "# Cargar las parejas desde el archivo\n",
    "with open(f\"{folder}/train_couples.txt\", \"r\") as file:\n",
    "    train_couples = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_with_carry_over.txt\", \"r\") as file:\n",
    "    combinations_with_carry_over = eval(file.read())  # Leer y convertir el contenido en una lista de tuplas\n",
    "\n",
    "# Separar parejas con y sin ceros\n",
    "train_without_zeros = [pair for pair in train_couples if 0 not in pair]\n",
    "train_with_carry_over = [pair for pair in train_couples if pair in combinations_with_carry_over]\n",
    "\n",
    "# Function to generate dataset with multiplication\n",
    "def generate_dataset_with_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas con ceros\n",
    "    selected_pairs = random.choices(train_couples, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_without_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas sin ceros\n",
    "    selected_pairs = random.choices(train_without_zeros, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_test_dataset(n_max=100):\n",
    "    # Create the columns\n",
    "    column_1 = list(range(n_max)) * n_max  # Numbers from 0 to 9 repeated 10 times\n",
    "    column_2 = [i for i in range(n_max) for _ in range(n_max)]  # Numbers from 0 to 9 repeated sequentially 10 times\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def decimal_to_binary(n, bits):\n",
    "    if 0 <= n < 2**bits:\n",
    "        # Convert the number to a binary string and then to an array of integers (0 and 1)\n",
    "        return np.array(list(format(n, f'0{bits}b'))).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(\"Number out of range\")\n",
    "\n",
    "# Function to convert binary number to decimal\n",
    "def binary_to_decimal(binary_vector, bits):\n",
    "    # Ensure the vector has the correct number of elements\n",
    "    if len(binary_vector) != bits:\n",
    "        raise ValueError(f\"The vector must have exactly {bits} elements.\")\n",
    "\n",
    "    # Calculate the decimal number\n",
    "    decimal = 0\n",
    "    for i in range(bits):\n",
    "        decimal += binary_vector[i] * (2 ** (bits - 1 - i))\n",
    "\n",
    "    return decimal\n",
    "\n",
    "def transform_to_tridimensional_matrix(dataset, bits_init=7, bits_end=8):\n",
    "    rows, cols = dataset.shape\n",
    "    if cols != 3:\n",
    "        raise ValueError(\"The dataset must have exactly 3 columns.\")\n",
    "\n",
    "    # Initialize the three matrices\n",
    "    matrix_column_1 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_2 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_3 = np.zeros((rows, bits_end), dtype=np.int8)\n",
    "\n",
    "    # Fill the matrices with the binary representation of each column\n",
    "    for i in range(rows):\n",
    "        matrix_column_1[i] = decimal_to_binary(dataset.iloc[i, 0], bits_init)\n",
    "        matrix_column_2[i] = decimal_to_binary(dataset.iloc[i, 1], bits_init)\n",
    "        matrix_column_3[i] = decimal_to_binary(dataset.iloc[i, 2], bits_end)\n",
    "\n",
    "    return matrix_column_1, matrix_column_2, matrix_column_3\n",
    "    \n",
    "    \n",
    "def prepare_dataset(level, size=1, couples_included=[]):       \n",
    "    if level == -3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = couples_included\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == -2:\n",
    "        dataset = generate_dataset_with_zeros(size)\n",
    "        return dataset\n",
    "        \n",
    "    elif level == -1:\n",
    "        dataset = generate_dataset_without_zeros(size)\n",
    "        return dataset\n",
    "\n",
    "    elif level == 0:\n",
    "        dataset = pd.DataFrame()\n",
    "        while len(dataset) < size:\n",
    "            column_1 = np.random.randint(1, 10, size)\n",
    "            column_2 = np.random.randint(1, 10, size)\n",
    "            temp_dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "            temp_dataset = temp_dataset[~temp_dataset[['Column_1', 'Column_2']].apply(tuple, axis=1).isin(combinations_with_carry_over)]\n",
    "            dataset = pd.concat([dataset, temp_dataset])\n",
    "        dataset = dataset.iloc[:size].reset_index(drop=True)\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 1:\n",
    "        pairs = random.choices(train_with_carry_over, k=size)\n",
    "        column_1 = [pair[0] for pair in pairs]\n",
    "        column_2 = [pair[1] for pair in pairs]\n",
    "        dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "        dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "\n",
    "def prepare_outputs(stage, x1, x2, outputs_prev):\n",
    "    if stage == 1:\n",
    "        outputs = []\n",
    "        for vec1, vec2 in zip(x1, x2):\n",
    "            z2 = lower_even(vec1[6] + vec2[6])\n",
    "            z3 = lower_even(vec1[5] + vec2[5] + z2 * 1/2)\n",
    "            z4 = lower_even(vec1[4] + vec2[4] + z3 * 1/2)\n",
    "            z5 = lower_even(vec1[3] + vec2[3] + z4 * 1/2)\n",
    "            z6 = lower_even(vec1[2] + vec2[2] + z5 * 1/2)\n",
    "            z7 = lower_even(vec1[1] + vec2[1] + z6 * 1/2)\n",
    "            z8 = lower_even(vec1[0] + vec2[0] + z7 * 1/2)\n",
    "            outputs.append([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "        return np.array(outputs)\n",
    "\n",
    "    elif stage == 2:\n",
    "        return outputs_prev\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "\n",
    "# Perfect parameters needed for the stages where a part of the NN performs perfectly\n",
    "# R vectors of dimension (14,1)\n",
    "R2_perfect = np.zeros((14))\n",
    "R3_perfect = np.zeros((14))\n",
    "R4_perfect = np.zeros((14))\n",
    "R5_perfect = np.zeros((14))\n",
    "R6_perfect = np.zeros((14))\n",
    "R7_perfect = np.zeros((14))\n",
    "R8_perfect = np.zeros((14))\n",
    "\n",
    "for i in range(2):\n",
    "    R2_perfect[7*i + 6] = 1\n",
    "    R3_perfect[7*i + 5] = 1\n",
    "    R4_perfect[7*i + 4] = 1\n",
    "    R5_perfect[7*i + 3] = 1\n",
    "    R6_perfect[7*i + 2] = 1\n",
    "    R7_perfect[7*i + 1] = 1\n",
    "    R8_perfect[7*i + 0] = 1\n",
    "\n",
    "# Scalar parameters v\n",
    "v2_perfect = 1/2\n",
    "v3_perfect = 1/2\n",
    "v4_perfect = 1/2\n",
    "v5_perfect = 1/2\n",
    "v6_perfect = 1/2\n",
    "v7_perfect = 1/2\n",
    "\n",
    "# Matrix T of dimension (28,7)\n",
    "T_perfect = np.zeros((14,8))\n",
    "for i in range(7):\n",
    "    for j in range(2):\n",
    "        T_perfect[7*j + i, i + 1] = 1\n",
    "\n",
    "# Parameter v\n",
    "v_perfect = 1/2\n",
    "\n",
    "# Neural network in every stage\n",
    "def neural_network_1(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    #y = differentiable_even_or_odd(jnp.dot(vec, T) + jnp.dot(z, v7))\n",
    "    return z\n",
    "    \n",
    "def neural_network_2(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "\n",
    "# Loss functions in every stage\n",
    "def loss_1(params, x1, x2, y):\n",
    "    pred = neural_network_1(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_2(params, x1, x2, y):\n",
    "    pred = neural_network_2(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "# Loss functions in every step\n",
    "@jax.jit\n",
    "def update_params_1(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_1)(params, x1, x2, y)\n",
    "    step_loss = loss_1(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_2(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_2)(params, x1, x2, y)\n",
    "    step_loss = loss_2(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "def decide_training(params, x1, x2, y, lr, stage):\n",
    "    if stage == 1:\n",
    "        params, step_loss = update_params_1(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 2:\n",
    "        params, step_loss = update_params_2(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "        \n",
    "# Main function to train the network\n",
    "def train_stages_neural_network(params, stage, level, lr=0.01, epochs=100):\n",
    "    decimal_dataset = prepare_dataset(level, epochs)\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    final_loss = 0\n",
    "    # Train the network\n",
    "    for epoch in range(epochs):\n",
    "        # Update parameters at each step\n",
    "        params, step_loss = decide_training(params, inputs_1[epoch], inputs_2[epoch], outputs[epoch], lr, stage)\n",
    "        final_loss += step_loss\n",
    "\n",
    "    final_loss = final_loss / epochs\n",
    "    #print(f\"Loss: {final_loss:.6f}\")\n",
    "    return params, final_loss\n",
    "\n",
    "\n",
    "# Main function to test the network\n",
    "def test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_test_dataset()\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "\n",
    "    correct_predictions_count = 0\n",
    "    correct_predictions_tested_count = 0\n",
    "    correct_predictions_trained_count = 0  # Counter for trained couples\n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_size = len(train_couples)\n",
    "    test_size = set_size - train_size\n",
    "    \n",
    "    for i in range(set_size):\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        # Check if the prediction matches the expected output\n",
    "        if jnp.all(prediction == outputs[i]):  \n",
    "            if (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1]) in train_couples:\n",
    "                correct_predictions_trained_count += 1  # Increment for trained couples\n",
    "            else:\n",
    "                correct_predictions_tested_count += 1 # Increment for tested couples\n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{decimal_dataset.iloc[i, 0]} plus {decimal_dataset.iloc[i, 1]} has failed.')\n",
    "\n",
    "    return test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count\n",
    "\n",
    "# Predict using the trained neural network\n",
    "def predict(params, x1, x2, stage):\n",
    "    if stage == 1:\n",
    "        binary_pred = neural_network_1(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 2:\n",
    "        binary_pred = neural_network_2(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79e9a11-6884-4c9b-94a0-e5c5243612d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_model():\n",
    "    # R vectors of dimension (14,1)\n",
    "    R2_perfect = np.zeros((14))\n",
    "    R3_perfect = np.zeros((14))\n",
    "    R4_perfect = np.zeros((14))\n",
    "    R5_perfect = np.zeros((14))\n",
    "    R6_perfect = np.zeros((14))\n",
    "    R7_perfect = np.zeros((14))\n",
    "    R8_perfect = np.zeros((14))\n",
    "    \n",
    "    for i in range(2):\n",
    "        R2_perfect[7*i + 6] = 1\n",
    "        R3_perfect[7*i + 5] = 1\n",
    "        R4_perfect[7*i + 4] = 1\n",
    "        R5_perfect[7*i + 3] = 1\n",
    "        R6_perfect[7*i + 2] = 1\n",
    "        R7_perfect[7*i + 1] = 1\n",
    "        R8_perfect[7*i + 0] = 1\n",
    "    \n",
    "    # Scalar parameters v\n",
    "    v2_perfect = 1/2\n",
    "    v3_perfect = 1/2\n",
    "    v4_perfect = 1/2\n",
    "    v5_perfect = 1/2\n",
    "    v6_perfect = 1/2\n",
    "    v7_perfect = 1/2\n",
    "    \n",
    "    # Matrix T of dimension (28,7)\n",
    "    T_perfect = np.zeros((14,8))\n",
    "    for i in range(7):\n",
    "        for j in range(2):\n",
    "            T_perfect[7*j + i, i + 1] = 1\n",
    "    \n",
    "    # Parameter v\n",
    "    v_perfect = 1/2\n",
    "    \n",
    "    original_model = [R2_perfect, R3_perfect, R4_perfect, R5_perfect, R6_perfect, R7_perfect, R8_perfect,\n",
    "            v2_perfect, v3_perfect, v4_perfect, v5_perfect, v6_perfect, v7_perfect, \n",
    "            T_perfect, v_perfect] \n",
    "    trainable_model = [R2_perfect, R3_perfect, R4_perfect, R5_perfect, R6_perfect, R7_perfect, R8_perfect,\n",
    "            v2_perfect, v3_perfect, v4_perfect, v5_perfect, v6_perfect, v7_perfect, \n",
    "            T_perfect, v_perfect] \n",
    "    return trainable_model, original_model\n",
    "\n",
    "def generate_model_random(mean=0.5, std=1):\n",
    "    R2 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the second bit\n",
    "    R3 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R4 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R5 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R6 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R7 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R8 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    v2 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v3 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v4 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v5 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v6 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v7 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    T = initialize_random_weights(mean, std, (14, 8))  # 196 neurons that allow performing the sum\n",
    "    v = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry vector for all bits\n",
    "    original_model = [R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v]\n",
    "    trainable_model = [R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v]\n",
    "    return trainable_model, original_model\n",
    "    \n",
    "def generate_model_AP(epsilon_non_zeros = 0.01, epsilon_zeros = 0.01):   \n",
    "    R2_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R3_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R4_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R5_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R6_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R7_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R8_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    for i in range(4):\n",
    "        R2_almost_perfect[7*i + 6] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R3_almost_perfect[7*i + 5] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R4_almost_perfect[7*i + 4] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R5_almost_perfect[7*i + 3] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R6_almost_perfect[7*i + 2] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R7_almost_perfect[7*i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R8_almost_perfect[7*i + 0] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v2_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v3_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v4_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v5_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v6_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v7_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    T_almost_perfect = np.zeros((14,8)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    for i in range(7):\n",
    "        for j in range(2):\n",
    "            T_almost_perfect[7*j + i, i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    original_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    trainable_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    return trainable_model, original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb1a38e-9ed3-4e9d-8e2a-d7981631eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "        \n",
    "def load_trainable_model(model, current_time, training_type, stage = 0):\n",
    "    folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "    if stage == 0:\n",
    "        model_path = f'{folder}/Parameters/{training_type}/{model}_{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'trainable_model'] = pickle.load(f)\n",
    "        print(f'Model trainable_model_{current_time} loaded successfully.')\n",
    "        return globals()[f'trainable_model']\n",
    "        \n",
    "    else:\n",
    "        model_path = f'{folder}/Trained_models/Stage_by_stage/{training_type}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'{model}_{stage}'] = pickle.load(f)\n",
    "        print(f'Model {model}_{stage}_{current_time} loaded successfully.')\n",
    "        return globals()[f'{model}_{stage}']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd36f332-63af-4dac-9970-6df9713fb387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trainable_model_stage_2024_12_04_12_42_00.pkl\n",
      "STAGE 1: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.0055993665009737015.\n",
      "Objective completed\n",
      "Stage 1 completed in 10.0 trainings.\n",
      "Model trainable_model_stage_1 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\trainable_model_stage_1-2024_12_04_12_42_00.pkl\n",
      "Results of Stage 1 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\Stage_1_results_2024_12_04_12_42_00.txt\n",
      "Loss is NaN.\n",
      "Stage 2 completed in 1.0 trainings.\n",
      "Model trainable_model_stage_2 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\trainable_model_stage_2-2024_12_04_12_42_00.pkl\n",
      "Results of Stage 2 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\Stage_2_results_2024_12_04_12_42_00.txt\n",
      "Loaded trainable_model_stage_2024_12_04_12_42_02.pkl\n",
      "STAGE 1: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.0044752066023647785.\n",
      "Objective completed\n",
      "Stage 1 completed in 10.0 trainings.\n",
      "Model trainable_model_stage_1 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\trainable_model_stage_1-2024_12_04_12_42_02.pkl\n",
      "Results of Stage 1 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\Stage_1_results_2024_12_04_12_42_02.txt\n",
      "STAGE 2: Out of 8000, 2690 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 657 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.12083092331886292.\n",
      "STAGE 2: Out of 8000, 6797 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1683 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.017350908368825912.\n",
      "STAGE 2: Out of 8000, 7117 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1784 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01649591512978077.\n",
      "STAGE 2: Out of 8000, 6910 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1737 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01525951735675335.\n",
      "STAGE 2: Out of 8000, 7031 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1754 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013920371420681477.\n",
      "STAGE 2: Out of 8000, 6910 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1738 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01606745459139347.\n",
      "STAGE 2: Out of 8000, 7068 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1766 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.010910131968557835.\n",
      "STAGE 2: Out of 8000, 7210 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1808 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012126892805099487.\n",
      "STAGE 2: Out of 8000, 7122 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1783 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01355451438575983.\n",
      "STAGE 2: Out of 8000, 7270 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1824 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011900181882083416.\n",
      "STAGE 2: Out of 8000, 7185 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1804 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01251221913844347.\n",
      "STAGE 2: Out of 8000, 7111 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1781 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012547453865408897.\n",
      "STAGE 2: Out of 8000, 7171 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1802 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012504948303103447.\n",
      "STAGE 2: Out of 8000, 7189 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1810 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012141956947743893.\n",
      "STAGE 2: Out of 8000, 7107 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1776 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013106489554047585.\n",
      "STAGE 2: Out of 8000, 7024 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1769 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012387021444737911.\n",
      "STAGE 2: Out of 8000, 6998 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1757 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012917786836624146.\n",
      "STAGE 2: Out of 8000, 7045 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1768 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013331569731235504.\n",
      "STAGE 2: Out of 8000, 6955 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1745 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01321442425251007.\n",
      "STAGE 2: Out of 8000, 7043 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1769 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013290698640048504.\n",
      "STAGE 2: Out of 8000, 7114 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1795 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011819237843155861.\n",
      "STAGE 2: Out of 8000, 7137 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1788 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01245194859802723.\n",
      "STAGE 2: Out of 8000, 7295 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1819 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01232051756232977.\n",
      "STAGE 2: Out of 8000, 6732 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1698 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01415296271443367.\n",
      "STAGE 2: Out of 8000, 7270 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1830 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012083656154572964.\n",
      "STAGE 2: Out of 8000, 7289 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1824 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012613032013177872.\n",
      "STAGE 2: Out of 8000, 6673 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1678 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012306567281484604.\n",
      "STAGE 2: Out of 8000, 7141 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1786 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011682902462780476.\n",
      "STAGE 2: Out of 8000, 7256 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1822 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012156670913100243.\n",
      "STAGE 2: Out of 8000, 6673 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1692 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012021341361105442.\n",
      "STAGE 2: Out of 8000, 7120 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1792 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012460384517908096.\n",
      "STAGE 2: Out of 8000, 7071 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1770 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012751876376569271.\n",
      "STAGE 2: Out of 8000, 7129 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1785 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012430611997842789.\n",
      "STAGE 2: Out of 8000, 7250 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1825 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012348641641438007.\n",
      "STAGE 2: Out of 8000, 7054 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1768 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012058672495186329.\n",
      "STAGE 2: Out of 8000, 7106 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1789 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012925750575959682.\n",
      "STAGE 2: Out of 8000, 7132 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1783 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012069715186953545.\n",
      "STAGE 2: Out of 8000, 7161 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1791 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012481273151934147.\n",
      "STAGE 2: Out of 8000, 7213 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1806 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01321923453360796.\n",
      "STAGE 2: Out of 8000, 7225 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1806 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012520605698227882.\n",
      "STAGE 2: Out of 8000, 6963 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1750 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012422260828316212.\n",
      "STAGE 2: Out of 8000, 7168 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1801 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01181837823241949.\n",
      "STAGE 2: Out of 8000, 7212 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1808 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012649210169911385.\n",
      "STAGE 2: Out of 8000, 7175 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1798 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013768582604825497.\n",
      "STAGE 2: Out of 8000, 7243 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1820 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012220555916428566.\n",
      "STAGE 2: Out of 8000, 7156 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1799 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012532451190054417.\n",
      "STAGE 2: Out of 8000, 7032 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1763 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0112350694835186.\n",
      "STAGE 2: Out of 8000, 6822 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1708 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012450444512069225.\n",
      "STAGE 2: Out of 8000, 7206 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1811 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012492098845541477.\n",
      "STAGE 2: Out of 8000, 7173 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1804 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012367884628474712.\n",
      "STAGE 2: Out of 8000, 7186 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1799 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011706563644111156.\n",
      "STAGE 2: Out of 8000, 7218 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1810 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012700272724032402.\n",
      "STAGE 2: Out of 8000, 7212 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1810 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013782056979835033.\n",
      "STAGE 2: Out of 8000, 6934 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1744 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012122279964387417.\n",
      "STAGE 2: Out of 8000, 7209 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1810 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012892048805952072.\n",
      "STAGE 2: Out of 8000, 7072 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1760 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013057379983365536.\n",
      "STAGE 2: Out of 8000, 7174 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1797 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012801971286535263.\n",
      "STAGE 2: Out of 8000, 7118 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1787 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01296171173453331.\n",
      "STAGE 2: Out of 8000, 7225 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1811 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01252505462616682.\n",
      "STAGE 2: Out of 8000, 7073 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1774 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012293378822505474.\n",
      "STAGE 2: Out of 8000, 7205 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1818 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013253949582576752.\n",
      "STAGE 2: Out of 8000, 7165 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1799 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011704636737704277.\n",
      "STAGE 2: Out of 8000, 6995 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1743 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012320543639361858.\n",
      "STAGE 2: Out of 8000, 7148 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1804 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012601355090737343.\n",
      "STAGE 2: Out of 8000, 7236 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1811 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011471389792859554.\n",
      "STAGE 2: Out of 8000, 7066 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1782 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012752066366374493.\n",
      "STAGE 2: Out of 8000, 7173 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1804 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012594960629940033.\n",
      "STAGE 2: Out of 8000, 7222 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1801 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012574119493365288.\n",
      "STAGE 2: Out of 8000, 7125 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1775 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012063786387443542.\n",
      "STAGE 2: Out of 8000, 7224 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1816 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012853629887104034.\n",
      "STAGE 2: Out of 8000, 7096 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1787 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012905151583254337.\n",
      "STAGE 2: Out of 8000, 7203 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1814 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012551157735288143.\n",
      "STAGE 2: Out of 8000, 7159 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1806 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012439951300621033.\n",
      "STAGE 2: Out of 8000, 7067 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1770 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011827097274363041.\n",
      "STAGE 2: Out of 8000, 7276 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1825 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.014069166965782642.\n",
      "STAGE 2: Out of 8000, 7227 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1814 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012514928355813026.\n",
      "STAGE 2: Out of 8000, 6846 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1715 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012538468465209007.\n",
      "STAGE 2: Out of 8000, 6992 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1749 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01354539580643177.\n",
      "STAGE 2: Out of 8000, 7250 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1825 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01150433998554945.\n",
      "STAGE 2: Out of 8000, 7071 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1773 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011925853788852692.\n",
      "STAGE 2: Out of 8000, 7051 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1769 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011907328851521015.\n",
      "STAGE 2: Out of 8000, 7220 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1808 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013499739579856396.\n",
      "STAGE 2: Out of 8000, 7075 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1776 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013576424680650234.\n",
      "STAGE 2: Out of 8000, 6950 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1748 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012057296931743622.\n",
      "STAGE 2: Out of 8000, 7280 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1819 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0119028864428401.\n",
      "STAGE 2: Out of 8000, 7238 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1813 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013075673021376133.\n",
      "STAGE 2: Out of 8000, 7205 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1803 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012123564258217812.\n",
      "STAGE 2: Out of 8000, 6993 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1757 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012420816347002983.\n",
      "STAGE 2: Out of 8000, 7253 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1814 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01256443839520216.\n",
      "STAGE 2: Out of 8000, 7237 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1818 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011062141507863998.\n",
      "STAGE 2: Out of 8000, 7156 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1795 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012976184487342834.\n",
      "STAGE 2: Out of 8000, 7028 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1771 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011624067090451717.\n",
      "STAGE 2: Out of 8000, 7087 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1770 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011160277761518955.\n",
      "STAGE 2: Out of 8000, 7228 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1813 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011489779688417912.\n",
      "STAGE 2: Out of 8000, 7273 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1824 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012502478435635567.\n",
      "STAGE 2: Out of 8000, 7230 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1803 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012318134307861328.\n",
      "STAGE 2: Out of 8000, 7130 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1793 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012703136540949345.\n",
      "STAGE 2: Out of 8000, 7059 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1766 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012148158624768257.\n",
      "STAGE 2: Out of 8000, 7209 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1809 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011816352605819702.\n",
      "STAGE 2: Out of 8000, 7143 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1780 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011504252441227436.\n",
      "STAGE 2: Out of 8000, 7187 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1804 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011863550171256065.\n",
      "STAGE 2: Out of 8000, 7233 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1819 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013123023323714733.\n",
      "STAGE 2: Out of 8000, 7256 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1818 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012998360209167004.\n",
      "STAGE 2: Out of 8000, 7251 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1824 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011898626573383808.\n",
      "STAGE 2: Out of 8000, 7219 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1814 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012410234659910202.\n",
      "STAGE 2: Out of 8000, 6877 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1723 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012525917030870914.\n",
      "STAGE 2: Out of 8000, 7262 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1814 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011312796734273434.\n",
      "STAGE 2: Out of 8000, 6724 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1697 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012686300091445446.\n",
      "STAGE 2: Out of 8000, 7140 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1790 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01118384674191475.\n",
      "STAGE 2: Out of 8000, 7303 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1836 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011073623783886433.\n",
      "STAGE 2: Out of 8000, 7284 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1828 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012359140440821648.\n",
      "STAGE 2: Out of 8000, 7167 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1794 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01199437864124775.\n",
      "STAGE 2: Out of 8000, 7184 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1805 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012479904107749462.\n",
      "STAGE 2: Out of 8000, 7262 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1812 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012623714283108711.\n",
      "STAGE 2: Out of 8000, 7079 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1770 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011709620244801044.\n",
      "STAGE 2: Out of 8000, 7226 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1822 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011891915462911129.\n",
      "STAGE 2: Out of 8000, 7230 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1814 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011658430099487305.\n",
      "STAGE 2: Out of 8000, 7115 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1774 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011613470502197742.\n",
      "STAGE 2: Out of 8000, 7143 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1801 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012157623656094074.\n",
      "STAGE 2: Out of 8000, 7142 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1793 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01201399601995945.\n",
      "STAGE 2: Out of 8000, 7228 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1809 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0118233822286129.\n",
      "STAGE 2: Out of 8000, 7133 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1794 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012573815882205963.\n",
      "STAGE 2: Out of 8000, 7047 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1774 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012097552418708801.\n",
      "STAGE 2: Out of 8000, 7255 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1817 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011813241988420486.\n",
      "STAGE 2: Out of 8000, 7148 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1793 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012338104657828808.\n",
      "STAGE 2: Out of 8000, 7206 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1813 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011669513769447803.\n",
      "STAGE 2: Out of 8000, 7256 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1823 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01257251389324665.\n",
      "STAGE 2: Out of 8000, 7207 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1807 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01299540139734745.\n",
      "STAGE 2: Out of 8000, 7075 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1772 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012757038697600365.\n",
      "STAGE 2: Out of 8000, 7283 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1816 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011468876153230667.\n",
      "STAGE 2: Out of 8000, 7209 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1809 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013061856850981712.\n",
      "STAGE 2: Out of 8000, 7171 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1803 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011998931877315044.\n",
      "STAGE 2: Out of 8000, 6807 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1713 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01327805407345295.\n",
      "STAGE 2: Out of 8000, 7152 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1794 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012678829953074455.\n",
      "STAGE 2: Out of 8000, 7145 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1802 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01187719963490963.\n",
      "STAGE 2: Out of 8000, 7078 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1758 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013575419783592224.\n",
      "STAGE 2: Out of 8000, 7171 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1794 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011815565638244152.\n",
      "STAGE 2: Out of 8000, 7249 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1822 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011612622998654842.\n",
      "STAGE 2: Out of 8000, 7126 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1790 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012612489052116871.\n",
      "STAGE 2: Out of 8000, 7095 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1778 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011441539041697979.\n",
      "STAGE 2: Out of 8000, 7119 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1792 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012356534600257874.\n",
      "STAGE 2: Out of 8000, 7165 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1803 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012724306434392929.\n",
      "STAGE 2: Out of 8000, 7023 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1757 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011828001588582993.\n",
      "STAGE 2: Out of 8000, 7186 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1807 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012224877253174782.\n",
      "STAGE 2: Out of 8000, 7215 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1817 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012405072338879108.\n",
      "STAGE 2: Out of 8000, 7269 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1813 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011713792569935322.\n",
      "STAGE 2: Out of 8000, 7266 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1822 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01145530492067337.\n",
      "STAGE 2: Out of 8000, 6686 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1688 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012975013814866543.\n",
      "STAGE 2: Out of 8000, 7186 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1798 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.014011790975928307.\n",
      "STAGE 2: Out of 8000, 7200 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1809 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012552263215184212.\n",
      "STAGE 2: Out of 8000, 7147 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1805 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013506066985428333.\n",
      "STAGE 2: Out of 8000, 6916 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1739 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01284564658999443.\n",
      "STAGE 2: Out of 8000, 6883 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1725 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012220731936395168.\n",
      "STAGE 2: Out of 8000, 7245 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1810 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013044063933193684.\n",
      "STAGE 2: Out of 8000, 7015 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1746 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012078753672540188.\n",
      "STAGE 2: Out of 8000, 6667 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1670 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011387400329113007.\n",
      "STAGE 2: Out of 8000, 6396 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1609 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013240493834018707.\n",
      "STAGE 2: Out of 8000, 7068 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1763 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011982003226876259.\n",
      "STAGE 2: Out of 8000, 7096 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1777 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011015500873327255.\n",
      "STAGE 2: Out of 8000, 7085 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1765 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012812419794499874.\n",
      "STAGE 2: Out of 8000, 6924 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1747 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012435649521648884.\n",
      "STAGE 2: Out of 8000, 7078 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1771 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011378873139619827.\n",
      "STAGE 2: Out of 8000, 7283 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1828 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012688398361206055.\n",
      "STAGE 2: Out of 8000, 7192 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1804 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01153858657926321.\n",
      "STAGE 2: Out of 8000, 7079 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1774 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01272500678896904.\n",
      "STAGE 2: Out of 8000, 7168 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1797 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012483766302466393.\n",
      "STAGE 2: Out of 8000, 7107 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1781 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013078422285616398.\n",
      "STAGE 2: Out of 8000, 7185 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1800 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011959872208535671.\n",
      "STAGE 2: Out of 8000, 7090 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1780 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013272793963551521.\n",
      "STAGE 2: Out of 8000, 7184 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1807 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013168448582291603.\n",
      "STAGE 2: Out of 8000, 7053 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1769 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013035225681960583.\n",
      "STAGE 2: Out of 8000, 7235 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1818 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012691729702055454.\n",
      "STAGE 2: Out of 8000, 6960 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1755 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011852899566292763.\n",
      "STAGE 2: Out of 8000, 7069 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1765 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012334238737821579.\n",
      "STAGE 2: Out of 8000, 6920 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1748 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011851754039525986.\n",
      "STAGE 2: Out of 8000, 7132 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1789 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013371497392654419.\n",
      "STAGE 2: Out of 8000, 7171 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1801 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012008818797767162.\n",
      "STAGE 2: Out of 8000, 7078 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1765 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011445209383964539.\n",
      "STAGE 2: Out of 8000, 7005 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1766 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012257268652319908.\n",
      "STAGE 2: Out of 8000, 7145 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1792 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0124356122687459.\n",
      "STAGE 2: Out of 8000, 7037 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1754 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011674351058900356.\n",
      "STAGE 2: Out of 8000, 6802 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1703 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012010043486952782.\n",
      "STAGE 2: Out of 8000, 7126 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1783 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012040027417242527.\n",
      "STAGE 2: Out of 8000, 7225 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1805 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012366934679448605.\n",
      "STAGE 2: Out of 8000, 7248 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1823 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01125931553542614.\n",
      "STAGE 2: Out of 8000, 7207 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1806 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011924974620342255.\n",
      "STAGE 2: Out of 8000, 6838 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1719 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012023763731122017.\n",
      "STAGE 2: Out of 8000, 7162 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1796 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011886345222592354.\n",
      "STAGE 2: Out of 8000, 7237 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1823 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011976881884038448.\n",
      "STAGE 2: Out of 8000, 7203 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1801 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012818118557333946.\n",
      "STAGE 2: Out of 8000, 7240 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1821 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013047546148300171.\n",
      "STAGE 2: Out of 8000, 7258 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1829 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012143914587795734.\n",
      "STAGE 2: Out of 8000, 7123 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1773 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012916700914502144.\n",
      "STAGE 2: Out of 8000, 7123 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1782 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011615096591413021.\n",
      "STAGE 2: Out of 8000, 7234 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1815 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011542283929884434.\n",
      "STAGE 2: Out of 8000, 7190 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1807 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01317095197737217.\n",
      "STAGE 2: Out of 8000, 7170 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1786 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011965479701757431.\n",
      "STAGE 2: Out of 8000, 7214 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1804 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0128707280382514.\n",
      "STAGE 2: Out of 8000, 7104 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1790 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012951523996889591.\n",
      "STAGE 2: Out of 8000, 7203 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1809 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012369685806334019.\n",
      "STAGE 2: Out of 8000, 7160 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1795 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013256457634270191.\n",
      "STAGE 2: Out of 8000, 7006 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1745 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011977068148553371.\n",
      "STAGE 2: Out of 8000, 7021 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1760 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.010747160762548447.\n",
      "STAGE 2: Out of 8000, 7152 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1791 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013024852611124516.\n",
      "STAGE 2: Out of 8000, 7053 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1762 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01246123667806387.\n",
      "STAGE 2: Out of 8000, 7204 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1812 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011204585433006287.\n",
      "STAGE 2: Out of 8000, 7057 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1779 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011726731434464455.\n",
      "STAGE 2: Out of 8000, 7295 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1826 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012377629987895489.\n",
      "STAGE 2: Out of 8000, 7148 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1801 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01171185914427042.\n",
      "STAGE 2: Out of 8000, 6950 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1746 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012336453422904015.\n",
      "STAGE 2: Out of 8000, 7154 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1794 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013121613301336765.\n",
      "STAGE 2: Out of 8000, 7186 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1796 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01187529880553484.\n",
      "STAGE 2: Out of 8000, 7008 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1754 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011072317138314247.\n",
      "STAGE 2: Out of 8000, 6838 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1718 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011904451064765453.\n",
      "STAGE 2: Out of 8000, 7184 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1792 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012241769582033157.\n",
      "STAGE 2: Out of 8000, 6718 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1688 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012605799362063408.\n",
      "STAGE 2: Out of 8000, 6845 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1723 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012643213383853436.\n",
      "STAGE 2: Out of 8000, 6861 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1720 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012861386872828007.\n",
      "STAGE 2: Out of 8000, 7267 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1823 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013354942202568054.\n",
      "STAGE 2: Out of 8000, 7260 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1810 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012632329948246479.\n",
      "STAGE 2: Out of 8000, 6810 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1692 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01270942110568285.\n",
      "STAGE 2: Out of 8000, 7066 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1771 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012696446850895882.\n",
      "STAGE 2: Out of 8000, 6720 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1682 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011922815814614296.\n",
      "STAGE 2: Out of 8000, 7289 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1826 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013761685229837894.\n",
      "STAGE 2: Out of 8000, 7149 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1788 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01199751254171133.\n",
      "STAGE 2: Out of 8000, 7076 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1780 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013001360930502415.\n",
      "STAGE 2: Out of 8000, 7057 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1767 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011489523574709892.\n",
      "STAGE 2: Out of 8000, 6988 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1755 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012614231556653976.\n",
      "STAGE 2: Out of 8000, 7270 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1823 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01185469888150692.\n",
      "STAGE 2: Out of 8000, 7019 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1759 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012255901470780373.\n",
      "STAGE 2: Out of 8000, 7161 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1803 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013355507515370846.\n",
      "STAGE 2: Out of 8000, 7287 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1826 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011843075044453144.\n",
      "STAGE 2: Out of 8000, 7012 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1761 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011655476875603199.\n",
      "STAGE 2: Out of 8000, 7101 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1784 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012093154713511467.\n",
      "STAGE 2: Out of 8000, 7274 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1817 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01285324152559042.\n",
      "STAGE 2: Out of 8000, 7244 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1816 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012217158451676369.\n",
      "STAGE 2: Out of 8000, 6541 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1602 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012181227095425129.\n",
      "STAGE 2: Out of 8000, 7026 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1748 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012880929745733738.\n",
      "STAGE 2: Out of 8000, 6806 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1701 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012759990058839321.\n",
      "STAGE 2: Out of 8000, 7155 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1792 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013392520137131214.\n",
      "STAGE 2: Out of 8000, 7286 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1829 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012734227813780308.\n",
      "STAGE 2: Out of 8000, 7254 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1817 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013431403785943985.\n",
      "STAGE 2: Out of 8000, 7146 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1790 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012266162782907486.\n",
      "STAGE 2: Out of 8000, 7242 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1815 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012880105525255203.\n",
      "STAGE 2: Out of 8000, 7126 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1788 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012262295000255108.\n",
      "STAGE 2: Out of 8000, 7048 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1758 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011758413165807724.\n",
      "STAGE 2: Out of 8000, 7185 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1797 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013020491227507591.\n",
      "STAGE 2: Out of 8000, 7128 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1777 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012703433632850647.\n",
      "STAGE 2: Out of 8000, 7127 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1761 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013699756935238838.\n",
      "STAGE 2: Out of 8000, 7151 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1793 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.011380517855286598.\n",
      "Stage 2 completed in 2500.0 trainings.\n",
      "Model trainable_model_stage_2 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\trainable_model_stage_2-2024_12_04_12_42_02.pkl\n",
      "Results of Stage 2 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\Stage_2_results_2024_12_04_12_42_02.txt\n",
      "Loaded trainable_model_stage_2024_12_04_12_42_04.pkl\n",
      "STAGE 1: Out of 8000, 7999 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.005122448783367872.\n",
      "STAGE 1: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.00024383932759519666.\n",
      "Objective completed\n",
      "Stage 1 completed in 20.0 trainings.\n",
      "Model trainable_model_stage_1 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\trainable_model_stage_1-2024_12_04_12_42_04.pkl\n",
      "Results of Stage 1 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\Stage_1_results_2024_12_04_12_42_04.txt\n",
      "Loss is NaN.\n",
      "Stage 2 completed in 1.0 trainings.\n",
      "Model trainable_model_stage_2 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\trainable_model_stage_2-2024_12_04_12_42_04.pkl\n",
      "Results of Stage 2 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\Stage_2_results_2024_12_04_12_42_04.txt\n",
      "Loaded trainable_model_stage_2024_12_04_12_42_06.pkl\n",
      "STAGE 1: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.005149922799319029.\n",
      "Objective completed\n",
      "Stage 1 completed in 10.0 trainings.\n",
      "Model trainable_model_stage_1 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\trainable_model_stage_1-2024_12_04_12_42_06.pkl\n",
      "Results of Stage 1 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\Stage_1_results_2024_12_04_12_42_06.txt\n",
      "Loss is NaN.\n",
      "Stage 2 completed in 1.0 trainings.\n",
      "Model trainable_model_stage_2 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\trainable_model_stage_2-2024_12_04_12_42_06.pkl\n",
      "Results of Stage 2 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\Stage_2_results_2024_12_04_12_42_06.txt\n",
      "Loaded trainable_model_stage_2024_12_04_12_42_08.pkl\n",
      "STAGE 1: Out of 8000, 7996 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.0064774188213050365.\n",
      "STAGE 1: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.0007695896783843637.\n",
      "Objective completed\n",
      "Stage 1 completed in 20.0 trainings.\n",
      "Model trainable_model_stage_1 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\trainable_model_stage_1-2024_12_04_12_42_08.pkl\n",
      "Results of Stage 1 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_1\\Stage_1_results_2024_12_04_12_42_08.txt\n",
      "Loss is NaN.\n",
      "Stage 2 completed in 1.0 trainings.\n",
      "Model trainable_model_stage_2 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\trainable_model_stage_2-2024_12_04_12_42_08.pkl\n",
      "Results of Stage 2 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Stage_by_stage/AP_0.1_0.1/Stage_2\\Stage_2_results_2024_12_04_12_42_08.txt\n"
     ]
    }
   ],
   "source": [
    "model = 'trainable_model_stage'\n",
    "training_type = 'AP_0.1_0.1'\n",
    "\n",
    "folder = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "folder_path = f'{folder}/Parameters/{training_type}'\n",
    "date_pattern = r'trainable_model_stage_(\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}).pkl'\n",
    "files = sorted(\n",
    "    (f for f in os.listdir(folder_path) if not f.startswith('.')),  # Filtrar archivos ocultos\n",
    "    key=lambda x: re.search(date_pattern, x).group(1) if re.search(date_pattern, x) else ''\n",
    ")\n",
    "\n",
    "for filename in files:\n",
    "    match = re.search(date_pattern, filename)\n",
    "    if match:\n",
    "        current_time = match.group(1)\n",
    "    else:\n",
    "        print('Error')\n",
    "        break\n",
    "    \n",
    "    file_path = f\"{folder_path}/{model}_{current_time}.pkl\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        trainable_model = pickle.load(file)\n",
    "\n",
    "    print(f'Loaded {model}_{current_time}.pkl')\n",
    "    \n",
    "    training_stages = 3\n",
    "    trainings_needed = np.zeros(training_stages)    \n",
    "    visualizer = 10\n",
    "    lr_changer = 250\n",
    "    stage_changer = 2500\n",
    "    N = 500\n",
    "\n",
    "    for stage in range(1,3):\n",
    "        if stage == 1:\n",
    "            trainable_model_stage_1 = [trainable_model[0],\n",
    "                                       trainable_model[1],\n",
    "                                       trainable_model[2],\n",
    "                                       trainable_model[3],\n",
    "                                       trainable_model[4],\n",
    "                                       trainable_model[5],\n",
    "                                       trainable_model[6],\n",
    "                                       trainable_model[7],\n",
    "                                       trainable_model[8],\n",
    "                                       trainable_model[9],\n",
    "                                       trainable_model[10],\n",
    "                                       trainable_model[11],\n",
    "                                       trainable_model[12]]\n",
    "        elif stage == 2:\n",
    "            trainable_model_stage_2 = [trainable_model_stage_1[0], \n",
    "                                       trainable_model_stage_1[1], \n",
    "                                       trainable_model_stage_1[2], \n",
    "                                       trainable_model_stage_1[3], \n",
    "                                       trainable_model_stage_1[4], \n",
    "                                       trainable_model_stage_1[5], \n",
    "                                       trainable_model_stage_1[6], \n",
    "                                       trainable_model_stage_1[7], \n",
    "                                       trainable_model_stage_1[8], \n",
    "                                       trainable_model_stage_1[9], \n",
    "                                       trainable_model_stage_1[10],\n",
    "                                       trainable_model_stage_1[11],\n",
    "                                       trainable_model_stage_1[12],\n",
    "                                       trainable_model[13], \n",
    "                                       trainable_model[14]]\n",
    "        \n",
    "        save_dir = f\"{folder}/Trained_models/Stage_by_stage/{training_type}/Stage_{stage}\" \n",
    "        os.makedirs(save_dir, exist_ok=True) \n",
    "        results_file = os.path.join(save_dir, f\"Stage_{stage}_results_{current_time}.txt\") \n",
    "        tee = Tee(results_file, 'w') \n",
    "        sys.stdout = tee\n",
    "    \n",
    "        try:\n",
    "            test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "            final_loss = 1\n",
    "            lr = 0.01\n",
    "            level = -2\n",
    "            response = \"yes\"\n",
    "            while final_loss != 0:\n",
    "                prev_model = globals()[f\"{model}_{stage}\"]\n",
    "                globals()[f\"{model}_{stage}\"], final_loss = train_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage, level=level, lr=lr, epochs=N)\n",
    "                trainings_needed[stage-1] += 1\n",
    "                if math.isnan(final_loss):\n",
    "                    globals()[f\"{model}_{stage}\"] = prev_model\n",
    "                    print('Loss is NaN.')\n",
    "                    break                \n",
    "                if trainings_needed[stage-1] % visualizer == 0:\n",
    "                    if response.lower() == \"yes\":\n",
    "                        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "                        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "                        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "                    elif response.lower() == \"no\":\n",
    "                        print(f\"STAGE {stage}: Objective completed, all are predicted correctly in the current model.\")\n",
    "                    print(f\"STAGE {stage}: Loss is {final_loss}.\")\n",
    "                #if trainings_needed[stage-1] % lr_changer == 0:\n",
    "                #    new_lr = input(f\"Change of learning rate? (Current one is {lr}, press enter if not): \")\n",
    "                #    if new_lr != \"\":\n",
    "                #        lr = float(new_lr)\n",
    "                if trainings_needed[stage-1] % stage_changer == 0:\n",
    "                    response_pre = 'yes'\n",
    "                    if response_pre.lower() == \"yes\":\n",
    "                        break\n",
    "                if correct_predictions_trained_count == train_size:\n",
    "                    response = \"yes\"\n",
    "                    while response.lower() not in [\"yes\", \"no\"]:\n",
    "                        response = input(\"Objective completed, skip to next stage? (yes/no): \")\n",
    "                        if response.lower() not in [\"yes\", \"no\"]:\n",
    "                            print('Incorrect answer')        \n",
    "                    if response.lower() == \"yes\":\n",
    "                        print('Objective completed')\n",
    "                        break\n",
    "                    elif response.lower() == \"no\":\n",
    "                        train_size = correct_predictions_trained_count + 1\n",
    "    \n",
    "            print(f'Stage {stage} completed in {trainings_needed[stage-1]} trainings.')\n",
    "            save_response = 'yes'\n",
    "            if save_response.lower() == 'yes':\n",
    "                save_path = os.path.join(save_dir, f\"trainable_model_stage_{stage}-{current_time}.pkl\")\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    pickle.dump(globals()[f\"{model}_{stage}\"], f)\n",
    "                print(f\"Model trainable_model_stage_{stage} saved at {save_path}\")\n",
    "\n",
    "        finally:\n",
    "            sys.stdout = tee.console\n",
    "            tee.close()\n",
    "        print(f\"Results of Stage {stage} saved in {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740eb898-649f-4cff-b15a-5138580f97ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
