{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711e908c-a200-4499-a72c-e7d32a573bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad\n",
    "from jax.nn import relu, sigmoid\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pytz\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb56570c-4104-46b7-8925-2cbdbfdebb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random_weights(mean, std, shape = ()):\n",
    "    return np.random.normal(loc=mean, scale=std, size=shape)\n",
    "\n",
    "# We use a sinusoidal function to approximate odd numbers by their immediately preceding even number and preserve differentiability\n",
    "def lower_even(x):\n",
    "    return x - 0.5 * (1 - jnp.cos(jnp.pi * x))\n",
    "\n",
    "# We use a sinusoidal function to approximate 0 for evens and 1 for odds while preserving differentiability\n",
    "def differentiable_even_or_odd(x):\n",
    "    return ((2 * x ** 3) / 3) - 3 * x ** 2 + ((10 * x) / 3)\n",
    "\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "\n",
    "# Cargar las parejas desde el archivo\n",
    "with open(f\"{folder}/train_couples.txt\", \"r\") as file:\n",
    "    train_couples = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_with_carry_over.txt\", \"r\") as file:\n",
    "    combinations_with_carry_over = eval(file.read())  # Leer y convertir el contenido en una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset.txt\", 'r') as file:\n",
    "    real_test_dataset = eval(file.read())  # Convertir el contenido del archivo a una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/test_dataset.txt\", 'r') as file:\n",
    "    test_dataset = eval(file.read())  # Convertir el contenido del archivo a una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/combinations_small_problem_size.txt\", 'r') as file:\n",
    "    combinations_small_problem_size = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_small_problem_size_binary.txt\", 'r') as file:\n",
    "    combinations_small_problem_size_binary = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_with_carry_over_decimal.txt\", 'r') as file:\n",
    "    combinations_with_carry_over_decimal = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_small_problem_size.txt\", 'r') as file:\n",
    "    real_test_dataset_small_problem_size = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_small_problem_size_binary.txt\", 'r') as file:\n",
    "    real_test_dataset_small_problem_size_binary = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_with_carry_over.txt\", 'r') as file:\n",
    "    real_test_dataset_with_carry_over = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_with_carry_over_decimal.txt\", 'r') as file:\n",
    "    real_test_dataset_with_carry_over_decimal = eval(file.read())\n",
    "    \n",
    "\n",
    "# Separar parejas con y sin ceros\n",
    "train_without_zeros = [pair for pair in train_couples if 0 not in pair]\n",
    "train_with_carry_over = [pair for pair in train_couples if pair in combinations_with_carry_over]\n",
    "train_with_carry_over_decimal = [pair for pair in train_couples if pair in combinations_with_carry_over_decimal]\n",
    "\n",
    "# Function to generate dataset with multiplication\n",
    "def generate_dataset_with_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas con ceros\n",
    "    selected_pairs = random.choices(train_couples, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_without_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas sin ceros\n",
    "    selected_pairs = random.choices(train_without_zeros, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_test_dataset(n_max=100):\n",
    "    # Create the columns\n",
    "    column_1 = list(range(n_max)) * n_max  # Numbers from 0 to 9 repeated 10 times\n",
    "    column_2 = [i for i in range(n_max) for _ in range(n_max)]  # Numbers from 0 to 9 repeated sequentially 10 times\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_real_test_dataset():\n",
    "    # Desempaquetar las parejas (a_i, b_i)\n",
    "    column_1, column_2 = zip(*real_test_dataset)\n",
    "    #column_1, column_2 = zip(*test_dataset)\n",
    "    \n",
    "    # Crear un DataFrame con las dos primeras columnas\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna como la suma de las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def decimal_to_binary(n, bits):\n",
    "    if 0 <= n < 2**bits:\n",
    "        # Convert the number to a binary string and then to an array of integers (0 and 1)\n",
    "        return np.array(list(format(n, f'0{bits}b'))).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(\"Number out of range\")\n",
    "\n",
    "# Function to convert binary number to decimal\n",
    "def binary_to_decimal(binary_vector, bits):\n",
    "    # Ensure the vector has the correct number of elements\n",
    "    if len(binary_vector) != bits:\n",
    "        raise ValueError(f\"The vector must have exactly {bits} elements.\")\n",
    "\n",
    "    # Calculate the decimal number\n",
    "    decimal = 0\n",
    "    for i in range(bits):\n",
    "        decimal += binary_vector[i] * (2 ** (bits - 1 - i))\n",
    "\n",
    "    return decimal\n",
    "\n",
    "def transform_to_tridimensional_matrix(dataset, bits_init=7, bits_end=8):\n",
    "    rows, cols = dataset.shape\n",
    "    if cols != 3:\n",
    "        raise ValueError(\"The dataset must have exactly 3 columns.\")\n",
    "\n",
    "    # Initialize the three matrices\n",
    "    matrix_column_1 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_2 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_3 = np.zeros((rows, bits_end), dtype=np.int8)\n",
    "\n",
    "    # Fill the matrices with the binary representation of each column\n",
    "    for i in range(rows):\n",
    "        matrix_column_1[i] = decimal_to_binary(dataset.iloc[i, 0], bits_init)\n",
    "        matrix_column_2[i] = decimal_to_binary(dataset.iloc[i, 1], bits_init)\n",
    "        matrix_column_3[i] = decimal_to_binary(dataset.iloc[i, 2], bits_end)\n",
    "\n",
    "    return matrix_column_1, matrix_column_2, matrix_column_3\n",
    "    \n",
    "def prepare_dataset(level, size=1, couples_included=[]):       \n",
    "    if level == -3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = couples_included\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == -2:\n",
    "        dataset = generate_dataset_with_zeros(size)\n",
    "        return dataset\n",
    "        \n",
    "    elif level == -1:\n",
    "        dataset = generate_dataset_without_zeros(size)\n",
    "        return dataset\n",
    "\n",
    "    elif level == 0:\n",
    "        dataset = pd.DataFrame()\n",
    "        while len(dataset) < size:\n",
    "            column_1 = np.random.randint(1, 10, size)\n",
    "            column_2 = np.random.randint(1, 10, size)\n",
    "            temp_dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "            temp_dataset = temp_dataset[~temp_dataset[['Column_1', 'Column_2']].apply(tuple, axis=1).isin(combinations_with_carry_over)]\n",
    "            dataset = pd.concat([dataset, temp_dataset])\n",
    "        dataset = dataset.iloc[:size].reset_index(drop=True)\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 1:\n",
    "        pairs = random.choices(train_with_carry_over, k=size)\n",
    "        column_1 = [pair[0] for pair in pairs]\n",
    "        column_2 = [pair[1] for pair in pairs]\n",
    "        dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "        dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "def prepare_outputs(stage, x1, x2, outputs_prev):\n",
    "    if stage == 1:\n",
    "        outputs = []\n",
    "        for vec1, vec2 in zip(x1, x2):\n",
    "            z2 = lower_even(vec1[6] + vec2[6])\n",
    "            z3 = lower_even(vec1[5] + vec2[5] + z2 * 1/2)\n",
    "            z4 = lower_even(vec1[4] + vec2[4] + z3 * 1/2)\n",
    "            z5 = lower_even(vec1[3] + vec2[3] + z4 * 1/2)\n",
    "            z6 = lower_even(vec1[2] + vec2[2] + z5 * 1/2)\n",
    "            z7 = lower_even(vec1[1] + vec2[1] + z6 * 1/2)\n",
    "            z8 = lower_even(vec1[0] + vec2[0] + z7 * 1/2)\n",
    "            outputs.append([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "        return np.array(outputs)\n",
    "\n",
    "    elif stage == 2:\n",
    "        return outputs_prev\n",
    "        \n",
    "    elif stage == 3:\n",
    "        return outputs_prev\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "# Perfect parameters needed for the stages where a part of the NN performs perfectly\n",
    "# R vectors of dimension (14,1)\n",
    "R2_perfect = np.zeros((14))\n",
    "R3_perfect = np.zeros((14))\n",
    "R4_perfect = np.zeros((14))\n",
    "R5_perfect = np.zeros((14))\n",
    "R6_perfect = np.zeros((14))\n",
    "R7_perfect = np.zeros((14))\n",
    "R8_perfect = np.zeros((14))\n",
    "\n",
    "for i in range(2):\n",
    "    R2_perfect[7*i + 6] = 1\n",
    "    R3_perfect[7*i + 5] = 1\n",
    "    R4_perfect[7*i + 4] = 1\n",
    "    R5_perfect[7*i + 3] = 1\n",
    "    R6_perfect[7*i + 2] = 1\n",
    "    R7_perfect[7*i + 1] = 1\n",
    "    R8_perfect[7*i + 0] = 1\n",
    "\n",
    "# Scalar parameters v\n",
    "v2_perfect = 1/2\n",
    "v3_perfect = 1/2\n",
    "v4_perfect = 1/2\n",
    "v5_perfect = 1/2\n",
    "v6_perfect = 1/2\n",
    "v7_perfect = 1/2\n",
    "\n",
    "# Matrix T of dimension (28,7)\n",
    "T_perfect = np.zeros((14,8))\n",
    "for i in range(7):\n",
    "    for j in range(2):\n",
    "        T_perfect[7*j + i, i + 1] = 1\n",
    "\n",
    "# Parameter v\n",
    "v_perfect = 1/2\n",
    "\n",
    "# Neural network in every stage\n",
    "def neural_network_1(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    #y = differentiable_even_or_odd(relu(jnp.dot(vec, T) + jnp.dot(z, v7)))\n",
    "    return z\n",
    "\n",
    "def neural_network_2(params, x1, x2):\n",
    "    T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2_perfect)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3_perfect) + jnp.dot(z2, v2_perfect)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4_perfect) + jnp.dot(z3, v3_perfect)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5_perfect) + jnp.dot(z4, v4_perfect)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6_perfect) + jnp.dot(z5, v5_perfect)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7_perfect) + jnp.dot(z6, v6_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8_perfect) + jnp.dot(z7, v7_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "    \n",
    "def neural_network_3(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "\n",
    "# Loss functions in every stage\n",
    "def loss_1(params, x1, x2, y):\n",
    "    pred = neural_network_1(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_2(params, x1, x2, y):\n",
    "    pred = neural_network_2(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_3(params, x1, x2, y):\n",
    "    pred = neural_network_3(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "# Loss functions in every step\n",
    "@jax.jit\n",
    "def update_params_1(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_1)(params, x1, x2, y)\n",
    "    step_loss = loss_1(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_2(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_2)(params, x1, x2, y)\n",
    "    step_loss = loss_2(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "    \n",
    "@jax.jit\n",
    "def update_params_3(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_3)(params, x1, x2, y)\n",
    "    step_loss = loss_3(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "def decide_training(params, x1, x2, y, lr, stage):\n",
    "    if stage == 1:\n",
    "        params, step_loss = update_params_1(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 2:\n",
    "        params, step_loss = update_params_2(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "        \n",
    "    elif stage == 3:\n",
    "        params, step_loss = update_params_3(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "        \n",
    "# Main function to train the network\n",
    "def train_stages_neural_network(params, stage, level, lr=0.01, epochs=100):\n",
    "    decimal_dataset = prepare_dataset(level, epochs)\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    final_loss = 0\n",
    "    # Train the network\n",
    "    for epoch in range(epochs):\n",
    "        # Update parameters at each step\n",
    "        params, step_loss = decide_training(params, inputs_1[epoch], inputs_2[epoch], outputs[epoch], lr, stage)\n",
    "        final_loss += step_loss\n",
    "\n",
    "    final_loss = final_loss / epochs\n",
    "    #print(f\"Loss: {final_loss:.6f}\")\n",
    "    return params, final_loss\n",
    "\n",
    "\n",
    "\n",
    "def decide_test(params, stage, real_test=0, visualize_errors=0):\n",
    "    if real_test == 1:\n",
    "        test_count, correct_predictions_test_count, train_count, correct_predictions_train_count, test_carry_over_count, correct_carry_over_predictions_test_count, train_carry_over_count, correct_carry_over_predictions_train_count, small_train_count, correct_predictions_small_train_count, small_test_count, correct_predictions_small_test_count, small_train_carry_count, correct_predictions_small_train_carry_count, small_test_carry_count, correct_predictions_small_test_carry_count, test_carry_over_decimal_count, correct_carry_over_decimal_predictions_test_count, train_carry_over_decimal_count, correct_carry_over_decimal_predictions_train_count, small_train_carry_decimal_count, correct_predictions_small_train_carry_decimal_count, small_test_carry_decimal_count, correct_predictions_small_test_carry_decimal_count, small_binary_train_count, correct_predictions_small_binary_train_count, small_binary_test_count, correct_predictions_small_binary_test_count, small_binary_train_carry_count, correct_predictions_small_binary_train_carry_count, small_binary_test_carry_count, correct_predictions_small_binary_test_carry_count, small_binary_train_carry_decimal_count, correct_predictions_small_binary_train_carry_decimal_count, small_binary_test_carry_decimal_count, correct_predictions_small_binary_test_carry_decimal_count, reaction_time_carry, reaction_time_carry_decimal, reaction_time_train,reaction_time_test, reaction_time_train_carry, reaction_time_train_carry_decimal, reaction_time_small_train, reaction_time_small_test, reaction_time_small_train_carry, reaction_time_small_test_carry, reaction_time_small_train_carry_decimal, reaction_time_small_test_carry_decimal, reaction_time_small_binary_train, reaction_time_small_binary_test, reaction_time_small_binary_train_carry, reaction_time_small_binary_test_carry, reaction_time_small_binary_train_carry_decimal, reaction_time_small_binary_test_carry_decimal = real_test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_count}, {correct_predictions_train_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_count}, {correct_predictions_test_count} tested were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {train_carry_over_count}, {correct_carry_over_predictions_train_count} trained with carry-over were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {test_carry_over_count}, {correct_carry_over_predictions_test_count} tested with carry-over were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_train_count}, {correct_predictions_small_train_count} trained with small problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_test_count}, {correct_predictions_small_test_count} tested with small problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_train_carry_count}, {correct_predictions_small_train_carry_count} trained with small problem size and with carry-over were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_test_carry_count}, {correct_predictions_small_test_carry_count} tested with small problem size and with carry-over were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {train_carry_over_decimal_count}, {correct_carry_over_decimal_predictions_train_count} trained with carry-over decimal were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {test_carry_over_decimal_count}, {correct_carry_over_decimal_predictions_test_count} tested with carry-over decimal were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_train_carry_decimal_count}, {correct_predictions_small_train_carry_decimal_count} trained with small problem size and with carry-over decimal were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_test_carry_decimal_count}, {correct_predictions_small_test_carry_decimal_count} tested with small problem size and with carry-over decimal were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_train_count}, {correct_predictions_small_binary_train_count} trained with small binary problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_test_count}, {correct_predictions_small_binary_test_count} tested with small binary problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_train_carry_count}, {correct_predictions_small_binary_train_carry_count} trained with small binary problem size and with carry-over were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_binary_test_carry_count}, {correct_predictions_small_binary_test_carry_count} tested with small binary problem size and with carry-over were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_train_carry_decimal_count}, {correct_predictions_small_binary_train_carry_decimal_count} trained with small binary problem size and with carry-over decimal were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_binary_test_carry_decimal_count}, {correct_predictions_small_binary_test_carry_decimal_count} tested with small binary problem size and with carry-over decimal were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_carry} reaction time with carry over.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_carry_decimal} reaction time with carry over decimal.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_train} reaction time for train.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_test} reaction time for test.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_train_carry} reaction time for train with carry over .\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_train_carry_decimal} reaction time for train with carry over decimal.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_train} reaction time for train small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_test} reaction time for test small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_train_carry} reaction time for train with carry over and small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_test_carry} reaction time for test with carry over and small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_train_carry_decimal} reaction time for train with carry over decimal and small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_test_carry_decimal} reaction time for test with carry over decimal and small.\") \n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_train} reaction time for train small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_test} reaction time for test small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_train_carry} reaction time for train with carry over and small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_test_carry} reaction time for test with carry over and small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_train_carry_decimal} reaction time for train with carry over decimal and small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_test_carry_decimal} reaction time for test with carry over decimal and small binary.\") \n",
    "            \n",
    "    else: \n",
    "        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "        \n",
    "\n",
    "# Main function to test the network\n",
    "def test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_test_dataset()\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    \n",
    "    correct_predictions_tested_count = 0\n",
    "    correct_predictions_trained_count = 0  # Counter for trained couples\n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_size = len(train_couples)\n",
    "    test_size = set_size - train_size\n",
    "    \n",
    "    for i in range(set_size):\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        # Check if the prediction matches the expected output\n",
    "        if jnp.all(prediction == outputs[i]):  \n",
    "            if (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1]) in train_couples:\n",
    "                correct_predictions_trained_count += 1  # Increment for trained couples\n",
    "            else:\n",
    "                correct_predictions_tested_count += 1 # Increment for tested couples\n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{decimal_dataset.iloc[i, 0]} plus {decimal_dataset.iloc[i, 1]} has failed.')\n",
    "\n",
    "    return test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count\n",
    "\n",
    "def real_test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_real_test_dataset()    \n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    \n",
    "    correct_predictions_test_count = 0\n",
    "    correct_predictions_train_count = 0\n",
    "    correct_carry_over_predictions_count = 0\n",
    "    correct_carry_over_predictions_test_count = 0\n",
    "    correct_carry_over_predictions_train_count = 0\n",
    "    correct_predictions_small_train_count = 0\n",
    "    correct_predictions_small_test_count = 0\n",
    "    correct_predictions_small_train_carry_count = 0\n",
    "    correct_predictions_small_test_carry_count = 0\n",
    "    correct_carry_over_decimal_predictions_count = 0\n",
    "    correct_carry_over_decimal_predictions_test_count = 0\n",
    "    correct_carry_over_decimal_predictions_train_count = 0\n",
    "    correct_predictions_small_train_carry_decimal_count = 0\n",
    "    correct_predictions_small_test_carry_decimal_count = 0\n",
    "    correct_predictions_small_binary_train_count = 0\n",
    "    correct_predictions_small_binary_test_count = 0\n",
    "    correct_predictions_small_binary_train_carry_count = 0\n",
    "    correct_predictions_small_binary_test_carry_count = 0\n",
    "    correct_predictions_small_binary_train_carry_decimal_count = 0\n",
    "    correct_predictions_small_binary_test_carry_decimal_count = 0\n",
    "    \n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_count = len(train_couples)\n",
    "    test_count = set_size - train_count\n",
    "    carry_over_count = len(combinations_with_carry_over) \n",
    "    carry_over_decimal_count = len(combinations_with_carry_over_decimal) \n",
    "    train_carry_over_count = len(train_with_carry_over)\n",
    "    test_carry_over_count = carry_over_count - train_carry_over_count\n",
    "    small_count = len(combinations_small_problem_size)\n",
    "    small_binary_count = len(combinations_small_problem_size_binary)\n",
    "    train_carry_over_decimal_count = len(train_with_carry_over_decimal)\n",
    "    test_carry_over_decimal_count = carry_over_decimal_count - train_carry_over_decimal_count\n",
    "\n",
    "    # Contadores adicionales\n",
    "    small_train_count = 0\n",
    "    small_test_count = 0\n",
    "    small_train_carry_count = 0\n",
    "    small_test_carry_count = 0\n",
    "    small_train_carry_decimal_count = 0\n",
    "    small_test_carry_decimal_count = 0\n",
    "    small_binary_train_count = 0\n",
    "    small_binary_test_count = 0\n",
    "    small_binary_train_carry_count = 0\n",
    "    small_binary_test_carry_count = 0\n",
    "    small_binary_train_carry_decimal_count = 0\n",
    "    small_binary_test_carry_decimal_count = 0\n",
    "    \n",
    "    reaction_time_carry = 0\n",
    "    reaction_time_carry_decimal = 0\n",
    "    reaction_time_train = 0\n",
    "    reaction_time_test = 0\n",
    "    reaction_time_train_carry = 0\n",
    "    reaction_time_train_carry_decimal = 0\n",
    "    reaction_time_small_train = 0\n",
    "    reaction_time_small_test = 0\n",
    "    reaction_time_small_train_carry = 0\n",
    "    reaction_time_small_test_carry = 0\n",
    "    reaction_time_small_train_carry_decimal = 0\n",
    "    reaction_time_small_test_carry_decimal = 0\n",
    "    reaction_time_small_binary_train = 0\n",
    "    reaction_time_small_binary_test = 0\n",
    "    reaction_time_small_binary_train_carry = 0\n",
    "    reaction_time_small_binary_test_carry = 0\n",
    "    reaction_time_small_binary_train_carry_decimal = 0\n",
    "    reaction_time_small_binary_test_carry_decimal = 0\n",
    "\n",
    "    for i in range(set_size):\n",
    "        pair = (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1])\n",
    "\n",
    "        start_time = time.perf_counter_ns()\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        elapsed_time = time.perf_counter_ns() - start_time\n",
    "\n",
    "        #is_small = pair in combinations_small_problem_size\n",
    "        #is_small_binary = pair in combinations_small_problem_size_binary\n",
    "        #is_train = pair in train_couples\n",
    "        #is_carry = pair in combinations_with_carry_over\n",
    "        #is_carry_decimal = pair in combinations_with_carry_over_decimal\n",
    "\n",
    "        is_small = pair in real_test_dataset_small_problem_size\n",
    "        is_small_binary = pair in real_test_dataset_small_problem_size_binary\n",
    "        is_train = pair in train_couples\n",
    "        is_carry = pair in real_test_dataset_with_carry_over\n",
    "        is_carry_decimal = pair in real_test_dataset_with_carry_over_decimal\n",
    "\n",
    "        # Actualizar tiempos de reacción y contadores totales\n",
    "        if is_small:\n",
    "            if is_train:\n",
    "                small_train_count += 1\n",
    "                reaction_time_small_train += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_train_carry_count += 1\n",
    "                    reaction_time_small_train_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_train_carry_decimal_count += 1\n",
    "                    reaction_time_small_train_carry_decimal += elapsed_time\n",
    "            else:\n",
    "                small_test_count += 1\n",
    "                reaction_time_small_test += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_test_carry_count += 1\n",
    "                    reaction_time_small_test_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_test_carry_decimal_count += 1\n",
    "                    reaction_time_small_test_carry_decimal += elapsed_time\n",
    "\n",
    "        # Actualizar tiempos de reacción y contadores totales\n",
    "        if is_small_binary:\n",
    "            if is_train:\n",
    "                small_binary_train_count += 1\n",
    "                reaction_time_small_binary_train += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_binary_train_carry_count += 1\n",
    "                    reaction_time_small_binary_train_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_binary_train_carry_decimal_count += 1\n",
    "                    reaction_time_small_binary_train_carry_decimal += elapsed_time\n",
    "            else:\n",
    "                small_binary_test_count += 1\n",
    "                reaction_time_small_binary_test += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_binary_test_carry_count += 1\n",
    "                    reaction_time_small_binary_test_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_binary_test_carry_decimal_count += 1\n",
    "                    reaction_time_small_binary_test_carry_decimal += elapsed_time\n",
    "\n",
    "        if is_carry:\n",
    "            reaction_time_carry += elapsed_time\n",
    "        if is_carry_decimal:\n",
    "            reaction_time_carry_decimal += elapsed_time\n",
    "        if is_train:\n",
    "            reaction_time_train += elapsed_time\n",
    "        else:\n",
    "            reaction_time_test += elapsed_time\n",
    "        if is_train and is_carry:\n",
    "            reaction_time_train_carry += elapsed_time\n",
    "        if is_train and is_carry_decimal:\n",
    "            reaction_time_train_carry_decimal += elapsed_time\n",
    "\n",
    "        # Contar predicciones correctas\n",
    "        if jnp.all(prediction == outputs[i]):\n",
    "            if is_small:\n",
    "                if is_train:\n",
    "                    correct_predictions_small_train_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_train_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_train_carry_decimal_count += 1\n",
    "                else:\n",
    "                    correct_predictions_small_test_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_test_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_test_carry_decimal_count += 1\n",
    "\n",
    "            if is_small_binary:\n",
    "                if is_train:\n",
    "                    correct_predictions_small_binary_train_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_binary_train_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_binary_train_carry_decimal_count += 1\n",
    "                else:\n",
    "                    correct_predictions_small_binary_test_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_binary_test_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_binary_test_carry_decimal_count += 1\n",
    "\n",
    "            # Actualizar contadores previos\n",
    "            if is_carry:\n",
    "                correct_carry_over_predictions_count += 1 \n",
    "            if is_carry_decimal:\n",
    "                correct_carry_over_decimal_predictions_count += 1 \n",
    "            if is_train:\n",
    "                correct_predictions_train_count += 1 \n",
    "            else:\n",
    "                correct_predictions_test_count += 1\n",
    "            if is_train and is_carry:\n",
    "                correct_carry_over_predictions_train_count += 1   \n",
    "            if is_train and is_carry_decimal:\n",
    "                correct_carry_over_decimal_predictions_train_count += 1 \n",
    "                \n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{pair[0]} plus {pair[1]} has failed.')\n",
    "\n",
    "    correct_carry_over_predictions_test_count = correct_carry_over_predictions_count - correct_carry_over_predictions_train_count\n",
    "    correct_carry_over_decimal_predictions_test_count = correct_carry_over_decimal_predictions_count - correct_carry_over_decimal_predictions_train_count\n",
    "    \n",
    "    return (\n",
    "        test_count,\n",
    "        correct_predictions_test_count,\n",
    "        train_count,\n",
    "        correct_predictions_train_count,\n",
    "        test_carry_over_count,\n",
    "        correct_carry_over_predictions_test_count,\n",
    "        train_carry_over_count,\n",
    "        correct_carry_over_predictions_train_count,\n",
    "        small_train_count,\n",
    "        correct_predictions_small_train_count,\n",
    "        small_test_count,\n",
    "        correct_predictions_small_test_count,\n",
    "        small_train_carry_count,\n",
    "        correct_predictions_small_train_carry_count,\n",
    "        small_test_carry_count,\n",
    "        correct_predictions_small_test_carry_count,\n",
    "        test_carry_over_decimal_count,\n",
    "        correct_carry_over_decimal_predictions_test_count,\n",
    "        train_carry_over_decimal_count,\n",
    "        correct_carry_over_decimal_predictions_train_count,\n",
    "        small_train_carry_decimal_count,\n",
    "        correct_predictions_small_train_carry_decimal_count,\n",
    "        small_test_carry_decimal_count,\n",
    "        correct_predictions_small_test_carry_decimal_count,\n",
    "        small_binary_train_count,\n",
    "        correct_predictions_small_binary_train_count,\n",
    "        small_binary_test_count,\n",
    "        correct_predictions_small_binary_test_count,\n",
    "        small_binary_train_carry_count,\n",
    "        correct_predictions_small_binary_train_carry_count,\n",
    "        small_binary_test_carry_count,\n",
    "        correct_predictions_small_binary_test_carry_count,\n",
    "        small_binary_train_carry_decimal_count,\n",
    "        correct_predictions_small_binary_train_carry_decimal_count,\n",
    "        small_binary_test_carry_decimal_count,\n",
    "        correct_predictions_small_binary_test_carry_decimal_count,\n",
    "        reaction_time_carry,\n",
    "        reaction_time_carry_decimal,\n",
    "        reaction_time_train,\n",
    "        reaction_time_test,\n",
    "        reaction_time_train_carry,\n",
    "        reaction_time_train_carry_decimal,\n",
    "        reaction_time_small_train,\n",
    "        reaction_time_small_test,\n",
    "        reaction_time_small_train_carry,\n",
    "        reaction_time_small_test_carry,\n",
    "        reaction_time_small_train_carry_decimal,\n",
    "        reaction_time_small_test_carry_decimal,\n",
    "        reaction_time_small_binary_train,\n",
    "        reaction_time_small_binary_test,\n",
    "        reaction_time_small_binary_train_carry,\n",
    "        reaction_time_small_binary_test_carry,\n",
    "        reaction_time_small_binary_train_carry_decimal,\n",
    "        reaction_time_small_binary_test_carry_decimal\n",
    "    )\n",
    "\n",
    "# Predict using the trained neural network\n",
    "def predict(params, x1, x2, stage):\n",
    "    if stage == 1:\n",
    "        binary_pred = neural_network_1(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 2:\n",
    "        binary_pred = neural_network_2(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 3:\n",
    "        binary_pred = neural_network_3(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "def generate_model_AP(epsilon_non_zeros = 0.01, epsilon_zeros = 0.01):   \n",
    "    R2_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R3_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R4_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R5_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R6_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R7_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R8_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    for i in range(2):\n",
    "        R2_almost_perfect[7*i + 6] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R3_almost_perfect[7*i + 5] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R4_almost_perfect[7*i + 4] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R5_almost_perfect[7*i + 3] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R6_almost_perfect[7*i + 2] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R7_almost_perfect[7*i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R8_almost_perfect[7*i + 0] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v2_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v3_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v4_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v5_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v6_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v7_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    T_almost_perfect = np.zeros((14,8)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    for i in range(7):\n",
    "        for j in range(2):\n",
    "            T_almost_perfect[7*j + i, i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    original_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    trainable_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    return trainable_model, original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d362f6dc-4abc-46e2-93be-45c196d34004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "        \n",
    "def load_trainable_model(model, current_time, training_type, stage = 0):\n",
    "    folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "    if stage == 0:\n",
    "        model_path = f'{folder}/Parameters/{training_type}/{model}_{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'trainable_model'] = pickle.load(f)\n",
    "        print(f'Model trainable_model_{current_time} loaded successfully.')\n",
    "        return globals()[f'trainable_model']\n",
    "        \n",
    "    else:\n",
    "        model_path = f'{folder}/Trained_models/Stages/{training_type}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'{model}_{stage}'] = pickle.load(f)\n",
    "        print(f'Model {model}_{stage}_{current_time} loaded successfully.')\n",
    "        return globals()[f'{model}_{stage}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f9cb29-4846-48df-bcac-c4b902fb0ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como D:\\OneDrive - Universidad Complutense de Madrid (UCM)\\Doctorado\\Curriculum_Learning\\Multidigit_Addition\\Parameters\\AP_0.05_0.05\\trainable_model_stage_2024_12_04_18_57_30.pkl\n",
      "Modelo guardado como D:\\OneDrive - Universidad Complutense de Madrid (UCM)\\Doctorado\\Curriculum_Learning\\Multidigit_Addition\\Parameters\\AP_0.05_0.05\\trainable_model_stage_2024_12_04_18_57_32.pkl\n",
      "Modelo guardado como D:\\OneDrive - Universidad Complutense de Madrid (UCM)\\Doctorado\\Curriculum_Learning\\Multidigit_Addition\\Parameters\\AP_0.05_0.05\\trainable_model_stage_2024_12_04_18_57_34.pkl\n",
      "Modelo guardado como D:\\OneDrive - Universidad Complutense de Madrid (UCM)\\Doctorado\\Curriculum_Learning\\Multidigit_Addition\\Parameters\\AP_0.05_0.05\\trainable_model_stage_2024_12_04_18_57_36.pkl\n",
      "Modelo guardado como D:\\OneDrive - Universidad Complutense de Madrid (UCM)\\Doctorado\\Curriculum_Learning\\Multidigit_Addition\\Parameters\\AP_0.05_0.05\\trainable_model_stage_2024_12_04_18_57_38.pkl\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "epsilon_zeros = 0.05\n",
    "epsilon_non_zeros = 0.05\n",
    "\n",
    "# Ruta base\n",
    "base_path = r\"D:\\OneDrive - Universidad Complutense de Madrid (UCM)\\Doctorado\\Curriculum_Learning\\Multidigit_Addition\\Parameters\"\n",
    "folder_name = f\"AP_{epsilon_zeros}_{epsilon_non_zeros}\"\n",
    "output_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "# Crear la carpeta si no existe\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Generar y guardar cinco modelos\n",
    "for _ in range(5):\n",
    "    trainable_model, original_model = generate_model_AP(epsilon_non_zeros, epsilon_zeros)\n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    file_name = f\"trainable_model_stage_{current_time}.pkl\"\n",
    "    file_path = os.path.join(output_path, file_name)\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(trainable_model, file)\n",
    "    print(f\"Modelo guardado como {file_path}\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a718a27d-647a-4517-98bb-684dc1364b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trainable_model_stage_1-2024_11_18_18_05_05.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m             real_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 64\u001b[0m             \u001b[43mdecide_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreal_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;241m=\u001b[39m tee\u001b[38;5;241m.\u001b[39mconsole\n",
      "Cell \u001b[1;32mIn[2], line 379\u001b[0m, in \u001b[0;36mdecide_test\u001b[1;34m(params, stage, real_test, visualize_errors)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecide_test\u001b[39m(params, stage, real_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, visualize_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m real_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 379\u001b[0m         test_count, correct_predictions_test_count, train_count, correct_predictions_train_count, test_carry_over_count, correct_carry_over_predictions_test_count, train_carry_over_count, correct_carry_over_predictions_train_count, small_train_count, correct_predictions_small_train_count, small_test_count, correct_predictions_small_test_count, small_train_carry_count, correct_predictions_small_train_carry_count, small_test_carry_count, correct_predictions_small_test_carry_count, test_carry_over_decimal_count, correct_carry_over_decimal_predictions_test_count, train_carry_over_decimal_count, correct_carry_over_decimal_predictions_train_count, small_train_carry_decimal_count, correct_predictions_small_train_carry_decimal_count, small_test_carry_decimal_count, correct_predictions_small_test_carry_decimal_count, small_binary_train_count, correct_predictions_small_binary_train_count, small_binary_test_count, correct_predictions_small_binary_test_count, small_binary_train_carry_count, correct_predictions_small_binary_train_carry_count, small_binary_test_carry_count, correct_predictions_small_binary_test_carry_count, small_binary_train_carry_decimal_count, correct_predictions_small_binary_train_carry_decimal_count, small_binary_test_carry_decimal_count, correct_predictions_small_binary_test_carry_decimal_count, reaction_time_carry, reaction_time_carry_decimal, reaction_time_train,reaction_time_test, reaction_time_train_carry, reaction_time_train_carry_decimal, reaction_time_small_train, reaction_time_small_test, reaction_time_small_train_carry, reaction_time_small_test_carry, reaction_time_small_train_carry_decimal, reaction_time_small_test_carry_decimal, reaction_time_small_binary_train, reaction_time_small_binary_test, reaction_time_small_binary_train_carry, reaction_time_small_binary_test_carry, reaction_time_small_binary_train_carry_decimal, reaction_time_small_binary_test_carry_decimal \u001b[38;5;241m=\u001b[39m \u001b[43mreal_test_stages_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTAGE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_predictions_train_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trained were predicted correctly in the current model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTAGE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_predictions_test_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tested were predicted correctly in the current model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 451\u001b[0m, in \u001b[0;36mreal_test_stages_neural_network\u001b[1;34m(params, stage, visualize_errors)\u001b[0m\n\u001b[0;32m    449\u001b[0m decimal_dataset \u001b[38;5;241m=\u001b[39m generate_real_test_dataset()    \n\u001b[0;32m    450\u001b[0m inputs_1, inputs_2, outputs_prev \u001b[38;5;241m=\u001b[39m transform_to_tridimensional_matrix(decimal_dataset)\n\u001b[1;32m--> 451\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_prev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m correct_predictions_test_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    454\u001b[0m correct_predictions_train_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 212\u001b[0m, in \u001b[0;36mprepare_outputs\u001b[1;34m(stage, x1, x2, outputs_prev)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vec1, vec2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x1, x2):\n\u001b[0;32m    211\u001b[0m     z2 \u001b[38;5;241m=\u001b[39m lower_even(vec1[\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m vec2[\u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m--> 212\u001b[0m     z3 \u001b[38;5;241m=\u001b[39m lower_even(vec1[\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m+\u001b[39m vec2[\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43mz2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    213\u001b[0m     z4 \u001b[38;5;241m=\u001b[39m lower_even(vec1[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m vec2[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m z3 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    214\u001b[0m     z5 \u001b[38;5;241m=\u001b[39m lower_even(vec1[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m vec2[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m z4 \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:573\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    571\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m--> 573\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\numpy\\ufunc_api.py:177\u001b[0m, in \u001b[0;36mufunc.__call__\u001b[1;34m(self, out, where, *args)\u001b[0m\n\u001b[0;32m    175\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    176\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__static_props[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_vectorized\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_performance = 'no'\n",
    "easy_examples = 'no'\n",
    "type_training = 'Stages'\n",
    "file_name = 'AP_0.05_0.05'\n",
    "\n",
    "if easy_examples == 'yes':\n",
    "    if validation_performance == 'yes':\n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/Validation_performance/tests-Easy_examples_{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/Easy_examples/{type_training}/{file_name}/Stage_3'\n",
    "    else:\n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/tests-Easy_examples_{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Easy_examples/{type_training}/{file_name}/Stage_3'\n",
    "    \n",
    "else:\n",
    "    if validation_performance == 'yes':    \n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/Validation_performance/tests-{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/{type_training}/{file_name}/Stage_3'\n",
    "    else:\n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/tests-{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/{type_training}/{file_name}/Stage_3'\n",
    "\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "tee = Tee(output_file, 'w') \n",
    "sys.stdout = tee\n",
    "\n",
    "try:\n",
    "    visualize_errors = 0\n",
    "    model = 'trainable_model_stage'\n",
    "    \n",
    "    date_pattern = r'trainable_model_stage_3-(\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}).pkl'\n",
    "    files = sorted(\n",
    "        (f for f in os.listdir(folder_path) if f.endswith('.pkl') and not f.startswith('.')),  # Filtrar archivos .pkl y ocultos\n",
    "        key=lambda x: re.search(date_pattern, x).group(0) if re.search(date_pattern, x) else ''\n",
    "    )\n",
    "    \n",
    "    for filename in files:\n",
    "        match = re.search(date_pattern, filename)\n",
    "        if match:\n",
    "            current_time = match.group(1)\n",
    "        else:\n",
    "            print('Error')\n",
    "            break\n",
    "    \n",
    "        for stage in range(1, 4):\n",
    "            if easy_examples == 'yes':\n",
    "                if validation_performance == 'yes':    \n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/Easy_examples/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "                else:\n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Easy_examples/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "                    \n",
    "            else:\n",
    "                if validation_performance == 'yes':   \n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "                else:\n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "\n",
    "            with open(file_path, 'rb') as file:\n",
    "                globals()[f\"{model}_{stage}\"] = pickle.load(file)\n",
    "    \n",
    "            print(f'Loaded {model}_{stage}-{current_time}.pkl')\n",
    "\n",
    "            real_test = 1\n",
    "            decide_test(params=globals()[f\"{model}_{stage}\"], stage=stage, real_test=real_test, visualize_errors=visualize_errors)\n",
    "                \n",
    "finally:\n",
    "    sys.stdout = tee.console\n",
    "    tee.close()\n",
    "    \n",
    "print(f'Finished, file {file_name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daf55b-da26-4126-8c75-09dcd2915511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc052aee-d272-4ad9-8f7d-a1defe4f8a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
