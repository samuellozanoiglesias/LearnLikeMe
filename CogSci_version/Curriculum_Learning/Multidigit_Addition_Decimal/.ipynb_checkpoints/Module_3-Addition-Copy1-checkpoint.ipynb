{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98558e0d-b53a-412c-81a9-9bb54f749c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Lambda, Concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.initializers import GlorotUniform, RandomUniform, Constant\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c8a971-a305-48fe-94a9-40be4a3f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los módulos preentrenados (unit_module y carry_module)\n",
    "unit_module = load_model('unit_module.keras')\n",
    "carry_module = load_model('carry_module.keras')\n",
    "unit_module.trainable = False\n",
    "carry_module.trainable = False\n",
    "unit_module.name = 'unit_model'\n",
    "carry_module.name = 'carry_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0452087c-51ad-4447-ad5e-91efa5837acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1771936e-21 1.7144982e-11 3.1472475e-05 9.9981755e-01 1.5102538e-04\n",
      "  1.5262895e-10 9.5085037e-11 4.9450106e-09 1.3280418e-11 1.4045509e-17]] [[9.999999e-01 5.989136e-08]] [[9.9991584e-01 3.8660859e-05 4.5050506e-08 3.8373384e-09 6.6833455e-10\n",
      "  5.7479936e-09 9.9060271e-09 1.9354084e-07 2.1289950e-06 4.3174157e-05]] [[9.9999309e-01 6.8641684e-06]]\n"
     ]
    }
   ],
   "source": [
    "x = [0, 2, 0, 1]\n",
    "\n",
    "units_input = jnp.array([x[1], x[3]])\n",
    "decs_input = jnp.array([x[0], x[2]])\n",
    "units_input = units_input[None, None, :]\n",
    "decs_input = decs_input[None, None, :]\n",
    "\n",
    "unit_output = jnp.array(unit_module(units_input))  # Salida para unidades\n",
    "carry_output_unit = jnp.array(carry_module(units_input))  # Salida de acarreo de unidades\n",
    "dec_output = jnp.array(unit_module(decs_input))  # Salida para decenas\n",
    "carry_output_dec = jnp.array(carry_module(decs_input))  # Salida de acarreo de decenas\n",
    "\n",
    "print(unit_output, carry_output_unit, dec_output, carry_output_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4f7d3-5420-48d6-a4f8-02aa814d155c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92293af0-33a3-408d-98e3-a37a680a8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar los datos\n",
    "def generate_final_data():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for a_dec in range(10):\n",
    "        for a_unit in range(10):\n",
    "            for b_dec in range(10):\n",
    "                for b_unit in range(10):\n",
    "                    x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "                    sum_units = (a_unit + b_unit) % 10\n",
    "                    carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "                    sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "                    carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "                    y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    return jnp.array(x_data), jnp.array(y_data)\n",
    "\n",
    "# Función para crear parámetros entrenables (v_0, ..., v_11)\n",
    "def init_params():\n",
    "    v_values_init = jnp.array([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1], dtype=jnp.float32)\n",
    "    key = random.PRNGKey(0)\n",
    "    keys = random.split(key, 12)\n",
    "    v_params = {f'v{i}': random.normal(keys[i], (1,)) * 0 + v_values_init[i] for i in range(12)}\n",
    "    return v_params\n",
    "\n",
    "# Modelo dinámico en JAX\n",
    "def model(params, x):\n",
    "    # Extraer unidades y decenas de los valores de entrada\n",
    "    units_input = jnp.array([x[1], x[3]])\n",
    "    decs_input = jnp.array([x[0], x[2]])\n",
    "    units_input = units_input[None, None, :]\n",
    "    decs_input = decs_input[None, None, :]\n",
    "    \n",
    "    # Llamar a los modelos unit_module y carry_module\n",
    "    unit_output = jnp.array(unit_module(units_input))  # Salida para unidades\n",
    "    carry_output_unit = jnp.array(carry_module(units_input))  # Salida de acarreo de unidades\n",
    "    dec_output = jnp.array(unit_module(decs_input))  # Salida para decenas\n",
    "    carry_output_dec = jnp.array(carry_module(decs_input))  # Salida de acarreo de decenas\n",
    "\n",
    "    # Tomar el valor máximo de las predicciones (argmax en JAX)\n",
    "    unit_val = jnp.argmax(unit_output, axis=-1)\n",
    "    carry_unit_val = jnp.argmax(carry_output_unit, axis=-1)\n",
    "    dec_val = jnp.argmax(dec_output, axis=-1)\n",
    "    carry_dec_val = jnp.argmax(carry_output_dec, axis=-1)\n",
    "\n",
    "    # Calcular las salidas combinadas con los parámetros v\n",
    "    salida_1 = (params['v0'] * carry_dec_val) + (params['v1'] * dec_val) + (params['v2'] * carry_unit_val) + (params['v3'] * unit_val)\n",
    "    salida_2 = (params['v4'] * carry_dec_val) + (params['v5'] * dec_val) + (params['v6'] * carry_unit_val) + (params['v7'] * unit_val)\n",
    "    salida_3 = (params['v8'] * carry_dec_val) + (params['v9'] * dec_val) + (params['v10'] * carry_unit_val) + (params['v11'] * unit_val)\n",
    "\n",
    "    return salida_1, salida_2, salida_3\n",
    "\n",
    "# Función de pérdida\n",
    "def loss_fn(params, x, y):\n",
    "    y_pred_1, y_pred_2, y_pred_3 = model(params, x)\n",
    "    return jnp.mean((y_pred_1 - y[0]) ** 2) + jnp.mean((y_pred_2 - y[1]) ** 2) + jnp.mean((y_pred_3 - y[2]) ** 2)\n",
    "    \n",
    "# Función para entrenar el modelo\n",
    "def update_params(params, x, y, lr):\n",
    "    # Asegúrate de usar JAX para los gradientes y operaciones\n",
    "    gradients = grad(loss_fn)(params, x, y)\n",
    "    step_loss = loss_fn(params, x, y)\n",
    "    new_params = jax.tree.map(lambda p, g: p - lr * g, params, gradients)\n",
    "    return new_params, step_loss\n",
    "\n",
    "\n",
    "def train_model(params, x_train, y_train, lr=0.01, epochs=100):\n",
    "    final_loss = 0\n",
    "    # Convertir x_train y y_train a arrays de JAX (si aún no lo son)\n",
    "    x_train = jnp.array(x_train)\n",
    "    y_train = jnp.array(y_train)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    for epoch in range(epochs):  # Número de épocas\n",
    "        params, step_loss = update_params(params, x_train[epoch], y_train[epoch], lr)\n",
    "        final_loss += step_loss\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {step_loss}\")\n",
    "        \n",
    "    final_loss = final_loss / epochs\n",
    "    return params, final_loss\n",
    "\n",
    "# Función para imprimir las predicciones y el loss en cada época\n",
    "def print_predictions_and_loss(epoch, predictions, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples = x_train.shape[0]\n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(predictions[j][i])) for j in range(3)]\n",
    "        \n",
    "        # Concatenar las predicciones en un número de 3 dígitos\n",
    "        concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "        \n",
    "        # Generar la salida esperada, concatenando los valores reales de y_train\n",
    "        expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))\n",
    "        \n",
    "        # Comprobar si la predicción es igual a la salida esperada\n",
    "        if concatenated_pred == expected_output:\n",
    "            pred_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}:\")\n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Si todas las predicciones son correctas, detener el entrenamiento\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente! Deteniendo entrenamiento.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def predictions(params, x_train, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples = x_train.shape[0]   \n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        prediction = model(params, x_train[i])\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(prediction[j].item())) for j in range(3)]\n",
    "        \n",
    "        # Concatenar las predicciones en un número de 3 dígitos\n",
    "        concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "        \n",
    "        # Generar la salida esperada, concatenando los valores reales de y_train\n",
    "        expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))\n",
    "        \n",
    "        # Comprobar si la predicción es igual a la salida esperada\n",
    "        if concatenated_pred == expected_output:\n",
    "            pred_count += 1\n",
    "\n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc503a87-d87f-4f4b-8895-10a1fa7d18b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones correctas: 9025 de 10000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = generate_final_data()\n",
    "params = init_params()\n",
    "\n",
    "predictions(params, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3db32-3fc1-4ab5-92a3-494ec92ae651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86181597-c941-4886-a28a-b612e940a339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00961376-49a8-4c0c-a8c1-3cbbf5932901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823fcaf-c605-412b-8039-51e9fc244133",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_final_data()\n",
    "params = init_params()\n",
    "x=x_train[0]\n",
    "print(jnp.array([x[1], x[3]]))\n",
    "new_params, final_loss = train_model(params, x_train, y_train, lr=0.01, epochs=100)\n",
    "print(final_loss)\n",
    "\n",
    "# Hacer predicciones después del entrenamiento\n",
    "predictions = model(params, x_train)\n",
    "print(\"Predicciones:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf51e8-d461-46ae-b59e-9bb29eab7081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc3aa9-c848-4beb-b1e2-a02a13abe0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c287a4bf-c7e2-4819-97f0-a50075e074e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Multiply.call().\n\n\u001b[1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'sparse'\u001b[0m\n\nArguments received by Multiply.call():\n  • args=(['tf.Tensor(shape=(1,), dtype=float32)', '<KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_22>'],)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dynamic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrainable_variables:\n",
      "Cell \u001b[1;32mIn[32], line 53\u001b[0m, in \u001b[0;36mbuild_dynamic_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m carry_dec_val \u001b[38;5;241m=\u001b[39m Lambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39margmax(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))(carry_output_dec)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Calcular las salidas finales combinando los valores ponderados\u001b[39;00m\n\u001b[0;32m     52\u001b[0m salida_1 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mMultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv_split\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarry_dec_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     54\u001b[0m     Multiply()([v_split[\u001b[38;5;241m1\u001b[39m], dec_val]),\n\u001b[0;32m     55\u001b[0m     Multiply()([v_split[\u001b[38;5;241m2\u001b[39m], carry_unit_val]),\n\u001b[0;32m     56\u001b[0m     Multiply()([v_split[\u001b[38;5;241m3\u001b[39m], unit_val]),\n\u001b[0;32m     57\u001b[0m ])\n\u001b[0;32m     58\u001b[0m salida_2 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[0;32m     59\u001b[0m     Multiply()([v_split[\u001b[38;5;241m4\u001b[39m], carry_dec_val]),\n\u001b[0;32m     60\u001b[0m     Multiply()([v_split[\u001b[38;5;241m5\u001b[39m], dec_val]),\n\u001b[0;32m     61\u001b[0m     Multiply()([v_split[\u001b[38;5;241m6\u001b[39m], carry_unit_val]),\n\u001b[0;32m     62\u001b[0m     Multiply()([v_split[\u001b[38;5;241m7\u001b[39m], unit_val]),\n\u001b[0;32m     63\u001b[0m ])\n\u001b[0;32m     64\u001b[0m salida_3 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[0;32m     65\u001b[0m     Multiply()([v_split[\u001b[38;5;241m8\u001b[39m], carry_dec_val]),\n\u001b[0;32m     66\u001b[0m     Multiply()([v_split[\u001b[38;5;241m9\u001b[39m], dec_val]),\n\u001b[0;32m     67\u001b[0m     Multiply()([v_split[\u001b[38;5;241m10\u001b[39m], carry_unit_val]),\n\u001b[0;32m     68\u001b[0m     Multiply()([v_split[\u001b[38;5;241m11\u001b[39m], unit_val]),\n\u001b[0;32m     69\u001b[0m ])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py:260\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    254\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m    255\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    256\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling Multiply.call().\n\n\u001b[1m'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'sparse'\u001b[0m\n\nArguments received by Multiply.call():\n  • args=(['tf.Tensor(shape=(1,), dtype=float32)', '<KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_22>'],)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "model = build_dynamic_model()\n",
    "model.summary()\n",
    "\n",
    "for var in model.trainable_variables:\n",
    "    if var.name == \"v_values:0\":\n",
    "        print(\"Valores iniciales de v_values:\", var.numpy())\n",
    "\n",
    "\n",
    "# Predicciones\n",
    "total_examples = x_train.shape[0]\n",
    "pred_count = 0\n",
    "\n",
    "# Realizar las predicciones para todos los ejemplos\n",
    "predictions = model.predict(x_train)\n",
    "\n",
    "# Si `predictions` contiene múltiples arrays (uno por salida del modelo):\n",
    "if isinstance(predictions, list):\n",
    "    # Concatenamos las predicciones en columnas\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {f\"Salida_{i+1}\": pred.flatten() for i, pred in enumerate(predictions)}\n",
    "    )\n",
    "else:\n",
    "    # Si `predictions` es un solo array\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Guardar como archivo CSV\n",
    "predictions_df.to_csv(\"predicciones_completas.csv\", index=False)\n",
    "\n",
    "# Inicializar listas para almacenar las predicciones y las salidas reales\n",
    "predicted_values = []\n",
    "expected_values = []\n",
    "\n",
    "for i in range(total_examples):\n",
    "    # Normalizar y redondear la predicción (cada salida del modelo)\n",
    "    normalized_pred = [\n",
    "        np.round(predictions[0][i]).astype(int),  # Primer valor del primer array\n",
    "        np.round(predictions[1][i]).astype(int),  # Primer valor del segundo array\n",
    "        np.round(predictions[2][i]).astype(int)   # Primer valor del tercer array\n",
    "    ]\n",
    "    \n",
    "    # Concatenar los tres elementos en normalized_pred como un solo número\n",
    "    concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "\n",
    "    # Comparar la predicción con la salida real\n",
    "    expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))  # Convertir la salida esperada en un número\n",
    "    \n",
    "    # Almacenar en las listas\n",
    "    predicted_values.append(concatenated_pred)\n",
    "    expected_values.append(expected_output)\n",
    "    \n",
    "    if concatenated_pred == expected_output:\n",
    "        pred_count += 1    \n",
    "\n",
    "print(f'Predicciones correctas: {pred_count} de {total_examples}.')\n",
    "\n",
    "# Crear un DataFrame con los datos\n",
    "data = {\n",
    "    \"Predicción\": predicted_values,\n",
    "    \"Valor Esperado\": expected_values\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar como archivo CSV\n",
    "df.to_csv(\"predicciones.csv\", index=False)\n",
    "\n",
    "print(f\"Archivo 'predicciones.csv' guardado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a153281-79cc-4133-9ce0-23d3f23d69ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c21301-93a0-4872-afbf-83700fbaf840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bf7f3-08d0-4374-9d8f-8149152c663e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f327801-4ba5-41cb-a654-53b6490c6169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb73e7-6710-44ad-a5f7-8a31e738acd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46548b-ff3f-49a5-a801-5de9ef66bf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcacb6-7fff-4886-8f33-47d9fed37126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13946a60-c632-45a3-92a2-bc8079f0618d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8a1ea-e598-41d2-9e41-7c7ce7d995bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
