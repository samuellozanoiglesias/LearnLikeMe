{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6675236-0245-4d91-a5c8-c30b9e87f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:08:30.394025: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-03 17:08:30.411349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733242110.431700  472213 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733242110.437895  472213 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 17:08:30.459528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5eff7d1-984f-4719-a990-cc4d31738baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733242119.115552  472213 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/samuel_lozano/CURRICULUM_LEARNING/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step  - accuracy: 0.6951 - loss: 0.6\n",
      "Evaluación de validación: 64/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6960 - loss: 0.6594 - val_accuracy: 0.6400 - val_loss: 0.5555\n",
      "Epoch 2/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step p - accuracy: 0.7540 - loss: 0.432\n",
      "Evaluación de validación: 91/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7721 - loss: 0.4105 - val_accuracy: 0.9100 - val_loss: 0.2732\n",
      "Epoch 3/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/stepp - accuracy: 0.9011 - loss: 0.210\n",
      "Evaluación de validación: 87/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8997 - loss: 0.2131 - val_accuracy: 0.8700 - val_loss: 0.2913\n",
      "Epoch 4/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9252 - loss: 0.207\n",
      "Evaluación de validación: 92/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9255 - loss: 0.2050 - val_accuracy: 0.9200 - val_loss: 0.1957\n",
      "Epoch 5/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9066 - loss: 0.229\n",
      "Evaluación de validación: 89/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9078 - loss: 0.2264 - val_accuracy: 0.8900 - val_loss: 0.2194\n",
      "Epoch 6/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9252 - loss: 0.147\n",
      "Evaluación de validación: 95/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9242 - loss: 0.1477 - val_accuracy: 0.9500 - val_loss: 0.1326\n",
      "Epoch 7/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9803 - loss: 0.078\n",
      "Evaluación de validación: 90/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9735 - loss: 0.0850 - val_accuracy: 0.9000 - val_loss: 0.2039\n",
      "Epoch 8/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9285 - loss: 0.159\n",
      "Evaluación de validación: 95/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9342 - loss: 0.1522 - val_accuracy: 0.9500 - val_loss: 0.1429\n",
      "Epoch 9/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9767 - loss: 0.084\n",
      "Evaluación de validación: 96/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9742 - loss: 0.0868 - val_accuracy: 0.9600 - val_loss: 0.1119\n",
      "Epoch 10/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9858 - loss: 0.069\n",
      "Evaluación de validación: 96/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0779 - val_accuracy: 0.9600 - val_loss: 0.1090\n",
      "Epoch 11/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9611 - loss: 0.097\n",
      "Evaluación de validación: 96/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1029 - val_accuracy: 0.9600 - val_loss: 0.0969\n",
      "Epoch 12/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step p - accuracy: 0.9658 - loss: 0.072\n",
      "Evaluación de validación: 98/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.0746 - val_accuracy: 0.9800 - val_loss: 0.0921\n",
      "Epoch 13/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9696 - loss: 0.090\n",
      "Evaluación de validación: 98/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0899 - val_accuracy: 0.9800 - val_loss: 0.0724\n",
      "Epoch 14/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9639 - loss: 0.073\n",
      "Evaluación de validación: 98/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9638 - loss: 0.0736 - val_accuracy: 0.9800 - val_loss: 0.0829\n",
      "Epoch 15/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/stepp - accuracy: 0.9880 - loss: 0.098\n",
      "Evaluación de validación: 93/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.1035 - val_accuracy: 0.9300 - val_loss: 0.1549\n",
      "Epoch 16/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9291 - loss: 0.122\n",
      "Evaluación de validación: 98/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9318 - loss: 0.1191 - val_accuracy: 0.9800 - val_loss: 0.0813\n",
      "Epoch 17/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/stepp - accuracy: 0.9385 - loss: 0.082\n",
      "Evaluación de validación: 95/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9347 - loss: 0.0906 - val_accuracy: 0.9500 - val_loss: 0.0830\n",
      "Epoch 18/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.8276 - loss: 0.259\n",
      "Evaluación de validación: 96/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8331 - loss: 0.2545 - val_accuracy: 0.9600 - val_loss: 0.1210\n",
      "Epoch 19/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9390 - loss: 0.095\n",
      "Evaluación de validación: 98/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9429 - loss: 0.0942 - val_accuracy: 0.9800 - val_loss: 0.0711\n",
      "Epoch 20/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9817 - loss: 0.065\n",
      "Evaluación de validación: 99/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0691 - val_accuracy: 0.9900 - val_loss: 0.0526\n",
      "Epoch 21/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9855 - loss: 0.100\n",
      "Evaluación de validación: 99/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0992 - val_accuracy: 0.9900 - val_loss: 0.0506\n",
      "Epoch 22/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/stepp - accuracy: 1.0000 - loss: 0.036\n",
      "Evaluación de validación: 95/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0388 - val_accuracy: 0.9500 - val_loss: 0.0822\n",
      "Epoch 23/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9343 - loss: 0.104\n",
      "Evaluación de validación: 99/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9329 - loss: 0.1105 - val_accuracy: 0.9900 - val_loss: 0.0504\n",
      "Epoch 24/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/stepp - accuracy: 0.9889 - loss: 0.083\n",
      "Evaluación de validación: 92/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0839 - val_accuracy: 0.9200 - val_loss: 0.1480\n",
      "Epoch 25/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 0.9675 - loss: 0.061\n",
      "Evaluación de validación: 99/100 correctas\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9682 - loss: 0.0622 - val_accuracy: 0.9900 - val_loss: 0.0425\n",
      "Epoch 26/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step p - accuracy: 1.0000 - loss: 0.038\n",
      "Evaluación de validación: 100/100 correctas\n",
      "¡Todas las combinaciones han sido aprendidas correctamente! Deteniendo entrenamiento.\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0390 - val_accuracy: 1.0000 - val_loss: 0.0288\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0275 \n",
      "Loss: 0.0288, Accuracy: 1.0000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Predicciones (probabilidades): [[9.9999988e-01 6.3830186e-08]\n",
      " [1.0000000e+00 1.9079860e-10]\n",
      " [1.0000000e+00 1.0107949e-10]\n",
      " [1.0000000e+00 2.0012156e-10]\n",
      " [1.0000000e+00 7.9865237e-10]]\n",
      "Predicciones (números): [0 0 0 0 0]\n",
      "Etiquetas reales: [0 0 0 0 0]\n",
      "\n",
      "Evaluación de validación final:\n",
      "Predicciones correctas: 100/100\n"
     ]
    }
   ],
   "source": [
    "# Generar datos para el módulo de llevadas\n",
    "def generate_carry_data():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for a in range(10):  # Primer número\n",
    "        for b in range(10):  # Segundo número\n",
    "            x_data.append([a, b])  # Entrada\n",
    "            y_data.append(1 if (a + b) >= 10 else 0)\n",
    "    return np.array(x_data), np.array(y_data)\n",
    "\n",
    "# Generar datos\n",
    "x, y = generate_carry_data()\n",
    "\n",
    "# Convertir etiquetas a one-hot (aunque solo haya 2 clases, 0 y 1)\n",
    "y_one_hot = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación (80% entrenamiento, 20% validación)\n",
    "train_size = int(len(x) * 0.8)  # 80% de datos para entrenamiento\n",
    "x_train, y_train = x[:train_size], y_one_hot[:train_size]\n",
    "x_val, y_val = x, y_one_hot  # 20% para validación\n",
    "\n",
    "# Asegurar formas consistentes para las entradas\n",
    "x_train = np.expand_dims(x_train, axis=1)  # Agrega una dimensión para 'timesteps'\n",
    "x_val = np.expand_dims(x_val, axis=1)      # Haz lo mismo con los datos de validación\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential([\n",
    "    LSTM(16, input_shape=(1, 2), return_sequences=True),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dense(2, activation='softmax')  # Salida para 2 clases: 0 (sin llevada) o 1 (con llevada)\n",
    "])\n",
    "\n",
    "# Callback personalizado para detener cuando todas las combinaciones sean correctas\n",
    "class StopWhenPerfectCallback(EarlyStopping):\n",
    "    def __init__(self, val_data, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.val_data = val_data  # Pasamos explícitamente los datos de validación\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Evaluar el rendimiento sobre todo el conjunto de validación\n",
    "        val_predictions = self.model.predict(self.val_data[0])\n",
    "        val_pred_labels = np.argmax(val_predictions, axis=1)\n",
    "        val_true_labels = np.argmax(self.val_data[1], axis=1)\n",
    "        \n",
    "        # Verificar si todas las combinaciones son correctas\n",
    "        correct_predictions = np.sum(val_pred_labels == val_true_labels)\n",
    "        total_predictions = len(val_true_labels)\n",
    "        \n",
    "        print(f'Evaluación de validación: {correct_predictions}/{total_predictions} correctas')\n",
    "\n",
    "        # Si todas las combinaciones son correctas, detener el entrenamiento\n",
    "        if correct_predictions == total_predictions:\n",
    "            print(\"¡Todas las combinaciones han sido aprendidas correctamente! Deteniendo entrenamiento.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Crear una instancia del callback con los datos de validación\n",
    "stop_callback = StopWhenPerfectCallback(val_data=(x_val, y_val), patience=500)\n",
    "\n",
    "# Entrenar el modelo con el callback personalizado\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=500,\n",
    "    batch_size=1,\n",
    "    callbacks=[stop_callback]\n",
    ")\n",
    "\n",
    "# Evaluación final\n",
    "loss, accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predicciones\n",
    "predictions = model.predict(x_val)\n",
    "predicted_numbers = np.argmax(predictions, axis=1)\n",
    "real_numbers = np.argmax(y_val, axis=1)  # Etiquetas reales\n",
    "\n",
    "print(\"Predicciones (probabilidades):\", predictions[:5])\n",
    "print(\"Predicciones (números):\", predicted_numbers[:5])\n",
    "print(\"Etiquetas reales:\", real_numbers[:5])\n",
    "\n",
    "# Mostrar las predicciones de validación y sus etiquetas\n",
    "print(\"\\nEvaluación de validación final:\")\n",
    "correct_predictions = np.sum(predicted_numbers == real_numbers)\n",
    "total_predictions = len(real_numbers)\n",
    "print(f'Predicciones correctas: {correct_predictions}/{total_predictions}')\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save('unit_carry_module.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bed0e-eabe-40a7-a02d-141dfb1aa020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (CURRICULUM_LEARNING)",
   "language": "python",
   "name": "curriculum_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
