{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98558e0d-b53a-412c-81a9-9bb54f749c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "from tensorflow.keras.models import Model, load_model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Lambda, Concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.initializers import GlorotUniform, RandomUniform, Constant\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d15cb903-d121-4c70-952d-9f60a5c352de",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition_Decimal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5220b5d7-767d-4616-9750-922b01af448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow no está utilizando la GPU\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay GPUs disponibles\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow está utilizando la GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow no está utilizando la GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1c8a971-a305-48fe-94a9-40be4a3f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los módulos preentrenados (unit_module y carry_module)\n",
    "unit_addition_model = load_model('unit_addition_module.keras')\n",
    "unit_carry_model = load_model('unit_carry_module.keras')\n",
    "dec_addition_model = load_model('dec_addition_module.keras')\n",
    "dec_carry_model = load_model('dec_carry_module.keras')\n",
    "\n",
    "unit_addition_model.trainable = False\n",
    "unit_carry_model.trainable = False\n",
    "dec_addition_model.trainable = False\n",
    "dec_carry_model.trainable = False\n",
    "\n",
    "unit_addition_model.name = 'unit_addition_model'\n",
    "unit_carry_model.name = 'unit_carry_model'\n",
    "dec_addition_model.name = 'dec_addition_model'\n",
    "dec_carry_model.name = 'dec_carry_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e640dcb3-ef42-4589-8409-d946e4f66dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las parejas desde el archivo\n",
    "with open(f\"{folder}train_couples.txt\", \"r\") as file:\n",
    "    train_couples = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}test_dataset.txt\", \"r\") as file:\n",
    "    test_dataset = eval(file.read())\n",
    "\n",
    "def generate_test_dataset():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for a, b in test_dataset:\n",
    "        a_dec = a // 10  # Decena del primer número\n",
    "        a_unit = a % 10  # Unidad del primer número\n",
    "        b_dec = b // 10  # Decena del segundo número\n",
    "        b_unit = b % 10  # Unidad del segundo número\n",
    "\n",
    "        x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "\n",
    "        sum_units = (a_unit + b_unit) % 10\n",
    "        carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "        sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "        carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "        y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    \n",
    "    return jnp.array(x_data), jnp.array(y_data)\n",
    "\n",
    "\n",
    "# Función para leer los datos desde un archivo .txt y generar el dataset de entrenamiento\n",
    "def generate_train_dataset():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for a, b in train_couples:\n",
    "        a_dec = a // 10  # Decena del primer número\n",
    "        a_unit = a % 10  # Unidad del primer número\n",
    "        b_dec = b // 10  # Decena del segundo número\n",
    "        b_unit = b % 10  # Unidad del segundo número\n",
    "\n",
    "        x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "\n",
    "        sum_units = (a_unit + b_unit) % 10\n",
    "        carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "        sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "        carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "        y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    \n",
    "    return jnp.array(x_data), jnp.array(y_data)\n",
    "\n",
    "# Función para generar los datos\n",
    "def generate_final_data():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for a_dec in range(10):\n",
    "        for a_unit in range(10):\n",
    "            for b_dec in range(10):\n",
    "                for b_unit in range(10):\n",
    "                    x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "                    sum_units = (a_unit + b_unit) % 10\n",
    "                    carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "                    sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "                    carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "                    y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    return jnp.array(x_data), jnp.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92293af0-33a3-408d-98e3-a37a680a8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear parámetros entrenables (v_0, ..., v_11)\n",
    "def init_params(epsilon = 0.1):\n",
    "    v_values_init = jnp.array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=jnp.float32)\n",
    "    v_params = {\n",
    "        f'v{i}': random.uniform(-10, 10) * epsilon + v_values_init[i] for i in range(12)\n",
    "    }\n",
    "    return v_params\n",
    "\n",
    "# Función de pérdida\n",
    "def loss_fn(params, x, y):\n",
    "    y_pred_1, y_pred_2, y_pred_3 = model(params, x)\n",
    "    return jnp.mean((y_pred_1 - y[0,0]) ** 2) + jnp.mean((y_pred_2 - y[0,1]) ** 2) + jnp.mean((y_pred_3 - y[0,2]) ** 2)\n",
    "    \n",
    "# Función para entrenar el modelo\n",
    "def update_params(params, x, y, lr):\n",
    "    # Asegúrate de usar JAX para los gradientes y operaciones\n",
    "    gradients = grad(loss_fn)(params, x, y)\n",
    "    step_loss = loss_fn(params, x, y)\n",
    "    new_params = jax.tree.map(lambda p, g: p - lr * g, params, gradients)\n",
    "    return new_params, step_loss\n",
    "\n",
    "def train_model(params, x_train, y_train, lr=0.01, epochs=100, batch_size=1):\n",
    "    final_loss = 0\n",
    "    total_examples = x_train.shape[0]\n",
    "    \n",
    "    # Convertir x_train y y_train a arrays de JAX (si aún no lo son)\n",
    "    x_train = jnp.array(x_train)\n",
    "    y_train = jnp.array(y_train)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    for epoch in range(epochs):  # Número de épocas\n",
    "        x_batch = x_train[epoch:epoch + 1]\n",
    "        y_batch = y_train[epoch:epoch + 1]\n",
    "        params, step_loss = update_params(params, x_batch, y_batch, lr)\n",
    "        final_loss += step_loss\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            pred_count, pred_count_train = correct_predictions(params)  # Contamos las predicciones correctas\n",
    "            print(f\"Epoch {epoch}, Loss: {step_loss}, Correct predictions: {pred_count}, Correct predictions train: {pred_count_train}\")\n",
    "            if pred_count_train == 8000:\n",
    "                break\n",
    "        \n",
    "    final_loss = final_loss / epochs\n",
    "    return params, final_loss\n",
    "\n",
    "def correct_predictions(params):\n",
    "    x_test, y_test = generate_test_dataset()\n",
    "    pred_count = 0\n",
    "    pred_count_train = 0\n",
    "    total_examples = x_test.shape[0]\n",
    "    pred_hundreds, pred_tens, pred_units = model(params, x_test)        \n",
    "    for i in range(total_examples):\n",
    "        normalized_pred = [int(jnp.round(pred_hundreds[i].item())),\n",
    "                           int(jnp.round(pred_tens[i].item())),\n",
    "                           int(jnp.round(pred_units[i].item()))]\n",
    "        \n",
    "        # Obtener los valores a y b de x_test\n",
    "        a = int(str(x_test[i, 0]) + str(x_test[i, 1]))\n",
    "        b = int(str(x_test[i, 2]) + str(x_test[i, 3]))\n",
    "        # Comparar las predicciones con las etiquetas y contar los aciertos\n",
    "        if normalized_pred[0] == y_test[i, 0] and normalized_pred[1] == y_test[i, 1] and normalized_pred[2] == y_test[i, 2]:\n",
    "            pred_count += 1\n",
    "            if (a, b) in train_couples:\n",
    "                pred_count_train += 1\n",
    "\n",
    "    return pred_count, pred_count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc299337-ef7d-4316-92bf-f76c12a817ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo dinámico en JAX\n",
    "def model(params, x):\n",
    "    units_input = jnp.array(x[:, [1, 3]])  # Columnas 1 y 3 representando unidades y decenas\n",
    "    units_input = units_input[:, None, :]  # Añade una dimensión extra para la secuencia (N, 1, 2)\n",
    "                            \n",
    "    unit_output = jnp.array(unit_addition_model(units_input))  # Asegúrate de que la entrada sea un batch\n",
    "    unit_carry_output = jnp.array(unit_carry_model(units_input))  # Salida de acarreo de unidades\n",
    "\n",
    "    # Tomar el valor máximo de las predicciones (argmax en JAX)\n",
    "    unit_val = jnp.argmax(unit_output, axis=-1)\n",
    "    carry_unit_val = jnp.argmax(unit_carry_output, axis=-1)\n",
    "\n",
    "    decs_input = jnp.array(x[:, [0, 2]])\n",
    "    decs_input = jnp.concatenate([decs_input, carry_unit_val[:, None]], axis=-1)\n",
    "    decs_input = decs_input[:, None, :]  # Añadir dimensión para la secuencia (N, 1, 3)\n",
    "    \n",
    "    dec_output = jnp.array(dec_addition_model(decs_input))  # Salida para decenas\n",
    "    dec_carry_output = jnp.array(dec_carry_model(decs_input))  # Salida de acarreo de decenas\n",
    "    \n",
    "    dec_val = jnp.argmax(dec_output, axis=-1)\n",
    "    carry_dec_val = jnp.argmax(dec_carry_output, axis=-1)\n",
    "\n",
    "    # Calcular las salidas combinadas con los parámetros v\n",
    "    salida_1 = (params['v0'] * carry_dec_val) + (params['v1'] * dec_val) + (params['v2'] * carry_unit_val) + (params['v3'] * unit_val)\n",
    "    salida_2 = (params['v4'] * carry_dec_val) + (params['v5'] * dec_val) + (params['v6'] * carry_unit_val) + (params['v7'] * unit_val)\n",
    "    salida_3 = (params['v8'] * carry_dec_val) + (params['v9'] * dec_val) + (params['v10'] * carry_unit_val) + (params['v11'] * unit_val)\n",
    "\n",
    "    return salida_1, salida_2, salida_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad68821-8b61-473b-ba5b-dba5eee4634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer parámetros de un archivo JSON\n",
    "def load_params_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "def save_trained_model(params, filename, model_dir):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    file_path = os.path.join(save_model_dir, filename)\n",
    "    serializable_params = {key: value.tolist() for key, value in params.items()}\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(serializable_params, f)\n",
    "\n",
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb30455-12b9-41f9-9dfa-a993a1ac3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trainable_model_2024_12_17_01_22_22.json\n",
      "Epoch 0, Loss: 13.36093521118164, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 10, Loss: 0.9679001569747925, Correct predictions: 1335, Correct predictions train: 1074\n",
      "Epoch 20, Loss: 0.38849037885665894, Correct predictions: 2944, Correct predictions train: 2320\n",
      "Epoch 30, Loss: 0.06355927884578705, Correct predictions: 3437, Correct predictions train: 2749\n",
      "Epoch 40, Loss: 0.28353413939476013, Correct predictions: 5239, Correct predictions train: 4174\n",
      "Epoch 50, Loss: 0.004351203795522451, Correct predictions: 5077, Correct predictions train: 4061\n",
      "Epoch 60, Loss: 0.5437416434288025, Correct predictions: 6378, Correct predictions train: 5118\n",
      "Epoch 70, Loss: 0.05991417169570923, Correct predictions: 6019, Correct predictions train: 4840\n",
      "Epoch 80, Loss: 2.6167497634887695, Correct predictions: 5805, Correct predictions train: 4621\n",
      "Epoch 90, Loss: 0.1780175119638443, Correct predictions: 5105, Correct predictions train: 4065\n",
      "Epoch 100, Loss: 6.8025031089782715, Correct predictions: 5691, Correct predictions train: 4571\n",
      "Epoch 110, Loss: 0.2007257640361786, Correct predictions: 6906, Correct predictions train: 5508\n",
      "Epoch 120, Loss: 0.12057435512542725, Correct predictions: 4166, Correct predictions train: 3313\n",
      "Epoch 130, Loss: 0.9420828223228455, Correct predictions: 1576, Correct predictions train: 1271\n",
      "Epoch 140, Loss: 1.7653535604476929, Correct predictions: 604, Correct predictions train: 483\n",
      "Epoch 150, Loss: 0.2089785635471344, Correct predictions: 9229, Correct predictions train: 7398\n",
      "Epoch 160, Loss: 1.2045376300811768, Correct predictions: 10000, Correct predictions train: 8000\n",
      "Saved trained_model_2024_12_17_01_22_22.json\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = generate_train_dataset()\n",
    "\n",
    "save_dir = f\"{folder}Results_models/AP_{epsilon}\"\n",
    "save_model_dir = f\"{folder}Trained_models/AP_{epsilon}\"\n",
    "folder_path = f'{folder}Parameters/AP_{epsilon}'\n",
    "date_pattern = r'trainable_model_(\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}).json'\n",
    "files = sorted(\n",
    "    (f for f in os.listdir(folder_path) if not f.startswith('.')),  # Filtrar archivos ocultos\n",
    "    key=lambda x: re.search(date_pattern, x).group(1) if re.search(date_pattern, x) else ''\n",
    ")\n",
    "\n",
    "for filename in files:\n",
    "    match = re.search(date_pattern, filename)\n",
    "    if match:\n",
    "        current_time = match.group(1)\n",
    "    else:\n",
    "        print('Error')\n",
    "        break\n",
    "    \n",
    "    file_path = f\"{folder_path}/trainable_model_{current_time}.json\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        trainable_model = json.load(file)\n",
    "\n",
    "    trainable_model_jnp = {key: jnp.array(value) for key, value in trainable_model.items()}\n",
    "    print(f'Loaded trainable_model_{current_time}.json')\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True) \n",
    "    results_file = os.path.join(save_dir, f\"Results_{current_time}.txt\") \n",
    "    tee = Tee(results_file, 'w') \n",
    "    sys.stdout = tee\n",
    "    \n",
    "    try: \n",
    "        new_params, average_loss = train_model(trainable_model_jnp, x_train, y_train, lr=0.01, epochs=1000)\n",
    "        pred_count, pred_count_train = correct_predictions(trainable_model_jnp)\n",
    "\n",
    "        trained_model_filename = f\"trained_model_{current_time}.json\"\n",
    "        save_trained_model(new_params, trained_model_filename, save_model_dir)\n",
    "        print(f'Saved trained_model_{current_time}.json')\n",
    "\n",
    "    finally:\n",
    "        sys.stdout = tee.console\n",
    "        tee.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7142fb59-e19a-4c8c-b78c-998dff5609d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trainable_model_2024_12_17_01_22_24.json\n",
      "Epoch 0, Loss: 69.80860900878906, Correct predictions: 5, Correct predictions train: 5\n",
      "Epoch 10, Loss: 0.9640272855758667, Correct predictions: 356, Correct predictions train: 290\n",
      "Epoch 20, Loss: 0.14204566180706024, Correct predictions: 3086, Correct predictions train: 2436\n",
      "Epoch 30, Loss: 0.18719357252120972, Correct predictions: 4791, Correct predictions train: 3827\n",
      "Epoch 40, Loss: 0.09300366044044495, Correct predictions: 5371, Correct predictions train: 4302\n",
      "Epoch 50, Loss: 0.0724881961941719, Correct predictions: 5212, Correct predictions train: 4152\n",
      "Epoch 60, Loss: 0.17300410568714142, Correct predictions: 6849, Correct predictions train: 5468\n",
      "Epoch 70, Loss: 0.6265217065811157, Correct predictions: 6053, Correct predictions train: 4834\n",
      "Epoch 80, Loss: 0.5899962782859802, Correct predictions: 6482, Correct predictions train: 5185\n",
      "Epoch 90, Loss: 0.3174198269844055, Correct predictions: 6055, Correct predictions train: 4831\n",
      "Epoch 100, Loss: 1.703079342842102, Correct predictions: 7490, Correct predictions train: 5987\n",
      "Epoch 110, Loss: 0.19850516319274902, Correct predictions: 8904, Correct predictions train: 7123\n",
      "Epoch 120, Loss: 0.606194019317627, Correct predictions: 6668, Correct predictions train: 5315\n",
      "Epoch 130, Loss: 0.17231839895248413, Correct predictions: 4383, Correct predictions train: 3508\n",
      "Epoch 140, Loss: 0.3241736888885498, Correct predictions: 2793, Correct predictions train: 2243\n",
      "Epoch 150, Loss: 0.15816622972488403, Correct predictions: 9925, Correct predictions train: 7944\n",
      "Epoch 160, Loss: 0.22221693396568298, Correct predictions: 9994, Correct predictions train: 7995\n",
      "Epoch 170, Loss: 0.14781668782234192, Correct predictions: 9119, Correct predictions train: 7305\n",
      "Epoch 180, Loss: 0.11504893004894257, Correct predictions: 10000, Correct predictions train: 8000\n",
      "Saved trained_model_2024_12_17_01_22_24.json\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = generate_train_dataset()\n",
    "\n",
    "save_dir = f\"{folder}Results_models/AP_{epsilon}\"\n",
    "save_model_dir = f\"{folder}Trained_models/AP_{epsilon}\"\n",
    "folder_path = f'{folder}Parameters_2/AP_{epsilon}'\n",
    "\n",
    "current_time = '2024_12_17_01_22_24'\n",
    "\n",
    "file_path = f\"{folder_path}/trainable_model_{current_time}.json\"\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    trainable_model = json.load(file)\n",
    "trainable_model_jnp = {key: jnp.array(value) for key, value in trainable_model.items()}\n",
    "print(f'Loaded trainable_model_{current_time}.json')\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True) \n",
    "results_file = os.path.join(save_dir, f\"Results_{current_time}.txt\") \n",
    "tee = Tee(results_file, 'w') \n",
    "sys.stdout = tee\n",
    "\n",
    "try: \n",
    "    new_params, average_loss = train_model(trainable_model_jnp, x_train, y_train, lr=0.01, epochs=1000)\n",
    "    pred_count, pred_count_train = correct_predictions(trainable_model_jnp)\n",
    "    trained_model_filename = f\"trained_model_{current_time}.json\"\n",
    "    save_trained_model(new_params, trained_model_filename, save_model_dir)\n",
    "    print(f'Saved trained_model_{current_time}.json')\n",
    "finally:\n",
    "    sys.stdout = tee.console\n",
    "    tee.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1d8b8-4466-4e80-972d-bb10d741e61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
