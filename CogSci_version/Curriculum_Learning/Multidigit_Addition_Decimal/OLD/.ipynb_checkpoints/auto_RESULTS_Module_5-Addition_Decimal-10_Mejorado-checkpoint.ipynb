{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98558e0d-b53a-412c-81a9-9bb54f749c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "from tensorflow.keras.models import Model, load_model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Lambda, Concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.initializers import GlorotUniform, RandomUniform, Constant\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15cb903-d121-4c70-952d-9f60a5c352de",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 10\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition_Decimal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5220b5d7-767d-4616-9750-922b01af448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow no está utilizando la GPU\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay GPUs disponibles\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow está utilizando la GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow no está utilizando la GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c8a971-a305-48fe-94a9-40be4a3f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los módulos preentrenados (unit_module y carry_module)\n",
    "unit_addition_model = load_model('unit_addition_module.keras')\n",
    "unit_carry_model = load_model('unit_carry_module.keras')\n",
    "dec_addition_model = load_model('dec_addition_module.keras')\n",
    "dec_carry_model = load_model('dec_carry_module.keras')\n",
    "\n",
    "unit_addition_model.trainable = False\n",
    "unit_carry_model.trainable = False\n",
    "dec_addition_model.trainable = False\n",
    "dec_carry_model.trainable = False\n",
    "\n",
    "unit_addition_model.name = 'unit_addition_model'\n",
    "unit_carry_model.name = 'unit_carry_model'\n",
    "dec_addition_model.name = 'dec_addition_model'\n",
    "dec_carry_model.name = 'dec_carry_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e640dcb3-ef42-4589-8409-d946e4f66dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las parejas desde el archivo\n",
    "with open(f\"{folder}train_couples.txt\", \"r\") as file:\n",
    "    train_couples = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}test_dataset.txt\", \"r\") as file:\n",
    "    test_dataset = eval(file.read())\n",
    "\n",
    "def generate_test_dataset():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for a, b in test_dataset:\n",
    "        a_dec = a // 10  # Decena del primer número\n",
    "        a_unit = a % 10  # Unidad del primer número\n",
    "        b_dec = b // 10  # Decena del segundo número\n",
    "        b_unit = b % 10  # Unidad del segundo número\n",
    "\n",
    "        x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "\n",
    "        sum_units = (a_unit + b_unit) % 10\n",
    "        carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "        sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "        carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "        y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    \n",
    "    return jnp.array(x_data), jnp.array(y_data)\n",
    "\n",
    "\n",
    "# Función para leer los datos desde un archivo .txt y generar el dataset de entrenamiento\n",
    "def generate_train_dataset():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for a, b in train_couples:\n",
    "        a_dec = a // 10  # Decena del primer número\n",
    "        a_unit = a % 10  # Unidad del primer número\n",
    "        b_dec = b // 10  # Decena del segundo número\n",
    "        b_unit = b % 10  # Unidad del segundo número\n",
    "\n",
    "        x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "\n",
    "        sum_units = (a_unit + b_unit) % 10\n",
    "        carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "        sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "        carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "        y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    \n",
    "    return jnp.array(x_data), jnp.array(y_data)\n",
    "\n",
    "# Función para generar los datos\n",
    "def generate_final_data():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for a_dec in range(10):\n",
    "        for a_unit in range(10):\n",
    "            for b_dec in range(10):\n",
    "                for b_unit in range(10):\n",
    "                    x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "                    sum_units = (a_unit + b_unit) % 10\n",
    "                    carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "                    sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "                    carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "                    y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    return jnp.array(x_data), jnp.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92293af0-33a3-408d-98e3-a37a680a8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear parámetros entrenables (v_0, ..., v_11)\n",
    "def init_params(epsilon = 0.1):\n",
    "    v_values_init = jnp.array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=jnp.float32)\n",
    "    v_params = {\n",
    "        f'v{i}': random.uniform(-10, 10) * epsilon + v_values_init[i] for i in range(12)\n",
    "    }\n",
    "    return v_params\n",
    "\n",
    "# Función de pérdida\n",
    "def loss_fn(params, x, y):\n",
    "    y_pred_1, y_pred_2, y_pred_3 = model(params, x)\n",
    "    return jnp.mean((y_pred_1 - y[0,0]) ** 2) + jnp.mean((y_pred_2 - y[0,1]) ** 2) + jnp.mean((y_pred_3 - y[0,2]) ** 2)\n",
    "    \n",
    "# Función para entrenar el modelo\n",
    "def update_params(params, x, y, lr):\n",
    "    # Asegúrate de usar JAX para los gradientes y operaciones\n",
    "    gradients = grad(loss_fn)(params, x, y)\n",
    "    step_loss = loss_fn(params, x, y)\n",
    "    new_params = jax.tree.map(lambda p, g: p - lr * g, params, gradients)\n",
    "    return new_params, step_loss\n",
    "\n",
    "def train_model(params, x_train, y_train, lr=0.01, epochs=100, batch_size=1):\n",
    "    final_loss = 0\n",
    "    total_examples = x_train.shape[0]\n",
    "    \n",
    "    # Convertir x_train y y_train a arrays de JAX (si aún no lo son)\n",
    "    x_train = jnp.array(x_train)\n",
    "    y_train = jnp.array(y_train)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    for epoch in range(epochs):  # Número de épocas\n",
    "        x_batch = x_train[epoch:epoch + 1]\n",
    "        y_batch = y_train[epoch:epoch + 1]\n",
    "        params, step_loss = update_params(params, x_batch, y_batch, lr)\n",
    "        final_loss += step_loss\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            pred_count, pred_count_train = correct_predictions(params)  # Contamos las predicciones correctas\n",
    "            print(f\"Epoch {epoch}, Loss: {step_loss}, Correct predictions: {pred_count}, Correct predictions train: {pred_count_train}\")\n",
    "            if pred_count_train == 8000:\n",
    "                break\n",
    "        \n",
    "    final_loss = final_loss / epochs\n",
    "    return params, final_loss\n",
    "\n",
    "def correct_predictions(params):\n",
    "    x_test, y_test = generate_test_dataset()\n",
    "    pred_count = 0\n",
    "    pred_count_train = 0\n",
    "    total_examples = x_test.shape[0]\n",
    "    pred_hundreds, pred_tens, pred_units = model(params, x_test)        \n",
    "    for i in range(total_examples):\n",
    "        normalized_pred = [int(jnp.round(pred_hundreds[i].item())),\n",
    "                           int(jnp.round(pred_tens[i].item())),\n",
    "                           int(jnp.round(pred_units[i].item()))]\n",
    "        \n",
    "        # Obtener los valores a y b de x_test\n",
    "        a = int(str(x_test[i, 0]) + str(x_test[i, 1]))\n",
    "        b = int(str(x_test[i, 2]) + str(x_test[i, 3]))\n",
    "        # Comparar las predicciones con las etiquetas y contar los aciertos\n",
    "        if normalized_pred[0] == y_test[i, 0] and normalized_pred[1] == y_test[i, 1] and normalized_pred[2] == y_test[i, 2]:\n",
    "            pred_count += 1\n",
    "            if (a, b) in train_couples:\n",
    "                pred_count_train += 1\n",
    "\n",
    "    return pred_count, pred_count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc299337-ef7d-4316-92bf-f76c12a817ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo dinámico en JAX\n",
    "def model(params, x):\n",
    "    units_input = jnp.array(x[:, [1, 3]])  # Columnas 1 y 3 representando unidades y decenas\n",
    "    units_input = units_input[:, None, :]  # Añade una dimensión extra para la secuencia (N, 1, 2)\n",
    "                            \n",
    "    unit_output = jnp.array(unit_addition_model(units_input))  # Asegúrate de que la entrada sea un batch\n",
    "    unit_carry_output = jnp.array(unit_carry_model(units_input))  # Salida de acarreo de unidades\n",
    "\n",
    "    # Tomar el valor máximo de las predicciones (argmax en JAX)\n",
    "    unit_val = jnp.argmax(unit_output, axis=-1)\n",
    "    carry_unit_val = jnp.argmax(unit_carry_output, axis=-1)\n",
    "\n",
    "    decs_input = jnp.array(x[:, [0, 2]])\n",
    "    decs_input = jnp.concatenate([decs_input, carry_unit_val[:, None]], axis=-1)\n",
    "    decs_input = decs_input[:, None, :]  # Añadir dimensión para la secuencia (N, 1, 3)\n",
    "    \n",
    "    dec_output = jnp.array(dec_addition_model(decs_input))  # Salida para decenas\n",
    "    dec_carry_output = jnp.array(dec_carry_model(decs_input))  # Salida de acarreo de decenas\n",
    "    \n",
    "    dec_val = jnp.argmax(dec_output, axis=-1)\n",
    "    carry_dec_val = jnp.argmax(dec_carry_output, axis=-1)\n",
    "\n",
    "    # Calcular las salidas combinadas con los parámetros v\n",
    "    salida_1 = (params['v0'] * carry_dec_val) + (params['v1'] * dec_val) + (params['v2'] * carry_unit_val) + (params['v3'] * unit_val)\n",
    "    salida_2 = (params['v4'] * carry_dec_val) + (params['v5'] * dec_val) + (params['v6'] * carry_unit_val) + (params['v7'] * unit_val)\n",
    "    salida_3 = (params['v8'] * carry_dec_val) + (params['v9'] * dec_val) + (params['v10'] * carry_unit_val) + (params['v11'] * unit_val)\n",
    "\n",
    "    return salida_1, salida_2, salida_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad68821-8b61-473b-ba5b-dba5eee4634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer parámetros de un archivo JSON\n",
    "def load_params_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "def save_trained_model(params, filename, model_dir):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    file_path = os.path.join(save_model_dir, filename)\n",
    "    serializable_params = {key: value.tolist() for key, value in params.items()}\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(serializable_params, f)\n",
    "\n",
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb30455-12b9-41f9-9dfa-a993a1ac3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trainable_model_2024_12_17_01_23_33.json\n",
      "Epoch 0, Loss: 519066.4375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 24998.3359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 2293.547607421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 2850.046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 40, Loss: 1699.9793701171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 1032.86328125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 3205.59326171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 9298.7646484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 13133.7685546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 4315.7421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 35568.359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 2800.480712890625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 8220.162109375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 4557.0205078125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 9208.33984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 2307.60498046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 160, Loss: 6317.00390625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 3990.23828125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 1764.437255859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 2044.6864013671875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 979.6666259765625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 1264.9942626953125, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 1473.462890625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 230, Loss: 1047.9837646484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 540.830322265625, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 1733.4554443359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 150.46571350097656, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 197.7825469970703, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 1320.504638671875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 2338.560546875, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 487.70513916015625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 160.5040283203125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 491.8382568359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 140.08895874023438, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 340, Loss: 1739.566650390625, Correct predictions: 51, Correct predictions train: 36\n",
      "Epoch 350, Loss: 2098.37255859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 12.268635749816895, Correct predictions: 5, Correct predictions train: 5\n",
      "Epoch 370, Loss: 422.66156005859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 334.4208679199219, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 390, Loss: 2.596015691757202, Correct predictions: 103, Correct predictions train: 83\n",
      "Epoch 400, Loss: 7.704380035400391, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 410, Loss: 14.63456916809082, Correct predictions: 165, Correct predictions train: 130\n",
      "Epoch 420, Loss: 1044.4022216796875, Correct predictions: 5, Correct predictions train: 2\n",
      "Epoch 430, Loss: 75.95977783203125, Correct predictions: 10, Correct predictions train: 8\n",
      "Epoch 440, Loss: 126.93780517578125, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 450, Loss: 293.802734375, Correct predictions: 22, Correct predictions train: 18\n",
      "Epoch 460, Loss: 8.246716499328613, Correct predictions: 7, Correct predictions train: 4\n",
      "Epoch 470, Loss: 262.69122314453125, Correct predictions: 126, Correct predictions train: 96\n",
      "Epoch 480, Loss: 145.26959228515625, Correct predictions: 225, Correct predictions train: 181\n",
      "Epoch 490, Loss: 1158.964111328125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 500, Loss: 0.604449987411499, Correct predictions: 105, Correct predictions train: 79\n",
      "Epoch 510, Loss: 24.030044555664062, Correct predictions: 334, Correct predictions train: 273\n",
      "Epoch 520, Loss: 178.33425903320312, Correct predictions: 240, Correct predictions train: 194\n",
      "Epoch 530, Loss: 8.431200981140137, Correct predictions: 327, Correct predictions train: 263\n",
      "Epoch 540, Loss: 63.55242156982422, Correct predictions: 61, Correct predictions train: 53\n",
      "Epoch 550, Loss: 0.9697016477584839, Correct predictions: 665, Correct predictions train: 523\n",
      "Epoch 560, Loss: 0.4794408082962036, Correct predictions: 770, Correct predictions train: 625\n",
      "Epoch 570, Loss: 62.8154411315918, Correct predictions: 307, Correct predictions train: 240\n",
      "Epoch 580, Loss: 3.3299648761749268, Correct predictions: 438, Correct predictions train: 340\n",
      "Epoch 590, Loss: 82.74931335449219, Correct predictions: 695, Correct predictions train: 546\n",
      "Epoch 600, Loss: 5.181663513183594, Correct predictions: 509, Correct predictions train: 400\n",
      "Epoch 610, Loss: 18.39963150024414, Correct predictions: 1262, Correct predictions train: 1024\n",
      "Epoch 620, Loss: 69.32003021240234, Correct predictions: 579, Correct predictions train: 464\n",
      "Epoch 630, Loss: 8.43149471282959, Correct predictions: 2971, Correct predictions train: 2378\n",
      "Epoch 640, Loss: 93.30899047851562, Correct predictions: 157, Correct predictions train: 137\n",
      "Epoch 650, Loss: 27.001659393310547, Correct predictions: 349, Correct predictions train: 280\n",
      "Epoch 660, Loss: 0.2755940556526184, Correct predictions: 889, Correct predictions train: 715\n",
      "Epoch 670, Loss: 763.1015014648438, Correct predictions: 387, Correct predictions train: 301\n",
      "Epoch 680, Loss: 15.163849830627441, Correct predictions: 730, Correct predictions train: 594\n",
      "Epoch 690, Loss: 129.28131103515625, Correct predictions: 434, Correct predictions train: 343\n",
      "Epoch 700, Loss: 28.70737075805664, Correct predictions: 245, Correct predictions train: 195\n",
      "Epoch 710, Loss: 17.222942352294922, Correct predictions: 930, Correct predictions train: 741\n",
      "Epoch 720, Loss: 340.6237487792969, Correct predictions: 452, Correct predictions train: 366\n",
      "Epoch 730, Loss: 0.947561502456665, Correct predictions: 1782, Correct predictions train: 1412\n",
      "Epoch 740, Loss: 30.023193359375, Correct predictions: 1528, Correct predictions train: 1209\n",
      "Epoch 750, Loss: 50.1798095703125, Correct predictions: 753, Correct predictions train: 594\n",
      "Epoch 760, Loss: 4.877688884735107, Correct predictions: 1025, Correct predictions train: 826\n",
      "Epoch 770, Loss: 23.492618560791016, Correct predictions: 483, Correct predictions train: 391\n",
      "Epoch 780, Loss: 0.05700121447443962, Correct predictions: 897, Correct predictions train: 702\n",
      "Epoch 790, Loss: 1.603859782218933, Correct predictions: 2336, Correct predictions train: 1877\n",
      "Epoch 800, Loss: 2.7037482261657715, Correct predictions: 630, Correct predictions train: 510\n",
      "Epoch 810, Loss: 1.9371871948242188, Correct predictions: 573, Correct predictions train: 448\n",
      "Epoch 820, Loss: 181.5493621826172, Correct predictions: 814, Correct predictions train: 649\n",
      "Epoch 830, Loss: 3.101360321044922, Correct predictions: 1625, Correct predictions train: 1320\n",
      "Epoch 840, Loss: 19.000085830688477, Correct predictions: 1780, Correct predictions train: 1410\n",
      "Epoch 850, Loss: 16.460535049438477, Correct predictions: 1633, Correct predictions train: 1323\n",
      "Epoch 860, Loss: 0.028104610741138458, Correct predictions: 834, Correct predictions train: 660\n",
      "Epoch 870, Loss: 0.9649131298065186, Correct predictions: 1529, Correct predictions train: 1233\n",
      "Epoch 880, Loss: 8.542415618896484, Correct predictions: 1917, Correct predictions train: 1511\n",
      "Epoch 890, Loss: 3.36381459236145, Correct predictions: 2468, Correct predictions train: 1972\n",
      "Epoch 900, Loss: 20.732437133789062, Correct predictions: 588, Correct predictions train: 478\n",
      "Epoch 910, Loss: 49.52333450317383, Correct predictions: 982, Correct predictions train: 777\n",
      "Epoch 920, Loss: 160.47816467285156, Correct predictions: 1110, Correct predictions train: 885\n",
      "Epoch 930, Loss: 5.056418418884277, Correct predictions: 1619, Correct predictions train: 1284\n",
      "Epoch 940, Loss: 0.004450704902410507, Correct predictions: 2511, Correct predictions train: 2031\n",
      "Epoch 950, Loss: 31.170209884643555, Correct predictions: 1503, Correct predictions train: 1204\n",
      "Epoch 960, Loss: 1.8020130395889282, Correct predictions: 2077, Correct predictions train: 1673\n",
      "Epoch 970, Loss: 13.113324165344238, Correct predictions: 2323, Correct predictions train: 1877\n",
      "Epoch 980, Loss: 0.8554755449295044, Correct predictions: 2287, Correct predictions train: 1823\n",
      "Epoch 990, Loss: 8.840662956237793, Correct predictions: 1009, Correct predictions train: 793\n",
      "Saved trained_model_2024_12_17_01_23_33.json\n",
      "Loaded trainable_model_2024_12_17_01_23_35.json\n",
      "Epoch 0, Loss: 107873.953125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 27635.90234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 444.9504699707031, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 876.3533935546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 40, Loss: 667.425537109375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 344.6908264160156, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 1288.5499267578125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 3439.93359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 6554.111328125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 1087.5076904296875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 16562.251953125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 728.8036499023438, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 2254.37939453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 2689.449951171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 5896.384765625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 634.2454223632812, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 160, Loss: 4053.41943359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 2600.2666015625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 529.0302124023438, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 857.5394287109375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 631.58251953125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 657.6693115234375, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 569.48876953125, Correct predictions: 13, Correct predictions train: 9\n",
      "Epoch 230, Loss: 388.04168701171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 278.02899169921875, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 1102.181396484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 56.95112228393555, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 97.83002471923828, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 802.9688720703125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 1224.1739501953125, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 309.2366943359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 73.54417419433594, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 125.24671936035156, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 91.63446807861328, Correct predictions: 6, Correct predictions train: 6\n",
      "Epoch 340, Loss: 1045.6522216796875, Correct predictions: 87, Correct predictions train: 61\n",
      "Epoch 350, Loss: 1244.072021484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 5.249858856201172, Correct predictions: 14, Correct predictions train: 11\n",
      "Epoch 370, Loss: 262.4801025390625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 218.30923461914062, Correct predictions: 57, Correct predictions train: 48\n",
      "Epoch 390, Loss: 1.6410436630249023, Correct predictions: 175, Correct predictions train: 142\n",
      "Epoch 400, Loss: 2.0277557373046875, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 410, Loss: 7.908185958862305, Correct predictions: 320, Correct predictions train: 254\n",
      "Epoch 420, Loss: 599.9356689453125, Correct predictions: 15, Correct predictions train: 11\n",
      "Epoch 430, Loss: 48.65782928466797, Correct predictions: 10, Correct predictions train: 8\n",
      "Epoch 440, Loss: 81.49038696289062, Correct predictions: 67, Correct predictions train: 58\n",
      "Epoch 450, Loss: 163.54208374023438, Correct predictions: 74, Correct predictions train: 56\n",
      "Epoch 460, Loss: 2.111154079437256, Correct predictions: 67, Correct predictions train: 49\n",
      "Epoch 470, Loss: 154.43780517578125, Correct predictions: 126, Correct predictions train: 96\n",
      "Epoch 480, Loss: 87.99287414550781, Correct predictions: 352, Correct predictions train: 285\n",
      "Epoch 490, Loss: 655.9544677734375, Correct predictions: 17, Correct predictions train: 14\n",
      "Epoch 500, Loss: 0.1604464054107666, Correct predictions: 378, Correct predictions train: 277\n",
      "Epoch 510, Loss: 11.961931228637695, Correct predictions: 369, Correct predictions train: 298\n",
      "Epoch 520, Loss: 102.33439636230469, Correct predictions: 374, Correct predictions train: 301\n",
      "Epoch 530, Loss: 5.171533584594727, Correct predictions: 543, Correct predictions train: 434\n",
      "Epoch 540, Loss: 38.1369743347168, Correct predictions: 67, Correct predictions train: 58\n",
      "Epoch 550, Loss: 0.2464037984609604, Correct predictions: 1250, Correct predictions train: 1004\n",
      "Epoch 560, Loss: 0.3110697269439697, Correct predictions: 1160, Correct predictions train: 947\n",
      "Epoch 570, Loss: 36.90986633300781, Correct predictions: 317, Correct predictions train: 248\n",
      "Epoch 580, Loss: 1.8500025272369385, Correct predictions: 903, Correct predictions train: 716\n",
      "Epoch 590, Loss: 48.82495880126953, Correct predictions: 1019, Correct predictions train: 809\n",
      "Epoch 600, Loss: 3.238041877746582, Correct predictions: 523, Correct predictions train: 414\n",
      "Epoch 610, Loss: 10.909751892089844, Correct predictions: 1277, Correct predictions train: 1029\n",
      "Epoch 620, Loss: 39.22947692871094, Correct predictions: 734, Correct predictions train: 587\n",
      "Epoch 630, Loss: 4.429622173309326, Correct predictions: 2955, Correct predictions train: 2361\n",
      "Epoch 640, Loss: 53.33148193359375, Correct predictions: 654, Correct predictions train: 534\n",
      "Epoch 650, Loss: 16.22382164001465, Correct predictions: 640, Correct predictions train: 521\n",
      "Epoch 660, Loss: 0.18026933073997498, Correct predictions: 889, Correct predictions train: 715\n",
      "Epoch 670, Loss: 441.68621826171875, Correct predictions: 550, Correct predictions train: 440\n",
      "Epoch 680, Loss: 8.840258598327637, Correct predictions: 730, Correct predictions train: 594\n",
      "Epoch 690, Loss: 74.58545684814453, Correct predictions: 477, Correct predictions train: 376\n",
      "Epoch 700, Loss: 16.65418815612793, Correct predictions: 245, Correct predictions train: 195\n",
      "Epoch 710, Loss: 9.85549259185791, Correct predictions: 1267, Correct predictions train: 1007\n",
      "Epoch 720, Loss: 196.36793518066406, Correct predictions: 473, Correct predictions train: 384\n",
      "Epoch 730, Loss: 0.5244384407997131, Correct predictions: 2079, Correct predictions train: 1653\n",
      "Epoch 740, Loss: 17.347393035888672, Correct predictions: 1695, Correct predictions train: 1343\n",
      "Epoch 750, Loss: 29.03008270263672, Correct predictions: 973, Correct predictions train: 771\n",
      "Epoch 760, Loss: 2.9338440895080566, Correct predictions: 1207, Correct predictions train: 971\n",
      "Epoch 770, Loss: 13.592933654785156, Correct predictions: 551, Correct predictions train: 446\n",
      "Epoch 780, Loss: 0.034761399030685425, Correct predictions: 1113, Correct predictions train: 878\n",
      "Epoch 790, Loss: 0.9036014676094055, Correct predictions: 2884, Correct predictions train: 2305\n",
      "Epoch 800, Loss: 1.5423235893249512, Correct predictions: 772, Correct predictions train: 625\n",
      "Epoch 810, Loss: 1.1018892526626587, Correct predictions: 669, Correct predictions train: 524\n",
      "Epoch 820, Loss: 104.8296890258789, Correct predictions: 1062, Correct predictions train: 852\n",
      "Epoch 830, Loss: 1.785465955734253, Correct predictions: 1836, Correct predictions train: 1486\n",
      "Epoch 840, Loss: 10.998276710510254, Correct predictions: 1870, Correct predictions train: 1481\n",
      "Epoch 850, Loss: 9.566530227661133, Correct predictions: 1905, Correct predictions train: 1539\n",
      "Epoch 860, Loss: 0.016822239384055138, Correct predictions: 866, Correct predictions train: 684\n",
      "Epoch 870, Loss: 0.550974428653717, Correct predictions: 1776, Correct predictions train: 1437\n",
      "Epoch 880, Loss: 4.929852485656738, Correct predictions: 2219, Correct predictions train: 1752\n",
      "Epoch 890, Loss: 1.9382448196411133, Correct predictions: 3063, Correct predictions train: 2458\n",
      "Epoch 900, Loss: 11.973938941955566, Correct predictions: 716, Correct predictions train: 575\n",
      "Epoch 910, Loss: 28.599140167236328, Correct predictions: 1119, Correct predictions train: 890\n",
      "Epoch 920, Loss: 92.71527099609375, Correct predictions: 1110, Correct predictions train: 885\n",
      "Epoch 930, Loss: 2.9169435501098633, Correct predictions: 1928, Correct predictions train: 1526\n",
      "Epoch 940, Loss: 0.0023162849247455597, Correct predictions: 3067, Correct predictions train: 2445\n",
      "Epoch 950, Loss: 18.016542434692383, Correct predictions: 1688, Correct predictions train: 1356\n",
      "Epoch 960, Loss: 1.0451819896697998, Correct predictions: 2391, Correct predictions train: 1931\n",
      "Epoch 970, Loss: 7.5902557373046875, Correct predictions: 2521, Correct predictions train: 2035\n",
      "Epoch 980, Loss: 0.4934588074684143, Correct predictions: 2595, Correct predictions train: 2070\n",
      "Epoch 990, Loss: 5.111997127532959, Correct predictions: 1255, Correct predictions train: 990\n",
      "Saved trained_model_2024_12_17_01_23_35.json\n",
      "Loaded trainable_model_2024_12_17_01_23_37.json\n",
      "Epoch 0, Loss: 230540.765625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 3119.75341796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 1982.6748046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 379.8633728027344, Correct predictions: 13, Correct predictions train: 11\n",
      "Epoch 40, Loss: 2121.80615234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 414.7379150390625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 4141.8828125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 5247.74755859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 23823.4609375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 807.7313842773438, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 58421.46875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 931.5974731445312, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 1527.6337890625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 10162.28125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 22004.427734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 1069.4158935546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 160, Loss: 15107.693359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 9162.2646484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 1149.480712890625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 1649.838623046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 2346.099365234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 1717.392333984375, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 947.7914428710938, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 230, Loss: 593.0985107421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 715.8359375, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 3699.546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 91.00629425048828, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 354.3940124511719, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 3034.2900390625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 3224.116943359375, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 1033.563720703125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 162.20477294921875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 131.7391815185547, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 330.2579345703125, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 340, Loss: 3255.2109375, Correct predictions: 37, Correct predictions train: 26\n",
      "Epoch 350, Loss: 3808.156005859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 10.435726165771484, Correct predictions: 15, Correct predictions train: 14\n",
      "Epoch 370, Loss: 851.881591796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 774.0451049804688, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 390, Loss: 6.159421920776367, Correct predictions: 99, Correct predictions train: 80\n",
      "Epoch 400, Loss: 2.7871787548065186, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 410, Loss: 21.656356811523438, Correct predictions: 165, Correct predictions train: 130\n",
      "Epoch 420, Loss: 1767.9415283203125, Correct predictions: 5, Correct predictions train: 2\n",
      "Epoch 430, Loss: 165.30091857910156, Correct predictions: 6, Correct predictions train: 6\n",
      "Epoch 440, Loss: 277.8828430175781, Correct predictions: 25, Correct predictions train: 21\n",
      "Epoch 450, Loss: 464.1518249511719, Correct predictions: 62, Correct predictions train: 46\n",
      "Epoch 460, Loss: 2.3539881706237793, Correct predictions: 94, Correct predictions train: 74\n",
      "Epoch 470, Loss: 467.94940185546875, Correct predictions: 94, Correct predictions train: 66\n",
      "Epoch 480, Loss: 276.5494384765625, Correct predictions: 213, Correct predictions train: 174\n",
      "Epoch 490, Loss: 1899.118896484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 500, Loss: 0.10116712749004364, Correct predictions: 261, Correct predictions train: 186\n",
      "Epoch 510, Loss: 29.55312728881836, Correct predictions: 392, Correct predictions train: 325\n",
      "Epoch 520, Loss: 301.194580078125, Correct predictions: 286, Correct predictions train: 229\n",
      "Epoch 530, Loss: 16.51428985595703, Correct predictions: 302, Correct predictions train: 238\n",
      "Epoch 540, Loss: 118.47764587402344, Correct predictions: 28, Correct predictions train: 26\n",
      "Epoch 550, Loss: 0.16354987025260925, Correct predictions: 779, Correct predictions train: 626\n",
      "Epoch 560, Loss: 1.0833650827407837, Correct predictions: 979, Correct predictions train: 804\n",
      "Epoch 570, Loss: 111.76568603515625, Correct predictions: 195, Correct predictions train: 149\n",
      "Epoch 580, Loss: 5.238335132598877, Correct predictions: 585, Correct predictions train: 470\n",
      "Epoch 590, Loss: 148.58819580078125, Correct predictions: 584, Correct predictions train: 458\n",
      "Epoch 600, Loss: 10.59859561920166, Correct predictions: 313, Correct predictions train: 235\n",
      "Epoch 610, Loss: 33.399234771728516, Correct predictions: 629, Correct predictions train: 508\n",
      "Epoch 620, Loss: 113.56146240234375, Correct predictions: 299, Correct predictions train: 242\n",
      "Epoch 630, Loss: 11.71860408782959, Correct predictions: 1671, Correct predictions train: 1338\n",
      "Epoch 640, Loss: 156.22329711914062, Correct predictions: 55, Correct predictions train: 48\n",
      "Epoch 650, Loss: 50.480064392089844, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 660, Loss: 0.6484277248382568, Correct predictions: 503, Correct predictions train: 409\n",
      "Epoch 670, Loss: 1313.4638671875, Correct predictions: 276, Correct predictions train: 223\n",
      "Epoch 680, Loss: 26.516368865966797, Correct predictions: 670, Correct predictions train: 544\n",
      "Epoch 690, Loss: 220.93658447265625, Correct predictions: 259, Correct predictions train: 202\n",
      "Epoch 700, Loss: 49.66206359863281, Correct predictions: 161, Correct predictions train: 124\n",
      "Epoch 710, Loss: 28.910221099853516, Correct predictions: 846, Correct predictions train: 674\n",
      "Epoch 720, Loss: 581.1629028320312, Correct predictions: 357, Correct predictions train: 287\n",
      "Epoch 730, Loss: 1.478226661682129, Correct predictions: 1119, Correct predictions train: 888\n",
      "Epoch 740, Loss: 51.479732513427734, Correct predictions: 926, Correct predictions train: 722\n",
      "Epoch 750, Loss: 86.2776870727539, Correct predictions: 556, Correct predictions train: 438\n",
      "Epoch 760, Loss: 9.140483856201172, Correct predictions: 783, Correct predictions train: 629\n",
      "Epoch 770, Loss: 40.40530776977539, Correct predictions: 288, Correct predictions train: 234\n",
      "Epoch 780, Loss: 0.1101846843957901, Correct predictions: 528, Correct predictions train: 410\n",
      "Epoch 790, Loss: 2.6017918586730957, Correct predictions: 1568, Correct predictions train: 1253\n",
      "Epoch 800, Loss: 4.507335186004639, Correct predictions: 316, Correct predictions train: 255\n",
      "Epoch 810, Loss: 3.209219455718994, Correct predictions: 357, Correct predictions train: 282\n",
      "Epoch 820, Loss: 310.8432312011719, Correct predictions: 668, Correct predictions train: 531\n",
      "Epoch 830, Loss: 5.275550365447998, Correct predictions: 1116, Correct predictions train: 910\n",
      "Epoch 840, Loss: 32.70948028564453, Correct predictions: 1220, Correct predictions train: 968\n",
      "Epoch 850, Loss: 28.588462829589844, Correct predictions: 1098, Correct predictions train: 897\n",
      "Epoch 860, Loss: 0.05209702253341675, Correct predictions: 545, Correct predictions train: 438\n",
      "Epoch 870, Loss: 1.612119436264038, Correct predictions: 1100, Correct predictions train: 885\n",
      "Epoch 880, Loss: 14.608585357666016, Correct predictions: 1407, Correct predictions train: 1102\n",
      "Epoch 890, Loss: 5.732885360717773, Correct predictions: 1584, Correct predictions train: 1261\n",
      "Epoch 900, Loss: 35.514869689941406, Correct predictions: 391, Correct predictions train: 322\n",
      "Epoch 910, Loss: 84.81531524658203, Correct predictions: 628, Correct predictions train: 492\n",
      "Epoch 920, Loss: 275.10748291015625, Correct predictions: 468, Correct predictions train: 393\n",
      "Epoch 930, Loss: 8.639752388000488, Correct predictions: 813, Correct predictions train: 650\n",
      "Epoch 940, Loss: 0.006055926438421011, Correct predictions: 1605, Correct predictions train: 1308\n",
      "Epoch 950, Loss: 53.4882698059082, Correct predictions: 980, Correct predictions train: 783\n",
      "Epoch 960, Loss: 3.115870475769043, Correct predictions: 1481, Correct predictions train: 1191\n",
      "Epoch 970, Loss: 22.572303771972656, Correct predictions: 1949, Correct predictions train: 1574\n",
      "Epoch 980, Loss: 1.4614115953445435, Correct predictions: 1442, Correct predictions train: 1149\n",
      "Epoch 990, Loss: 15.183953285217285, Correct predictions: 662, Correct predictions train: 518\n",
      "Saved trained_model_2024_12_17_01_23_37.json\n",
      "Loaded trainable_model_2024_12_17_01_23_39.json\n",
      "Epoch 0, Loss: 505757.3125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 17038.68359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 1134.2371826171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 2279.302978515625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 40, Loss: 769.4398193359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 805.6993408203125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 1412.225341796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 6871.70849609375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 3840.5654296875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 3468.274169921875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 12084.31640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 2088.083984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 6773.44189453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 849.822998046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 1467.422119140625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 1614.9873046875, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 160, Loss: 1008.5723876953125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 843.50830078125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 1124.977783203125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 1378.105224609375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 157.6353302001953, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 652.6134643554688, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 1058.34423828125, Correct predictions: 13, Correct predictions train: 9\n",
      "Epoch 230, Loss: 774.0187377929688, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 284.4883117675781, Correct predictions: 57, Correct predictions train: 44\n",
      "Epoch 250, Loss: 468.1724548339844, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 109.60202026367188, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 59.02427673339844, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 227.04086303710938, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 1191.7850341796875, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 134.2333984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 99.0265884399414, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 320, Loss: 378.595458984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 26.061477661132812, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 340, Loss: 621.5897216796875, Correct predictions: 87, Correct predictions train: 61\n",
      "Epoch 350, Loss: 787.6859741210938, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 360, Loss: 8.120855331420898, Correct predictions: 60, Correct predictions train: 47\n",
      "Epoch 370, Loss: 131.12303161621094, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 68.2669906616211, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 390, Loss: 0.41460245847702026, Correct predictions: 205, Correct predictions train: 163\n",
      "Epoch 400, Loss: 5.663992881774902, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 410, Loss: 7.0131144523620605, Correct predictions: 490, Correct predictions train: 387\n",
      "Epoch 420, Loss: 432.18170166015625, Correct predictions: 18, Correct predictions train: 14\n",
      "Epoch 430, Loss: 19.40386962890625, Correct predictions: 21, Correct predictions train: 18\n",
      "Epoch 440, Loss: 31.844568252563477, Correct predictions: 30, Correct predictions train: 21\n",
      "Epoch 450, Loss: 131.8426513671875, Correct predictions: 164, Correct predictions train: 128\n",
      "Epoch 460, Loss: 6.292680263519287, Correct predictions: 158, Correct predictions train: 126\n",
      "Epoch 470, Loss: 101.39601135253906, Correct predictions: 252, Correct predictions train: 199\n",
      "Epoch 480, Loss: 50.38941955566406, Correct predictions: 362, Correct predictions train: 294\n",
      "Epoch 490, Loss: 499.07769775390625, Correct predictions: 37, Correct predictions train: 29\n",
      "Epoch 500, Loss: 0.49835801124572754, Correct predictions: 417, Correct predictions train: 328\n",
      "Epoch 510, Loss: 13.304483413696289, Correct predictions: 444, Correct predictions train: 357\n",
      "Epoch 520, Loss: 74.00994110107422, Correct predictions: 540, Correct predictions train: 440\n",
      "Epoch 530, Loss: 2.773550510406494, Correct predictions: 820, Correct predictions train: 649\n",
      "Epoch 540, Loss: 22.85227394104004, Correct predictions: 97, Correct predictions train: 79\n",
      "Epoch 550, Loss: 0.7891654372215271, Correct predictions: 1400, Correct predictions train: 1134\n",
      "Epoch 560, Loss: 0.10800919681787491, Correct predictions: 1160, Correct predictions train: 947\n",
      "Epoch 570, Loss: 24.287700653076172, Correct predictions: 555, Correct predictions train: 443\n",
      "Epoch 580, Loss: 1.5011662244796753, Correct predictions: 1092, Correct predictions train: 868\n",
      "Epoch 590, Loss: 31.566211700439453, Correct predictions: 1296, Correct predictions train: 1026\n",
      "Epoch 600, Loss: 1.555856466293335, Correct predictions: 737, Correct predictions train: 583\n",
      "Epoch 610, Loss: 6.904516696929932, Correct predictions: 1332, Correct predictions train: 1078\n",
      "Epoch 620, Loss: 29.85977554321289, Correct predictions: 835, Correct predictions train: 666\n",
      "Epoch 630, Loss: 4.268700122833252, Correct predictions: 4950, Correct predictions train: 3986\n",
      "Epoch 640, Loss: 39.150150299072266, Correct predictions: 1254, Correct predictions train: 1018\n",
      "Epoch 650, Loss: 9.663623809814453, Correct predictions: 634, Correct predictions train: 515\n",
      "Epoch 660, Loss: 0.05184241384267807, Correct predictions: 1273, Correct predictions train: 1026\n",
      "Epoch 670, Loss: 308.99505615234375, Correct predictions: 660, Correct predictions train: 520\n",
      "Epoch 680, Loss: 6.009542942047119, Correct predictions: 844, Correct predictions train: 682\n",
      "Epoch 690, Loss: 52.844459533691406, Correct predictions: 566, Correct predictions train: 448\n",
      "Epoch 700, Loss: 11.545685768127441, Correct predictions: 278, Correct predictions train: 223\n",
      "Epoch 710, Loss: 7.203139305114746, Correct predictions: 1657, Correct predictions train: 1327\n",
      "Epoch 720, Loss: 139.52845764160156, Correct predictions: 554, Correct predictions train: 453\n",
      "Epoch 730, Loss: 0.4309540390968323, Correct predictions: 2206, Correct predictions train: 1761\n",
      "Epoch 740, Loss: 12.218578338623047, Correct predictions: 2012, Correct predictions train: 1607\n",
      "Epoch 750, Loss: 20.34782600402832, Correct predictions: 1187, Correct predictions train: 935\n",
      "Epoch 760, Loss: 1.7387466430664062, Correct predictions: 1441, Correct predictions train: 1148\n",
      "Epoch 770, Loss: 9.522216796875, Correct predictions: 628, Correct predictions train: 506\n",
      "Epoch 780, Loss: 0.01922973059117794, Correct predictions: 1440, Correct predictions train: 1132\n",
      "Epoch 790, Loss: 0.698797881603241, Correct predictions: 3692, Correct predictions train: 2969\n",
      "Epoch 800, Loss: 1.1404640674591064, Correct predictions: 967, Correct predictions train: 775\n",
      "Epoch 810, Loss: 0.8233934640884399, Correct predictions: 957, Correct predictions train: 760\n",
      "Epoch 820, Loss: 74.02710723876953, Correct predictions: 1250, Correct predictions train: 1002\n",
      "Epoch 830, Loss: 1.2753671407699585, Correct predictions: 2058, Correct predictions train: 1653\n",
      "Epoch 840, Loss: 7.691579818725586, Correct predictions: 2348, Correct predictions train: 1872\n",
      "Epoch 850, Loss: 6.584853172302246, Correct predictions: 2259, Correct predictions train: 1827\n",
      "Epoch 860, Loss: 0.010201471857726574, Correct predictions: 1011, Correct predictions train: 804\n",
      "Epoch 870, Loss: 0.4059070348739624, Correct predictions: 2228, Correct predictions train: 1810\n",
      "Epoch 880, Loss: 3.488650321960449, Correct predictions: 2867, Correct predictions train: 2280\n",
      "Epoch 890, Loss: 1.3798935413360596, Correct predictions: 3876, Correct predictions train: 3104\n",
      "Epoch 900, Loss: 8.448246002197266, Correct predictions: 958, Correct predictions train: 759\n",
      "Epoch 910, Loss: 20.18604278564453, Correct predictions: 1258, Correct predictions train: 996\n",
      "Epoch 920, Loss: 65.328369140625, Correct predictions: 1110, Correct predictions train: 885\n",
      "Epoch 930, Loss: 2.067293643951416, Correct predictions: 2625, Correct predictions train: 2091\n",
      "Epoch 940, Loss: 0.002291950862854719, Correct predictions: 3438, Correct predictions train: 2734\n",
      "Epoch 950, Loss: 12.672298431396484, Correct predictions: 1994, Correct predictions train: 1600\n",
      "Epoch 960, Loss: 0.7252183556556702, Correct predictions: 2987, Correct predictions train: 2411\n",
      "Epoch 970, Loss: 5.309414386749268, Correct predictions: 2914, Correct predictions train: 2351\n",
      "Epoch 980, Loss: 0.34985673427581787, Correct predictions: 3324, Correct predictions train: 2633\n",
      "Epoch 990, Loss: 3.5900206565856934, Correct predictions: 1642, Correct predictions train: 1303\n",
      "Saved trained_model_2024_12_17_01_23_39.json\n",
      "Loaded trainable_model_2024_12_17_01_23_41.json\n",
      "Epoch 0, Loss: 674386.5, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 11512.453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 1180.8865966796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 1454.968994140625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 40, Loss: 1426.2320556640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 1288.5372314453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 2796.374267578125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 13592.02734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 17507.2265625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 2420.28564453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 41406.4140625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 1302.783935546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 6801.91552734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 8490.4521484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 20693.88671875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 1072.539306640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 160, Loss: 14280.1171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 10001.783203125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 902.4891357421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 3531.435791015625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 2245.678955078125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 2769.337646484375, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 2289.26904296875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 230, Loss: 1533.8538818359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 1171.0595703125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 250, Loss: 4392.59521484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 227.1544952392578, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 259.11907958984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 2622.28564453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 5153.478515625, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 1235.336181640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 307.76824951171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 238.54029846191406, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 343.79669189453125, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 340, Loss: 4298.57763671875, Correct predictions: 37, Correct predictions train: 26\n",
      "Epoch 350, Loss: 5137.7158203125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 21.71738624572754, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 370, Loss: 1063.37158203125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 834.581787109375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 390, Loss: 5.639755725860596, Correct predictions: 99, Correct predictions train: 80\n",
      "Epoch 400, Loss: 3.5559916496276855, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 410, Loss: 33.22189712524414, Correct predictions: 201, Correct predictions train: 163\n",
      "Epoch 420, Loss: 2497.7314453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 430, Loss: 192.52532958984375, Correct predictions: 6, Correct predictions train: 6\n",
      "Epoch 440, Loss: 321.65106201171875, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 450, Loss: 684.667236328125, Correct predictions: 68, Correct predictions train: 51\n",
      "Epoch 460, Loss: 3.9386918544769287, Correct predictions: 52, Correct predictions train: 37\n",
      "Epoch 470, Loss: 639.356689453125, Correct predictions: 52, Correct predictions train: 38\n",
      "Epoch 480, Loss: 360.6860656738281, Correct predictions: 189, Correct predictions train: 156\n",
      "Epoch 490, Loss: 2738.837158203125, Correct predictions: 5, Correct predictions train: 5\n",
      "Epoch 500, Loss: 0.45166897773742676, Correct predictions: 144, Correct predictions train: 106\n",
      "Epoch 510, Loss: 50.37641906738281, Correct predictions: 248, Correct predictions train: 210\n",
      "Epoch 520, Loss: 426.1455078125, Correct predictions: 131, Correct predictions train: 112\n",
      "Epoch 530, Loss: 21.08407974243164, Correct predictions: 258, Correct predictions train: 204\n",
      "Epoch 540, Loss: 156.87200927734375, Correct predictions: 21, Correct predictions train: 19\n",
      "Epoch 550, Loss: 0.5921155214309692, Correct predictions: 481, Correct predictions train: 378\n",
      "Epoch 560, Loss: 1.2088990211486816, Correct predictions: 1079, Correct predictions train: 883\n",
      "Epoch 570, Loss: 152.82571411132812, Correct predictions: 192, Correct predictions train: 146\n",
      "Epoch 580, Loss: 7.747129440307617, Correct predictions: 413, Correct predictions train: 332\n",
      "Epoch 590, Loss: 201.9236297607422, Correct predictions: 370, Correct predictions train: 296\n",
      "Epoch 600, Loss: 13.069992065429688, Correct predictions: 277, Correct predictions train: 207\n",
      "Epoch 610, Loss: 45.05329895019531, Correct predictions: 466, Correct predictions train: 384\n",
      "Epoch 620, Loss: 163.800048828125, Correct predictions: 253, Correct predictions train: 204\n",
      "Epoch 630, Loss: 18.644588470458984, Correct predictions: 1629, Correct predictions train: 1306\n",
      "Epoch 640, Loss: 222.26614379882812, Correct predictions: 55, Correct predictions train: 48\n",
      "Epoch 650, Loss: 66.70489501953125, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 660, Loss: 0.6780318021774292, Correct predictions: 503, Correct predictions train: 409\n",
      "Epoch 670, Loss: 1835.796142578125, Correct predictions: 224, Correct predictions train: 181\n",
      "Epoch 680, Loss: 36.67923355102539, Correct predictions: 370, Correct predictions train: 295\n",
      "Epoch 690, Loss: 310.2317199707031, Correct predictions: 233, Correct predictions train: 182\n",
      "Epoch 700, Loss: 69.18301391601562, Correct predictions: 153, Correct predictions train: 118\n",
      "Epoch 710, Loss: 41.064449310302734, Correct predictions: 682, Correct predictions train: 536\n",
      "Epoch 720, Loss: 816.9100952148438, Correct predictions: 249, Correct predictions train: 201\n",
      "Epoch 730, Loss: 2.1972994804382324, Correct predictions: 1019, Correct predictions train: 809\n",
      "Epoch 740, Loss: 72.13029479980469, Correct predictions: 762, Correct predictions train: 596\n",
      "Epoch 750, Loss: 120.67231750488281, Correct predictions: 475, Correct predictions train: 373\n",
      "Epoch 760, Loss: 12.057962417602539, Correct predictions: 578, Correct predictions train: 461\n",
      "Epoch 770, Loss: 56.50126647949219, Correct predictions: 224, Correct predictions train: 182\n",
      "Epoch 780, Loss: 0.1420898735523224, Correct predictions: 451, Correct predictions train: 351\n",
      "Epoch 790, Loss: 3.7758383750915527, Correct predictions: 1172, Correct predictions train: 937\n",
      "Epoch 800, Loss: 6.430330753326416, Correct predictions: 219, Correct predictions train: 178\n",
      "Epoch 810, Loss: 4.596574783325195, Correct predictions: 275, Correct predictions train: 220\n",
      "Epoch 820, Loss: 435.946044921875, Correct predictions: 458, Correct predictions train: 364\n",
      "Epoch 830, Loss: 7.429971218109131, Correct predictions: 746, Correct predictions train: 613\n",
      "Epoch 840, Loss: 45.71156311035156, Correct predictions: 876, Correct predictions train: 692\n",
      "Epoch 850, Loss: 39.72305679321289, Correct predictions: 840, Correct predictions train: 691\n",
      "Epoch 860, Loss: 0.06925758719444275, Correct predictions: 345, Correct predictions train: 276\n",
      "Epoch 870, Loss: 2.2966997623443604, Correct predictions: 894, Correct predictions train: 723\n",
      "Epoch 880, Loss: 20.503847122192383, Correct predictions: 1131, Correct predictions train: 884\n",
      "Epoch 890, Loss: 8.064179420471191, Correct predictions: 1246, Correct predictions train: 988\n",
      "Epoch 900, Loss: 49.79245376586914, Correct predictions: 294, Correct predictions train: 241\n",
      "Epoch 910, Loss: 118.92943572998047, Correct predictions: 441, Correct predictions train: 355\n",
      "Epoch 920, Loss: 385.5176696777344, Correct predictions: 220, Correct predictions train: 186\n",
      "Epoch 930, Loss: 12.13296890258789, Correct predictions: 561, Correct predictions train: 439\n",
      "Epoch 940, Loss: 0.009753084741532803, Correct predictions: 1205, Correct predictions train: 965\n",
      "Epoch 950, Loss: 74.90656280517578, Correct predictions: 902, Correct predictions train: 722\n",
      "Epoch 960, Loss: 4.342006206512451, Correct predictions: 1152, Correct predictions train: 921\n",
      "Epoch 970, Loss: 31.54743194580078, Correct predictions: 1432, Correct predictions train: 1163\n",
      "Epoch 980, Loss: 2.052577018737793, Correct predictions: 1204, Correct predictions train: 960\n",
      "Epoch 990, Loss: 21.251955032348633, Correct predictions: 460, Correct predictions train: 356\n",
      "Saved trained_model_2024_12_17_01_23_41.json\n",
      "Loaded trainable_model_2024_12_17_01_23_43.json\n",
      "Epoch 0, Loss: 219366.796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 35656.51171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 996.424072265625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 3089.61865234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 40, Loss: 868.0173950195312, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 1482.1549072265625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 1647.2161865234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 14285.193359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 8163.236328125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 3961.1708984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 20255.373046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 2057.234130859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 9638.1845703125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 3929.88671875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 10376.427734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 1502.9373779296875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 160, Loss: 7190.31005859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 5717.5322265625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 1017.2688598632812, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 3343.32666015625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 1142.6787109375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 2183.14453125, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 2318.88720703125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 230, Loss: 1610.81884765625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 932.7352294921875, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 2707.1171875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 234.16146850585938, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 121.39202880859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 1236.1947021484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 4036.962890625, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 765.7808227539062, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 270.8032531738281, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 390.7803649902344, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 188.29318237304688, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 340, Loss: 2902.39599609375, Correct predictions: 51, Correct predictions train: 36\n",
      "Epoch 350, Loss: 3530.952392578125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 20.223243713378906, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 370, Loss: 684.5789794921875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 471.7917785644531, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 390, Loss: 2.7683229446411133, Correct predictions: 103, Correct predictions train: 83\n",
      "Epoch 400, Loss: 5.490733623504639, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 410, Loss: 25.249717712402344, Correct predictions: 237, Correct predictions train: 183\n",
      "Epoch 420, Loss: 1781.6749267578125, Correct predictions: 15, Correct predictions train: 11\n",
      "Epoch 430, Loss: 116.64520263671875, Correct predictions: 6, Correct predictions train: 6\n",
      "Epoch 440, Loss: 193.80673217773438, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 450, Loss: 505.1397399902344, Correct predictions: 62, Correct predictions train: 46\n",
      "Epoch 460, Loss: 6.402286529541016, Correct predictions: 7, Correct predictions train: 4\n",
      "Epoch 470, Loss: 443.96295166015625, Correct predictions: 126, Correct predictions train: 96\n",
      "Epoch 480, Loss: 241.02325439453125, Correct predictions: 196, Correct predictions train: 164\n",
      "Epoch 490, Loss: 1985.599853515625, Correct predictions: 25, Correct predictions train: 20\n",
      "Epoch 500, Loss: 0.6696515083312988, Correct predictions: 128, Correct predictions train: 98\n",
      "Epoch 510, Loss: 41.295169830322266, Correct predictions: 302, Correct predictions train: 249\n",
      "Epoch 520, Loss: 304.32843017578125, Correct predictions: 205, Correct predictions train: 165\n",
      "Epoch 530, Loss: 13.837757110595703, Correct predictions: 381, Correct predictions train: 303\n",
      "Epoch 540, Loss: 106.15574645996094, Correct predictions: 36, Correct predictions train: 32\n",
      "Epoch 550, Loss: 0.9473819732666016, Correct predictions: 582, Correct predictions train: 461\n",
      "Epoch 560, Loss: 0.7048943042755127, Correct predictions: 1060, Correct predictions train: 868\n",
      "Epoch 570, Loss: 106.18894958496094, Correct predictions: 303, Correct predictions train: 236\n",
      "Epoch 580, Loss: 5.727161884307861, Correct predictions: 598, Correct predictions train: 471\n",
      "Epoch 590, Loss: 139.599365234375, Correct predictions: 535, Correct predictions train: 418\n",
      "Epoch 600, Loss: 8.326374053955078, Correct predictions: 371, Correct predictions train: 282\n",
      "Epoch 610, Loss: 30.95953941345215, Correct predictions: 601, Correct predictions train: 493\n",
      "Epoch 620, Loss: 118.76624298095703, Correct predictions: 335, Correct predictions train: 268\n",
      "Epoch 630, Loss: 14.556228637695312, Correct predictions: 2365, Correct predictions train: 1888\n",
      "Epoch 640, Loss: 159.43045043945312, Correct predictions: 55, Correct predictions train: 48\n",
      "Epoch 650, Loss: 45.06414794921875, Correct predictions: 370, Correct predictions train: 301\n",
      "Epoch 660, Loss: 0.372839093208313, Correct predictions: 706, Correct predictions train: 570\n",
      "Epoch 670, Loss: 1298.3233642578125, Correct predictions: 279, Correct predictions train: 221\n",
      "Epoch 680, Loss: 25.725557327270508, Correct predictions: 690, Correct predictions train: 562\n",
      "Epoch 690, Loss: 220.2177734375, Correct predictions: 289, Correct predictions train: 223\n",
      "Epoch 700, Loss: 48.799072265625, Correct predictions: 161, Correct predictions train: 124\n",
      "Epoch 710, Loss: 29.41707992553711, Correct predictions: 924, Correct predictions train: 736\n",
      "Epoch 720, Loss: 580.370361328125, Correct predictions: 396, Correct predictions train: 317\n",
      "Epoch 730, Loss: 1.630685567855835, Correct predictions: 1119, Correct predictions train: 888\n",
      "Epoch 740, Loss: 51.11357116699219, Correct predictions: 1190, Correct predictions train: 936\n",
      "Epoch 750, Loss: 85.39031982421875, Correct predictions: 642, Correct predictions train: 514\n",
      "Epoch 760, Loss: 8.134641647338867, Correct predictions: 808, Correct predictions train: 650\n",
      "Epoch 770, Loss: 39.97492980957031, Correct predictions: 360, Correct predictions train: 290\n",
      "Epoch 780, Loss: 0.09404963254928589, Correct predictions: 714, Correct predictions train: 555\n",
      "Epoch 790, Loss: 2.750844955444336, Correct predictions: 1761, Correct predictions train: 1413\n",
      "Epoch 800, Loss: 4.622379302978516, Correct predictions: 413, Correct predictions train: 339\n",
      "Epoch 810, Loss: 3.3145480155944824, Correct predictions: 360, Correct predictions train: 285\n",
      "Epoch 820, Loss: 309.1564636230469, Correct predictions: 703, Correct predictions train: 556\n",
      "Epoch 830, Loss: 5.286762237548828, Correct predictions: 1155, Correct predictions train: 941\n",
      "Epoch 840, Loss: 32.325260162353516, Correct predictions: 1414, Correct predictions train: 1125\n",
      "Epoch 850, Loss: 27.961013793945312, Correct predictions: 1293, Correct predictions train: 1053\n",
      "Epoch 860, Loss: 0.047023314982652664, Correct predictions: 603, Correct predictions train: 486\n",
      "Epoch 870, Loss: 1.6491552591323853, Correct predictions: 1252, Correct predictions train: 1008\n",
      "Epoch 880, Loss: 14.549539566040039, Correct predictions: 1569, Correct predictions train: 1229\n",
      "Epoch 890, Loss: 5.732433319091797, Correct predictions: 1879, Correct predictions train: 1495\n",
      "Epoch 900, Loss: 35.301979064941406, Correct predictions: 467, Correct predictions train: 385\n",
      "Epoch 910, Loss: 84.32847595214844, Correct predictions: 714, Correct predictions train: 566\n",
      "Epoch 920, Loss: 273.21868896484375, Correct predictions: 812, Correct predictions train: 660\n",
      "Epoch 930, Loss: 8.613334655761719, Correct predictions: 1084, Correct predictions train: 865\n",
      "Epoch 940, Loss: 0.007681619375944138, Correct predictions: 2008, Correct predictions train: 1625\n",
      "Epoch 950, Loss: 53.059410095214844, Correct predictions: 1124, Correct predictions train: 894\n",
      "Epoch 960, Loss: 3.063462495803833, Correct predictions: 1669, Correct predictions train: 1340\n",
      "Epoch 970, Loss: 22.31045913696289, Correct predictions: 2124, Correct predictions train: 1717\n",
      "Epoch 980, Loss: 1.4573087692260742, Correct predictions: 1700, Correct predictions train: 1346\n",
      "Epoch 990, Loss: 15.046786308288574, Correct predictions: 774, Correct predictions train: 609\n",
      "Saved trained_model_2024_12_17_01_23_43.json\n",
      "Loaded trainable_model_2024_12_17_01_23_45.json\n",
      "Epoch 0, Loss: 66987.3125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 32293.5859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 480.9275817871094, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 672.4862060546875, Correct predictions: 13, Correct predictions train: 11\n",
      "Epoch 40, Loss: 554.5540771484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 145.55438232421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 1067.256591796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 1449.236083984375, Correct predictions: 31, Correct predictions train: 22\n",
      "Epoch 80, Loss: 5208.3740234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 649.539306640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 13405.93359375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 516.149169921875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 1078.1519775390625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 1985.3958740234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 4030.755859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 481.28411865234375, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 160, Loss: 2761.43115234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 1603.459228515625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 423.5624084472656, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 371.6688232421875, Correct predictions: 13, Correct predictions train: 9\n",
      "Epoch 200, Loss: 426.6103515625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 317.13873291015625, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 241.4715118408203, Correct predictions: 13, Correct predictions train: 9\n",
      "Epoch 230, Loss: 163.49560546875, Correct predictions: 21, Correct predictions train: 15\n",
      "Epoch 240, Loss: 133.10377502441406, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 641.1597290039062, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 260, Loss: 24.061826705932617, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 77.94876098632812, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 580.2998046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 592.9781494140625, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 179.07418823242188, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 33.043643951416016, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 84.04707336425781, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 58.41167449951172, Correct predictions: 6, Correct predictions train: 6\n",
      "Epoch 340, Loss: 566.5300903320312, Correct predictions: 87, Correct predictions train: 61\n",
      "Epoch 350, Loss: 664.8360595703125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 2.291644811630249, Correct predictions: 105, Correct predictions train: 84\n",
      "Epoch 370, Loss: 147.58665466308594, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 380, Loss: 135.7890167236328, Correct predictions: 57, Correct predictions train: 48\n",
      "Epoch 390, Loss: 1.142106533050537, Correct predictions: 304, Correct predictions train: 236\n",
      "Epoch 400, Loss: 1.4635344743728638, Correct predictions: 14, Correct predictions train: 9\n",
      "Epoch 410, Loss: 3.9154014587402344, Correct predictions: 462, Correct predictions train: 370\n",
      "Epoch 420, Loss: 311.54608154296875, Correct predictions: 23, Correct predictions train: 18\n",
      "Epoch 430, Loss: 28.682998657226562, Correct predictions: 28, Correct predictions train: 24\n",
      "Epoch 440, Loss: 48.24342346191406, Correct predictions: 84, Correct predictions train: 68\n",
      "Epoch 450, Loss: 82.78010559082031, Correct predictions: 118, Correct predictions train: 94\n",
      "Epoch 460, Loss: 1.4404813051223755, Correct predictions: 109, Correct predictions train: 86\n",
      "Epoch 470, Loss: 81.87580871582031, Correct predictions: 279, Correct predictions train: 222\n",
      "Epoch 480, Loss: 48.06004333496094, Correct predictions: 452, Correct predictions train: 371\n",
      "Epoch 490, Loss: 336.44952392578125, Correct predictions: 41, Correct predictions train: 33\n",
      "Epoch 500, Loss: 0.08068375289440155, Correct predictions: 658, Correct predictions train: 495\n",
      "Epoch 510, Loss: 5.615299701690674, Correct predictions: 799, Correct predictions train: 649\n",
      "Epoch 520, Loss: 53.09516143798828, Correct predictions: 583, Correct predictions train: 471\n",
      "Epoch 530, Loss: 2.8644771575927734, Correct predictions: 818, Correct predictions train: 656\n",
      "Epoch 540, Loss: 20.626789093017578, Correct predictions: 165, Correct predictions train: 135\n",
      "Epoch 550, Loss: 0.1391606628894806, Correct predictions: 2011, Correct predictions train: 1610\n",
      "Epoch 560, Loss: 0.18890544772148132, Correct predictions: 1160, Correct predictions train: 947\n",
      "Epoch 570, Loss: 19.55819320678711, Correct predictions: 612, Correct predictions train: 484\n",
      "Epoch 580, Loss: 0.9350117444992065, Correct predictions: 1309, Correct predictions train: 1039\n",
      "Epoch 590, Loss: 25.972776412963867, Correct predictions: 1404, Correct predictions train: 1122\n",
      "Epoch 600, Loss: 1.8356399536132812, Correct predictions: 965, Correct predictions train: 773\n",
      "Epoch 610, Loss: 5.8307647705078125, Correct predictions: 1682, Correct predictions train: 1354\n",
      "Epoch 620, Loss: 20.119537353515625, Correct predictions: 993, Correct predictions train: 798\n",
      "Epoch 630, Loss: 2.1508145332336426, Correct predictions: 4092, Correct predictions train: 3288\n",
      "Epoch 640, Loss: 27.577470779418945, Correct predictions: 1418, Correct predictions train: 1148\n",
      "Epoch 650, Loss: 8.786205291748047, Correct predictions: 646, Correct predictions train: 526\n",
      "Epoch 660, Loss: 0.11455428600311279, Correct predictions: 1583, Correct predictions train: 1262\n",
      "Epoch 670, Loss: 230.88037109375, Correct predictions: 795, Correct predictions train: 619\n",
      "Epoch 680, Loss: 4.650695323944092, Correct predictions: 1090, Correct predictions train: 878\n",
      "Epoch 690, Loss: 38.8770751953125, Correct predictions: 867, Correct predictions train: 681\n",
      "Epoch 700, Loss: 8.723243713378906, Correct predictions: 357, Correct predictions train: 283\n",
      "Epoch 710, Loss: 5.101285934448242, Correct predictions: 1900, Correct predictions train: 1526\n",
      "Epoch 720, Loss: 102.28924560546875, Correct predictions: 678, Correct predictions train: 552\n",
      "Epoch 730, Loss: 0.26428738236427307, Correct predictions: 3115, Correct predictions train: 2494\n",
      "Epoch 740, Loss: 9.054139137268066, Correct predictions: 2691, Correct predictions train: 2153\n",
      "Epoch 750, Loss: 15.168231964111328, Correct predictions: 1536, Correct predictions train: 1219\n",
      "Epoch 760, Loss: 1.5905838012695312, Correct predictions: 2040, Correct predictions train: 1617\n",
      "Epoch 770, Loss: 7.10321044921875, Correct predictions: 1008, Correct predictions train: 796\n",
      "Epoch 780, Loss: 0.019127193838357925, Correct predictions: 2205, Correct predictions train: 1770\n",
      "Epoch 790, Loss: 0.46175193786621094, Correct predictions: 5440, Correct predictions train: 4366\n",
      "Epoch 800, Loss: 0.7962181568145752, Correct predictions: 1444, Correct predictions train: 1149\n",
      "Epoch 810, Loss: 0.5674938559532166, Correct predictions: 1194, Correct predictions train: 944\n",
      "Epoch 820, Loss: 54.68218231201172, Correct predictions: 1697, Correct predictions train: 1356\n",
      "Epoch 830, Loss: 0.9289588928222656, Correct predictions: 2788, Correct predictions train: 2236\n",
      "Epoch 840, Loss: 5.749501705169678, Correct predictions: 3045, Correct predictions train: 2424\n",
      "Epoch 850, Loss: 5.01882266998291, Correct predictions: 2853, Correct predictions train: 2293\n",
      "Epoch 860, Loss: 0.009074809029698372, Correct predictions: 1251, Correct predictions train: 999\n",
      "Epoch 870, Loss: 0.28467708826065063, Correct predictions: 2761, Correct predictions train: 2233\n",
      "Epoch 880, Loss: 2.5703351497650146, Correct predictions: 3598, Correct predictions train: 2889\n",
      "Epoch 890, Loss: 1.0092010498046875, Correct predictions: 4805, Correct predictions train: 3845\n",
      "Epoch 900, Loss: 6.247165203094482, Correct predictions: 1612, Correct predictions train: 1278\n",
      "Epoch 910, Loss: 14.919744491577148, Correct predictions: 1438, Correct predictions train: 1144\n",
      "Epoch 920, Loss: 48.386810302734375, Correct predictions: 2010, Correct predictions train: 1590\n",
      "Epoch 930, Loss: 1.5203303098678589, Correct predictions: 3813, Correct predictions train: 3038\n",
      "Epoch 940, Loss: 0.0011176185216754675, Correct predictions: 4728, Correct predictions train: 3772\n",
      "Epoch 950, Loss: 9.406312942504883, Correct predictions: 2556, Correct predictions train: 2072\n",
      "Epoch 960, Loss: 0.5473468899726868, Correct predictions: 3851, Correct predictions train: 3097\n",
      "Epoch 970, Loss: 3.9677155017852783, Correct predictions: 3430, Correct predictions train: 2774\n",
      "Epoch 980, Loss: 0.25717228651046753, Correct predictions: 4394, Correct predictions train: 3501\n",
      "Epoch 990, Loss: 2.6698665618896484, Correct predictions: 2312, Correct predictions train: 1841\n",
      "Saved trained_model_2024_12_17_01_23_45.json\n",
      "Loaded trainable_model_2024_12_17_01_23_47.json\n",
      "Epoch 0, Loss: 337293.5, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 47473.0859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 2887.096923828125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 2443.10107421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 40, Loss: 3109.521240234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 296.08782958984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 5940.0947265625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 2350.11474609375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 26275.3671875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 3403.140869140625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 70137.484375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 3033.719482421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 3987.5634765625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 8814.314453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 15692.58203125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 2887.8251953125, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 160, Loss: 10686.2578125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 5151.2578125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 2540.2587890625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 538.5173950195312, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 1626.1435546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 565.0181274414062, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 368.10833740234375, Correct predictions: 48, Correct predictions train: 34\n",
      "Epoch 230, Loss: 264.7237243652344, Correct predictions: 21, Correct predictions train: 15\n",
      "Epoch 240, Loss: 232.59274291992188, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 1823.990478515625, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 260, Loss: 37.6700439453125, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 395.205810546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 2485.667724609375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 1069.3094482421875, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 504.40185546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 310, Loss: 49.61691665649414, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 480.91339111328125, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 330, Loss: 200.17642211914062, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 340, Loss: 1367.87109375, Correct predictions: 51, Correct predictions train: 36\n",
      "Epoch 350, Loss: 1551.838623046875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 3.3215737342834473, Correct predictions: 11, Correct predictions train: 10\n",
      "Epoch 370, Loss: 389.0806884765625, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 380, Loss: 443.77056884765625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 390, Loss: 4.587416648864746, Correct predictions: 175, Correct predictions train: 142\n",
      "Epoch 400, Loss: 8.665380477905273, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 410, Loss: 7.48977518081665, Correct predictions: 230, Correct predictions train: 183\n",
      "Epoch 420, Loss: 676.1875610351562, Correct predictions: 5, Correct predictions train: 2\n",
      "Epoch 430, Loss: 83.96607971191406, Correct predictions: 10, Correct predictions train: 8\n",
      "Epoch 440, Loss: 142.51962280273438, Correct predictions: 17, Correct predictions train: 14\n",
      "Epoch 450, Loss: 168.0004425048828, Correct predictions: 36, Correct predictions train: 30\n",
      "Epoch 460, Loss: 8.318514823913574, Correct predictions: 22, Correct predictions train: 16\n",
      "Epoch 470, Loss: 187.333251953125, Correct predictions: 126, Correct predictions train: 96\n",
      "Epoch 480, Loss: 118.32744598388672, Correct predictions: 224, Correct predictions train: 184\n",
      "Epoch 490, Loss: 707.0992431640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 500, Loss: 0.33376288414001465, Correct predictions: 93, Correct predictions train: 70\n",
      "Epoch 510, Loss: 9.319633483886719, Correct predictions: 341, Correct predictions train: 277\n",
      "Epoch 520, Loss: 114.9757080078125, Correct predictions: 243, Correct predictions train: 197\n",
      "Epoch 530, Loss: 7.291994094848633, Correct predictions: 443, Correct predictions train: 352\n",
      "Epoch 540, Loss: 49.59309005737305, Correct predictions: 147, Correct predictions train: 120\n",
      "Epoch 550, Loss: 0.6869836449623108, Correct predictions: 846, Correct predictions train: 678\n",
      "Epoch 560, Loss: 0.5883967876434326, Correct predictions: 721, Correct predictions train: 585\n",
      "Epoch 570, Loss: 44.693607330322266, Correct predictions: 303, Correct predictions train: 236\n",
      "Epoch 580, Loss: 1.8900364637374878, Correct predictions: 683, Correct predictions train: 540\n",
      "Epoch 590, Loss: 59.93459701538086, Correct predictions: 1119, Correct predictions train: 888\n",
      "Epoch 600, Loss: 4.930621147155762, Correct predictions: 429, Correct predictions train: 340\n",
      "Epoch 610, Loss: 13.613210678100586, Correct predictions: 900, Correct predictions train: 732\n",
      "Epoch 620, Loss: 42.273780822753906, Correct predictions: 563, Correct predictions train: 456\n",
      "Epoch 630, Loss: 3.9036660194396973, Correct predictions: 1944, Correct predictions train: 1563\n",
      "Epoch 640, Loss: 59.198974609375, Correct predictions: 565, Correct predictions train: 458\n",
      "Epoch 650, Loss: 21.191631317138672, Correct predictions: 388, Correct predictions train: 319\n",
      "Epoch 660, Loss: 0.39025670289993286, Correct predictions: 835, Correct predictions train: 673\n",
      "Epoch 670, Loss: 509.6622009277344, Correct predictions: 415, Correct predictions train: 339\n",
      "Epoch 680, Loss: 10.435419082641602, Correct predictions: 730, Correct predictions train: 594\n",
      "Epoch 690, Loss: 85.1961669921875, Correct predictions: 434, Correct predictions train: 343\n",
      "Epoch 700, Loss: 19.356599807739258, Correct predictions: 163, Correct predictions train: 126\n",
      "Epoch 710, Loss: 10.978870391845703, Correct predictions: 1100, Correct predictions train: 879\n",
      "Epoch 720, Loss: 223.78781127929688, Correct predictions: 402, Correct predictions train: 322\n",
      "Epoch 730, Loss: 0.5301101803779602, Correct predictions: 1419, Correct predictions train: 1124\n",
      "Epoch 740, Loss: 19.90895652770996, Correct predictions: 1310, Correct predictions train: 1037\n",
      "Epoch 750, Loss: 33.44668197631836, Correct predictions: 738, Correct predictions train: 581\n",
      "Epoch 760, Loss: 3.8465769290924072, Correct predictions: 971, Correct predictions train: 782\n",
      "Epoch 770, Loss: 15.667989730834961, Correct predictions: 483, Correct predictions train: 391\n",
      "Epoch 780, Loss: 0.047935809940099716, Correct predictions: 837, Correct predictions train: 652\n",
      "Epoch 790, Loss: 0.9610114097595215, Correct predictions: 2336, Correct predictions train: 1877\n",
      "Epoch 800, Loss: 1.7019087076187134, Correct predictions: 609, Correct predictions train: 494\n",
      "Epoch 810, Loss: 1.2055050134658813, Correct predictions: 501, Correct predictions train: 399\n",
      "Epoch 820, Loss: 120.0611343383789, Correct predictions: 759, Correct predictions train: 604\n",
      "Epoch 830, Loss: 2.0261647701263428, Correct predictions: 1625, Correct predictions train: 1320\n",
      "Epoch 840, Loss: 12.694334983825684, Correct predictions: 1735, Correct predictions train: 1371\n",
      "Epoch 850, Loss: 11.182071685791016, Correct predictions: 1510, Correct predictions train: 1219\n",
      "Epoch 860, Loss: 0.02168041467666626, Correct predictions: 769, Correct predictions train: 611\n",
      "Epoch 870, Loss: 0.6098252534866333, Correct predictions: 1473, Correct predictions train: 1184\n",
      "Epoch 880, Loss: 5.636597633361816, Correct predictions: 1800, Correct predictions train: 1425\n",
      "Epoch 890, Loss: 2.2054405212402344, Correct predictions: 2296, Correct predictions train: 1840\n",
      "Epoch 900, Loss: 13.723222732543945, Correct predictions: 558, Correct predictions train: 452\n",
      "Epoch 910, Loss: 32.76704025268555, Correct predictions: 922, Correct predictions train: 728\n",
      "Epoch 920, Loss: 106.37358093261719, Correct predictions: 1108, Correct predictions train: 885\n",
      "Epoch 930, Loss: 3.3311150074005127, Correct predictions: 1510, Correct predictions train: 1201\n",
      "Epoch 940, Loss: 0.001994551159441471, Correct predictions: 2463, Correct predictions train: 1988\n",
      "Epoch 950, Loss: 20.69985008239746, Correct predictions: 1439, Correct predictions train: 1151\n",
      "Epoch 960, Loss: 1.213940143585205, Correct predictions: 2029, Correct predictions train: 1634\n",
      "Epoch 970, Loss: 8.759178161621094, Correct predictions: 2313, Correct predictions train: 1869\n",
      "Epoch 980, Loss: 0.563352108001709, Correct predictions: 2224, Correct predictions train: 1768\n",
      "Epoch 990, Loss: 5.880674362182617, Correct predictions: 974, Correct predictions train: 769\n",
      "Saved trained_model_2024_12_17_01_23_47.json\n",
      "Loaded trainable_model_2024_12_17_01_23_49.json\n",
      "Epoch 0, Loss: 65683.3125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 3529.31591796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 4506.58447265625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 3322.26806640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 40, Loss: 2592.55224609375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 949.9091186523438, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 4817.4990234375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 6998.705078125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 15613.5791015625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 6592.41015625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 46555.59375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 4637.81689453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 10439.2685546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 3560.341796875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 4149.0478515625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 3897.85009765625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 160, Loss: 2768.435546875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 706.8353881835938, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 2983.717529296875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 1139.234619140625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 200, Loss: 400.1610107421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 314.89984130859375, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 1007.3121948242188, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 230, Loss: 787.2415161132812, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 142.50912475585938, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 191.06472778320312, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 107.8062744140625, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 238.40037536621094, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 897.7999267578125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 561.7545166015625, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 52.430145263671875, Correct predictions: 91, Correct predictions train: 82\n",
      "Epoch 310, Loss: 68.11402893066406, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 797.1702880859375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 34.04594039916992, Correct predictions: 9, Correct predictions train: 8\n",
      "Epoch 340, Loss: 183.16806030273438, Correct predictions: 53, Correct predictions train: 38\n",
      "Epoch 350, Loss: 237.18338012695312, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 360, Loss: 6.460402965545654, Correct predictions: 40, Correct predictions train: 32\n",
      "Epoch 370, Loss: 41.44857406616211, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 64.31330108642578, Correct predictions: 64, Correct predictions train: 54\n",
      "Epoch 390, Loss: 1.3461302518844604, Correct predictions: 242, Correct predictions train: 191\n",
      "Epoch 400, Loss: 12.842127799987793, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 410, Loss: 2.9475836753845215, Correct predictions: 278, Correct predictions train: 221\n",
      "Epoch 420, Loss: 143.5404510498047, Correct predictions: 20, Correct predictions train: 16\n",
      "Epoch 430, Loss: 9.12753677368164, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 440, Loss: 15.742809295654297, Correct predictions: 20, Correct predictions train: 14\n",
      "Epoch 450, Loss: 49.43092346191406, Correct predictions: 84, Correct predictions train: 69\n",
      "Epoch 460, Loss: 13.46126651763916, Correct predictions: 23, Correct predictions train: 17\n",
      "Epoch 470, Loss: 31.187957763671875, Correct predictions: 356, Correct predictions train: 285\n",
      "Epoch 480, Loss: 14.817237854003906, Correct predictions: 463, Correct predictions train: 384\n",
      "Epoch 490, Loss: 175.33001708984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 500, Loss: 0.8116148114204407, Correct predictions: 178, Correct predictions train: 138\n",
      "Epoch 510, Loss: 7.366708278656006, Correct predictions: 669, Correct predictions train: 536\n",
      "Epoch 520, Loss: 24.674917221069336, Correct predictions: 396, Correct predictions train: 318\n",
      "Epoch 530, Loss: 0.8306228518486023, Correct predictions: 643, Correct predictions train: 518\n",
      "Epoch 540, Loss: 6.744395732879639, Correct predictions: 285, Correct predictions train: 227\n",
      "Epoch 550, Loss: 1.4301701784133911, Correct predictions: 992, Correct predictions train: 794\n",
      "Epoch 560, Loss: 0.07365886121988297, Correct predictions: 965, Correct predictions train: 786\n",
      "Epoch 570, Loss: 7.481793403625488, Correct predictions: 855, Correct predictions train: 685\n",
      "Epoch 580, Loss: 0.5671113133430481, Correct predictions: 1359, Correct predictions train: 1063\n",
      "Epoch 590, Loss: 9.615307807922363, Correct predictions: 1532, Correct predictions train: 1217\n",
      "Epoch 600, Loss: 0.5144866704940796, Correct predictions: 1127, Correct predictions train: 912\n",
      "Epoch 610, Loss: 2.0785911083221436, Correct predictions: 2082, Correct predictions train: 1690\n",
      "Epoch 620, Loss: 10.494665145874023, Correct predictions: 1051, Correct predictions train: 845\n",
      "Epoch 630, Loss: 1.9870471954345703, Correct predictions: 5220, Correct predictions train: 4197\n",
      "Epoch 640, Loss: 13.247686386108398, Correct predictions: 820, Correct predictions train: 665\n",
      "Epoch 650, Loss: 2.8486487865448, Correct predictions: 1320, Correct predictions train: 1070\n",
      "Epoch 660, Loss: 0.06503253430128098, Correct predictions: 1926, Correct predictions train: 1535\n",
      "Epoch 670, Loss: 99.87467956542969, Correct predictions: 993, Correct predictions train: 769\n",
      "Epoch 680, Loss: 1.8960729837417603, Correct predictions: 1509, Correct predictions train: 1212\n",
      "Epoch 690, Loss: 17.277772903442383, Correct predictions: 993, Correct predictions train: 774\n",
      "Epoch 700, Loss: 3.702397346496582, Correct predictions: 360, Correct predictions train: 285\n",
      "Epoch 710, Loss: 2.426671266555786, Correct predictions: 2112, Correct predictions train: 1710\n",
      "Epoch 720, Loss: 45.741119384765625, Correct predictions: 869, Correct predictions train: 694\n",
      "Epoch 730, Loss: 0.16523560881614685, Correct predictions: 3062, Correct predictions train: 2438\n",
      "Epoch 740, Loss: 3.973456382751465, Correct predictions: 3062, Correct predictions train: 2436\n",
      "Epoch 750, Loss: 6.588129043579102, Correct predictions: 1696, Correct predictions train: 1348\n",
      "Epoch 760, Loss: 0.5121200084686279, Correct predictions: 2138, Correct predictions train: 1689\n",
      "Epoch 770, Loss: 3.0815114974975586, Correct predictions: 1125, Correct predictions train: 885\n",
      "Epoch 780, Loss: 0.0056886132806539536, Correct predictions: 2345, Correct predictions train: 1882\n",
      "Epoch 790, Loss: 0.24991391599178314, Correct predictions: 5300, Correct predictions train: 4251\n",
      "Epoch 800, Loss: 0.3887772560119629, Correct predictions: 1554, Correct predictions train: 1239\n",
      "Epoch 810, Loss: 0.28376802802085876, Correct predictions: 1260, Correct predictions train: 992\n",
      "Epoch 820, Loss: 24.12999153137207, Correct predictions: 1828, Correct predictions train: 1465\n",
      "Epoch 830, Loss: 0.4201738238334656, Correct predictions: 2957, Correct predictions train: 2373\n",
      "Epoch 840, Loss: 2.4853618144989014, Correct predictions: 3359, Correct predictions train: 2683\n",
      "Epoch 850, Loss: 2.098827600479126, Correct predictions: 3098, Correct predictions train: 2491\n",
      "Epoch 860, Loss: 0.0030197601299732924, Correct predictions: 1312, Correct predictions train: 1046\n",
      "Epoch 870, Loss: 0.13784843683242798, Correct predictions: 2850, Correct predictions train: 2303\n",
      "Epoch 880, Loss: 1.1393705606460571, Correct predictions: 3853, Correct predictions train: 3089\n",
      "Epoch 890, Loss: 0.4531879425048828, Correct predictions: 4997, Correct predictions train: 4002\n",
      "Epoch 900, Loss: 2.7516274452209473, Correct predictions: 1735, Correct predictions train: 1377\n",
      "Epoch 910, Loss: 6.577005386352539, Correct predictions: 1547, Correct predictions train: 1229\n",
      "Epoch 920, Loss: 21.251911163330078, Correct predictions: 2010, Correct predictions train: 1590\n",
      "Epoch 930, Loss: 0.6760980486869812, Correct predictions: 4091, Correct predictions train: 3258\n",
      "Epoch 940, Loss: 0.0011022489052265882, Correct predictions: 4962, Correct predictions train: 3959\n",
      "Epoch 950, Loss: 4.115838050842285, Correct predictions: 2636, Correct predictions train: 2135\n",
      "Epoch 960, Loss: 0.23273256421089172, Correct predictions: 4151, Correct predictions train: 3345\n",
      "Epoch 970, Loss: 1.7159626483917236, Correct predictions: 3634, Correct predictions train: 2937\n",
      "Epoch 980, Loss: 0.1144590899348259, Correct predictions: 4703, Correct predictions train: 3755\n",
      "Epoch 990, Loss: 1.16436767578125, Correct predictions: 2629, Correct predictions train: 2093\n",
      "Saved trained_model_2024_12_17_01_23_49.json\n",
      "Loaded trainable_model_2024_12_17_01_23_51.json\n",
      "Epoch 0, Loss: 181067.53125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 10, Loss: 25550.98828125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 20, Loss: 1012.3191528320312, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 30, Loss: 304.8691101074219, Correct predictions: 13, Correct predictions train: 11\n",
      "Epoch 40, Loss: 1728.14453125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 50, Loss: 558.2343139648438, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 60, Loss: 3418.83984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 70, Loss: 7049.048828125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 80, Loss: 21891.208984375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 90, Loss: 346.4224548339844, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 100, Loss: 52003.19921875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 110, Loss: 424.179931640625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 120, Loss: 1592.61669921875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 130, Loss: 10095.798828125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 140, Loss: 23052.982421875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 150, Loss: 581.9232788085938, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 160, Loss: 15860.1953125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 170, Loss: 10146.0302734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 180, Loss: 736.29052734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 190, Loss: 2165.60302734375, Correct predictions: 13, Correct predictions train: 9\n",
      "Epoch 200, Loss: 2475.419677734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 210, Loss: 2128.2353515625, Correct predictions: 7, Correct predictions train: 6\n",
      "Epoch 220, Loss: 1264.8372802734375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 230, Loss: 796.5909423828125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 240, Loss: 890.14111328125, Correct predictions: 21, Correct predictions train: 17\n",
      "Epoch 250, Loss: 4211.5126953125, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 260, Loss: 121.86073303222656, Correct predictions: 55, Correct predictions train: 46\n",
      "Epoch 270, Loss: 324.3515625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 280, Loss: 3064.10888671875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 290, Loss: 3986.929443359375, Correct predictions: 31, Correct predictions train: 29\n",
      "Epoch 300, Loss: 1179.052001953125, Correct predictions: 29, Correct predictions train: 25\n",
      "Epoch 310, Loss: 208.33905029296875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 320, Loss: 54.088809967041016, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 330, Loss: 359.6793212890625, Correct predictions: 3, Correct predictions train: 3\n",
      "Epoch 340, Loss: 3826.49755859375, Correct predictions: 49, Correct predictions train: 36\n",
      "Epoch 350, Loss: 4503.9609375, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 360, Loss: 13.634483337402344, Correct predictions: 30, Correct predictions train: 26\n",
      "Epoch 370, Loss: 984.8892822265625, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 380, Loss: 853.514404296875, Correct predictions: 1, Correct predictions train: 1\n",
      "Epoch 390, Loss: 6.3816938400268555, Correct predictions: 103, Correct predictions train: 83\n",
      "Epoch 400, Loss: 1.3279169797897339, Correct predictions: 5, Correct predictions train: 4\n",
      "Epoch 410, Loss: 26.508962631225586, Correct predictions: 255, Correct predictions train: 201\n",
      "Epoch 420, Loss: 2117.875732421875, Correct predictions: 5, Correct predictions train: 2\n",
      "Epoch 430, Loss: 187.02513122558594, Correct predictions: 6, Correct predictions train: 6\n",
      "Epoch 440, Loss: 313.775634765625, Correct predictions: 37, Correct predictions train: 31\n",
      "Epoch 450, Loss: 562.4605102539062, Correct predictions: 132, Correct predictions train: 100\n",
      "Epoch 460, Loss: 0.9927053451538086, Correct predictions: 144, Correct predictions train: 118\n",
      "Epoch 470, Loss: 555.4217529296875, Correct predictions: 126, Correct predictions train: 96\n",
      "Epoch 480, Loss: 323.9172058105469, Correct predictions: 281, Correct predictions train: 233\n",
      "Epoch 490, Loss: 2287.6640625, Correct predictions: 5, Correct predictions train: 5\n",
      "Epoch 500, Loss: 0.08767981827259064, Correct predictions: 353, Correct predictions train: 257\n",
      "Epoch 510, Loss: 37.101715087890625, Correct predictions: 445, Correct predictions train: 368\n",
      "Epoch 520, Loss: 360.9537353515625, Correct predictions: 342, Correct predictions train: 279\n",
      "Epoch 530, Loss: 19.222061157226562, Correct predictions: 314, Correct predictions train: 249\n",
      "Epoch 540, Loss: 139.37774658203125, Correct predictions: 36, Correct predictions train: 32\n",
      "Epoch 550, Loss: 0.08474013954401016, Correct predictions: 1202, Correct predictions train: 964\n",
      "Epoch 560, Loss: 1.2086477279663086, Correct predictions: 1079, Correct predictions train: 883\n",
      "Epoch 570, Loss: 132.68707275390625, Correct predictions: 215, Correct predictions train: 162\n",
      "Epoch 580, Loss: 6.352139472961426, Correct predictions: 743, Correct predictions train: 595\n",
      "Epoch 590, Loss: 176.09683227539062, Correct predictions: 648, Correct predictions train: 512\n",
      "Epoch 600, Loss: 12.208196640014648, Correct predictions: 313, Correct predictions train: 235\n",
      "Epoch 610, Loss: 39.50006866455078, Correct predictions: 689, Correct predictions train: 561\n",
      "Epoch 620, Loss: 136.80099487304688, Correct predictions: 299, Correct predictions train: 242\n",
      "Epoch 630, Loss: 14.474853515625, Correct predictions: 1852, Correct predictions train: 1485\n",
      "Epoch 640, Loss: 187.50148010253906, Correct predictions: 63, Correct predictions train: 54\n",
      "Epoch 650, Loss: 59.35067367553711, Correct predictions: 174, Correct predictions train: 146\n",
      "Epoch 660, Loss: 0.7073266506195068, Correct predictions: 503, Correct predictions train: 409\n",
      "Epoch 670, Loss: 1568.8253173828125, Correct predictions: 276, Correct predictions train: 223\n",
      "Epoch 680, Loss: 31.58132553100586, Correct predictions: 715, Correct predictions train: 580\n",
      "Epoch 690, Loss: 264.2257080078125, Correct predictions: 289, Correct predictions train: 223\n",
      "Epoch 700, Loss: 59.26356506347656, Correct predictions: 161, Correct predictions train: 124\n",
      "Epoch 710, Loss: 34.683013916015625, Correct predictions: 852, Correct predictions train: 677\n",
      "Epoch 720, Loss: 695.233154296875, Correct predictions: 357, Correct predictions train: 287\n",
      "Epoch 730, Loss: 1.794905662536621, Correct predictions: 1119, Correct predictions train: 888\n",
      "Epoch 740, Loss: 61.53007507324219, Correct predictions: 1055, Correct predictions train: 832\n",
      "Epoch 750, Loss: 103.07136535644531, Correct predictions: 642, Correct predictions train: 514\n",
      "Epoch 760, Loss: 10.741474151611328, Correct predictions: 798, Correct predictions train: 642\n",
      "Epoch 770, Loss: 48.2673454284668, Correct predictions: 354, Correct predictions train: 287\n",
      "Epoch 780, Loss: 0.1286296844482422, Correct predictions: 681, Correct predictions train: 532\n",
      "Epoch 790, Loss: 3.139346122741699, Correct predictions: 1704, Correct predictions train: 1364\n",
      "Epoch 800, Loss: 5.413787841796875, Correct predictions: 411, Correct predictions train: 337\n",
      "Epoch 810, Loss: 3.8587045669555664, Correct predictions: 360, Correct predictions train: 285\n",
      "Epoch 820, Loss: 371.6249694824219, Correct predictions: 703, Correct predictions train: 556\n",
      "Epoch 830, Loss: 6.314364433288574, Correct predictions: 1116, Correct predictions train: 910\n",
      "Epoch 840, Loss: 39.067481994628906, Correct predictions: 1301, Correct predictions train: 1032\n",
      "Epoch 850, Loss: 34.09135055541992, Correct predictions: 1098, Correct predictions train: 897\n",
      "Epoch 860, Loss: 0.06135771423578262, Correct predictions: 575, Correct predictions train: 461\n",
      "Epoch 870, Loss: 1.9355857372283936, Correct predictions: 1252, Correct predictions train: 1008\n",
      "Epoch 880, Loss: 17.468809127807617, Correct predictions: 1407, Correct predictions train: 1102\n",
      "Epoch 890, Loss: 6.859472274780273, Correct predictions: 1685, Correct predictions train: 1338\n",
      "Epoch 900, Loss: 42.455665588378906, Correct predictions: 411, Correct predictions train: 337\n",
      "Epoch 910, Loss: 101.3950424194336, Correct predictions: 628, Correct predictions train: 492\n",
      "Epoch 920, Loss: 328.8289489746094, Correct predictions: 754, Correct predictions train: 621\n",
      "Epoch 930, Loss: 10.332892417907715, Correct predictions: 974, Correct predictions train: 782\n",
      "Epoch 940, Loss: 0.007502354681491852, Correct predictions: 1831, Correct predictions train: 1490\n",
      "Epoch 950, Loss: 63.921871185302734, Correct predictions: 1096, Correct predictions train: 872\n",
      "Epoch 960, Loss: 3.71860408782959, Correct predictions: 1661, Correct predictions train: 1333\n",
      "Epoch 970, Loss: 26.960453033447266, Correct predictions: 1969, Correct predictions train: 1590\n",
      "Epoch 980, Loss: 1.7478740215301514, Correct predictions: 1630, Correct predictions train: 1290\n",
      "Epoch 990, Loss: 18.1429443359375, Correct predictions: 756, Correct predictions train: 593\n",
      "Saved trained_model_2024_12_17_01_23_51.json\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = generate_train_dataset()\n",
    "\n",
    "save_dir = f\"{folder}Results_models/AP_{epsilon}\"\n",
    "save_model_dir = f\"{folder}Trained_models/AP_{epsilon}\"\n",
    "folder_path = f'{folder}Parameters/AP_{epsilon}'\n",
    "date_pattern = r'trainable_model_(\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}).json'\n",
    "files = sorted(\n",
    "    (f for f in os.listdir(folder_path) if not f.startswith('.')),  # Filtrar archivos ocultos\n",
    "    key=lambda x: re.search(date_pattern, x).group(1) if re.search(date_pattern, x) else ''\n",
    ")\n",
    "\n",
    "for filename in files:\n",
    "    match = re.search(date_pattern, filename)\n",
    "    if match:\n",
    "        current_time = match.group(1)\n",
    "    else:\n",
    "        print('Error')\n",
    "        break\n",
    "    \n",
    "    file_path = f\"{folder_path}/trainable_model_{current_time}.json\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        trainable_model = json.load(file)\n",
    "\n",
    "    trainable_model_jnp = {key: jnp.array(value) for key, value in trainable_model.items()}\n",
    "    print(f'Loaded trainable_model_{current_time}.json')\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True) \n",
    "    results_file = os.path.join(save_dir, f\"Results_{current_time}.txt\") \n",
    "    tee = Tee(results_file, 'w') \n",
    "    sys.stdout = tee\n",
    "    \n",
    "    try: \n",
    "        new_params, average_loss = train_model(trainable_model_jnp, x_train, y_train, lr=0.01, epochs=1000)\n",
    "        pred_count, pred_count_train = correct_predictions(trainable_model_jnp)\n",
    "\n",
    "        trained_model_filename = f\"trained_model_{current_time}.json\"\n",
    "        save_trained_model(new_params, trained_model_filename, save_model_dir)\n",
    "        print(f'Saved trained_model_{current_time}.json')\n",
    "\n",
    "    finally:\n",
    "        sys.stdout = tee.console\n",
    "        tee.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142fb59-e19a-4c8c-b78c-998dff5609d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1d8b8-4466-4e80-972d-bb10d741e61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
