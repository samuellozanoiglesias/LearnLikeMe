{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98558e0d-b53a-412c-81a9-9bb54f749c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Lambda, Concatenate, Reshape, Flatten\n",
    "from tensorflow.keras.initializers import GlorotUniform, RandomUniform, Constant\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c8a971-a305-48fe-94a9-40be4a3f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los módulos preentrenados (unit_module y carry_module)\n",
    "unit_module = load_model('unit_module.keras')\n",
    "carry_module = load_model('carry_module.keras')\n",
    "unit_module.trainable = False\n",
    "carry_module.trainable = False\n",
    "unit_module.name = 'unit_model'\n",
    "carry_module.name = 'carry_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92293af0-33a3-408d-98e3-a37a680a8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar los datos\n",
    "def generate_final_data():\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for a_dec in range(10):\n",
    "        for a_unit in range(10):\n",
    "            for b_dec in range(10):\n",
    "                for b_unit in range(10):\n",
    "                    x_data.append([a_dec, a_unit, b_dec, b_unit])  # Entrada\n",
    "                    sum_units = (a_unit + b_unit) % 10\n",
    "                    carry_units = 1 if (a_unit + b_unit) >= 10 else 0\n",
    "                    sum_dec = (a_dec + b_dec + carry_units) % 10\n",
    "                    carry_dec = 1 if (a_dec + b_dec + carry_units) >= 10 else 0\n",
    "                    y_data.append([carry_dec, sum_dec, sum_units])  # Salida\n",
    "    return jnp.array(x_data), jnp.array(y_data)\n",
    "\n",
    "# Función para crear parámetros entrenables (v_0, ..., v_35)\n",
    "def init_params():\n",
    "    v_values_init = jnp.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                               0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                               0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=jnp.float32)\n",
    "    key = random.PRNGKey(0)\n",
    "    keys = random.split(key, 35)\n",
    "    v_params = {f'v{i}': random.normal(keys[i], (1,)) * epsilon + v_values_init[i] for i in range(35)}\n",
    "    return v_params\n",
    "\n",
    "# Función de pérdida\n",
    "def loss_fn(params, x, y):\n",
    "    y_pred_1, y_pred_2, y_pred_3 = model(params, x)\n",
    "    return jnp.mean((y_pred_1 - y[0]) ** 2) + jnp.mean((y_pred_2 - y[1]) ** 2) + jnp.mean((y_pred_3 - y[2]) ** 2)\n",
    "    \n",
    "# Función para entrenar el modelo\n",
    "def update_params(params, x, y, lr):\n",
    "    # Asegúrate de usar JAX para los gradientes y operaciones\n",
    "    gradients = grad(loss_fn)(params, x, y)\n",
    "    step_loss = loss_fn(params, x, y)\n",
    "    new_params = jax.tree.map(lambda p, g: p - lr * g, params, gradients)\n",
    "    return new_params, step_loss\n",
    "\n",
    "\n",
    "def train_model(params, x_train, y_train, lr=0.01, epochs=100):\n",
    "    final_loss = 0\n",
    "    # Convertir x_train y y_train a arrays de JAX (si aún no lo son)\n",
    "    x_train = jnp.array(x_train)\n",
    "    y_train = jnp.array(y_train)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    for epoch in range(epochs):  # Número de épocas\n",
    "        params, step_loss = update_params(params, x_train[epoch], y_train[epoch], lr)\n",
    "        final_loss += step_loss\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {step_loss}\")\n",
    "        \n",
    "    final_loss = final_loss / epochs\n",
    "    return params, final_loss\n",
    "\n",
    "# Función para imprimir las predicciones y el loss en cada época\n",
    "def print_predictions_and_loss(epoch, predictions, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples = x_train.shape[0]\n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(predictions[j][i])) for j in range(3)]\n",
    "        \n",
    "        # Concatenar las predicciones en un número de 3 dígitos\n",
    "        concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "        \n",
    "        # Generar la salida esperada, concatenando los valores reales de y_train\n",
    "        expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))\n",
    "        \n",
    "        # Comprobar si la predicción es igual a la salida esperada\n",
    "        if concatenated_pred == expected_output:\n",
    "            pred_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}:\")\n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Si todas las predicciones son correctas, detener el entrenamiento\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente! Deteniendo entrenamiento.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def count_predictions(params, x_train, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples =  x_train.shape[0]   \n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        prediction = model(params, x_train[i])\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(prediction[j].item())) for j in range(3)]\n",
    "        \n",
    "        if normalized_pred[0] == y_train[i,0]:\n",
    "            if normalized_pred[1] == y_train[i,1]:\n",
    "                if normalized_pred[2] == y_train[i,2]:\n",
    "                    pred_count += 1\n",
    "                    \n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente!\")\n",
    "        \n",
    "\n",
    "def predictions(params, x_train, y_train):\n",
    "    pred_count = 0\n",
    "    total_examples = x_train.shape[0]   \n",
    "    \n",
    "    for i in range(total_examples):\n",
    "        prediction = model(params, x_train[i])\n",
    "        # Obtener las predicciones para la unidad, decena y acarreo\n",
    "        normalized_pred = [int(jnp.round(prediction[j].item())) for j in range(3)]\n",
    "        \n",
    "        # Concatenar las predicciones en un número de 3 dígitos\n",
    "        concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "        \n",
    "        # Generar la salida esperada, concatenando los valores reales de y_train\n",
    "        expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))\n",
    "        \n",
    "        # Comprobar si la predicción es igual a la salida esperada\n",
    "        if concatenated_pred == expected_output:\n",
    "            pred_count += 1\n",
    "\n",
    "    print(f\"Predicciones correctas: {pred_count} de {total_examples}\")\n",
    "\n",
    "    if pred_count == total_examples:\n",
    "        print(\"¡Todas las combinaciones han sido aprendidas correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd07b07e-151a-4351-86fd-ef13854af55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo dinámico en JAX\n",
    "def model(params, x):\n",
    "    # Extraer unidades y decenas de los valores de entrada\n",
    "    units_input = jnp.array([x[1], x[3]])\n",
    "    decs_input = jnp.array([x[0], x[2]])\n",
    "    incorrect_option_1 = jnp.array([x[0], x[1]])\n",
    "    incorrect_option_2 = jnp.array([x[0], x[3]])\n",
    "    incorrect_option_3 = jnp.array([x[1], x[2]])\n",
    "    incorrect_option_4 = jnp.array([x[2], x[3]])\n",
    "    units_input = units_input[None, None, :]\n",
    "    decs_input = decs_input[None, None, :]\n",
    "    incorrect_option_1 = incorrect_option_1[None, None, :]\n",
    "    incorrect_option_2 = incorrect_option_2[None, None, :]\n",
    "    incorrect_option_3 = incorrect_option_3[None, None, :]\n",
    "    incorrect_option_4 = incorrect_option_4[None, None, :]\n",
    "    \n",
    "    # Llamar a los modelos unit_module y carry_module\n",
    "    unit_output = jnp.array(unit_module(units_input))  # Salida para unidades\n",
    "    carry_output_unit = jnp.array(carry_module(units_input))  # Salida de acarreo de unidades\n",
    "    dec_output = jnp.array(unit_module(decs_input))  # Salida para decenas\n",
    "    carry_output_dec = jnp.array(carry_module(decs_input))  # Salida de acarreo de decenas\n",
    "\n",
    "    incorrect_option_1_output = jnp.array(unit_module(incorrect_option_1)) \n",
    "    carry_incorrect_option_1 = jnp.array(carry_module(incorrect_option_1))  \n",
    "    incorrect_option_2_output = jnp.array(unit_module(incorrect_option_2)) \n",
    "    carry_incorrect_option_2 = jnp.array(carry_module(incorrect_option_2))  \n",
    "    incorrect_option_3_output = jnp.array(unit_module(incorrect_option_3)) \n",
    "    carry_incorrect_option_3 = jnp.array(carry_module(incorrect_option_3))  \n",
    "    incorrect_option_4_output = jnp.array(unit_module(incorrect_option_4)) \n",
    "    carry_incorrect_option_4 = jnp.array(carry_module(incorrect_option_4))  \n",
    "\n",
    "    # Tomar el valor máximo de las predicciones (argmax en JAX)\n",
    "    unit_val = jnp.argmax(unit_output, axis=-1)\n",
    "    carry_unit_val = jnp.argmax(carry_output_unit, axis=-1)\n",
    "    dec_val = jnp.argmax(dec_output, axis=-1)\n",
    "    carry_dec_val = jnp.argmax(carry_output_dec, axis=-1)\n",
    "    incorrect_option_1_val = jnp.argmax(incorrect_option_1_output, axis=-1)\n",
    "    carry_incorrect_option_1_val = jnp.argmax(carry_incorrect_option_1, axis=-1)\n",
    "    incorrect_option_2_val = jnp.argmax(incorrect_option_2_output, axis=-1)\n",
    "    carry_incorrect_option_2_val = jnp.argmax(carry_incorrect_option_2, axis=-1)\n",
    "    incorrect_option_3_val = jnp.argmax(incorrect_option_3_output, axis=-1)\n",
    "    carry_incorrect_option_3_val = jnp.argmax(carry_incorrect_option_3, axis=-1)\n",
    "    incorrect_option_4_val = jnp.argmax(incorrect_option_4_output, axis=-1)\n",
    "    carry_incorrect_option_4_val = jnp.argmax(carry_incorrect_option_4, axis=-1)\n",
    "\n",
    "    # Calcular las salidas combinadas con los parámetros v\n",
    "    salida_1 = ((params['v0'] * carry_dec_val) + (params['v1'] * dec_val) + (params['v2'] * carry_unit_val) + (params['v3'] * unit_val)\n",
    "                + (params['v0'] * carry_incorrect_option_4_val) + (params['v0'] * incorrect_option_4_val) + (params['v0'] * carry_incorrect_option_3_val) + (params['v0'] * incorrect_option_3_val)\n",
    "                + (params['v0'] * carry_incorrect_option_2_val) + (params['v0'] * incorrect_option_2_val) + (params['v0'] * carry_incorrect_option_1_val) + (params['v0'] * incorrect_option_1_val))\n",
    "    salida_2 = ((params['v4'] * carry_dec_val) + (params['v5'] * dec_val) + (params['v6'] * carry_unit_val) + (params['v7'] * unit_val)\n",
    "                + (params['v0'] * carry_incorrect_option_4_val) + (params['v0'] * incorrect_option_4_val) + (params['v0'] * carry_incorrect_option_3_val) + (params['v0'] * incorrect_option_3_val)\n",
    "                + (params['v0'] * carry_incorrect_option_2_val) + (params['v0'] * incorrect_option_2_val) + (params['v0'] * carry_incorrect_option_1_val) + (params['v0'] * incorrect_option_1_val))\n",
    "    salida_3 = ((params['v8'] * carry_dec_val) + (params['v9'] * dec_val) + (params['v10'] * carry_unit_val) + (params['v11'] * unit_val)\n",
    "                + (params['v0'] * carry_incorrect_option_4_val) + (params['v0'] * incorrect_option_4_val) + (params['v0'] * carry_incorrect_option_3_val) + (params['v0'] * incorrect_option_3_val)\n",
    "                + (params['v0'] * carry_incorrect_option_2_val) + (params['v0'] * incorrect_option_2_val) + (params['v0'] * carry_incorrect_option_1_val) + (params['v0'] * incorrect_option_1_val))\n",
    "\n",
    "    return salida_1, salida_2, salida_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cb6df06-5d82-48bb-984a-7f34ece07bcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling Multiply.call().\n\n\u001b[1m'ResourceVariable' object has no attribute 'sparse'\u001b[0m\n\nArguments received by Multiply.call():\n  • args=(['tf.Tensor(shape=(1,), dtype=float32)', '<KerasTensor shape=(1,), dtype=float32, sparse=False, name=keras_tensor_22>'],)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dynamic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrainable_variables:\n",
      "Cell \u001b[1;32mIn[56], line 103\u001b[0m, in \u001b[0;36mbuild_dynamic_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m carry_dec_val \u001b[38;5;241m=\u001b[39m Lambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39margmax(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))(carry_output_dec)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Salidas combinadas utilizando los parámetros v0, ..., v11\u001b[39;00m\n\u001b[0;32m    102\u001b[0m salida_1 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[1;32m--> 103\u001b[0m     \u001b[43mMultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarry_dec_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    104\u001b[0m     Multiply()([v1, dec_val]),\n\u001b[0;32m    105\u001b[0m     Multiply()([v2, carry_unit_val]),\n\u001b[0;32m    106\u001b[0m     Multiply()([v3, unit_val]),\n\u001b[0;32m    107\u001b[0m ])\n\u001b[0;32m    108\u001b[0m salida_2 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[0;32m    109\u001b[0m     Multiply()([v4, carry_dec_val]),\n\u001b[0;32m    110\u001b[0m     Multiply()([v5, dec_val]),\n\u001b[0;32m    111\u001b[0m     Multiply()([v6, carry_unit_val]),\n\u001b[0;32m    112\u001b[0m     Multiply()([v7, unit_val]),\n\u001b[0;32m    113\u001b[0m ])\n\u001b[0;32m    114\u001b[0m salida_3 \u001b[38;5;241m=\u001b[39m Add()([\n\u001b[0;32m    115\u001b[0m     Multiply()([v8, carry_dec_val]),\n\u001b[0;32m    116\u001b[0m     Multiply()([v9, dec_val]),\n\u001b[0;32m    117\u001b[0m     Multiply()([v10, carry_unit_val]),\n\u001b[0;32m    118\u001b[0m     Multiply()([v11, unit_val]),\n\u001b[0;32m    119\u001b[0m ])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\merging\\base_merge.py:251\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_output_spec\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m    250\u001b[0m     output_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_output_shape([x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs])\n\u001b[1;32m--> 251\u001b[0m     output_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m KerasTensor(\n\u001b[0;32m    253\u001b[0m         output_shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype, sparse\u001b[38;5;241m=\u001b[39moutput_sparse\n\u001b[0;32m    254\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling Multiply.call().\n\n\u001b[1m'ResourceVariable' object has no attribute 'sparse'\u001b[0m\n\nArguments received by Multiply.call():\n  • args=(['tf.Tensor(shape=(1,), dtype=float32)', '<KerasTensor shape=(1,), dtype=float32, sparse=False, name=keras_tensor_22>'],)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "x_train, y_train = generate_final_data()\n",
    "params = init_params()\n",
    "x=x_train[0]\n",
    "print(jnp.array([x[1], x[3]]))\n",
    "new_params, final_loss = train_model(params, x_train, y_train, lr=0.01, epochs=100)\n",
    "print(final_loss)\n",
    "\n",
    "# Hacer predicciones después del entrenamiento\n",
    "predictions = model(params, x_train)\n",
    "print(\"Predicciones:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc503a87-d87f-4f4b-8895-10a1fa7d18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_dynamic_model()\n",
    "model.summary()\n",
    "\n",
    "for var in model.trainable_variables:\n",
    "    if var.name == \"v_values:0\":\n",
    "        print(\"Valores iniciales de v_values:\", var.numpy())\n",
    "\n",
    "\n",
    "# Predicciones\n",
    "total_examples = x_train.shape[0]\n",
    "pred_count = 0\n",
    "\n",
    "# Realizar las predicciones para todos los ejemplos\n",
    "predictions = model.predict(x_train)\n",
    "\n",
    "# Si `predictions` contiene múltiples arrays (uno por salida del modelo):\n",
    "if isinstance(predictions, list):\n",
    "    # Concatenamos las predicciones en columnas\n",
    "    predictions_df = pd.DataFrame(\n",
    "        {f\"Salida_{i+1}\": pred.flatten() for i, pred in enumerate(predictions)}\n",
    "    )\n",
    "else:\n",
    "    # Si `predictions` es un solo array\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Guardar como archivo CSV\n",
    "predictions_df.to_csv(\"predicciones_completas.csv\", index=False)\n",
    "\n",
    "# Inicializar listas para almacenar las predicciones y las salidas reales\n",
    "predicted_values = []\n",
    "expected_values = []\n",
    "\n",
    "for i in range(total_examples):\n",
    "    # Normalizar y redondear la predicción (cada salida del modelo)\n",
    "    normalized_pred = [\n",
    "        np.round(predictions[0][i]).astype(int),  # Primer valor del primer array\n",
    "        np.round(predictions[1][i]).astype(int),  # Primer valor del segundo array\n",
    "        np.round(predictions[2][i]).astype(int)   # Primer valor del tercer array\n",
    "    ]\n",
    "    \n",
    "    # Concatenar los tres elementos en normalized_pred como un solo número\n",
    "    concatenated_pred = int(\"\".join(str(pred) for pred in normalized_pred))\n",
    "\n",
    "    # Comparar la predicción con la salida real\n",
    "    expected_output = int(\"\".join(str(int(round(val))) for val in y_train[i]))  # Convertir la salida esperada en un número\n",
    "    \n",
    "    # Almacenar en las listas\n",
    "    predicted_values.append(concatenated_pred)\n",
    "    expected_values.append(expected_output)\n",
    "    \n",
    "    if concatenated_pred == expected_output:\n",
    "        pred_count += 1    \n",
    "\n",
    "print(f'Predicciones correctas: {pred_count} de {total_examples}.')\n",
    "\n",
    "# Crear un DataFrame con los datos\n",
    "data = {\n",
    "    \"Predicción\": predicted_values,\n",
    "    \"Valor Esperado\": expected_values\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar como archivo CSV\n",
    "df.to_csv(\"predicciones.csv\", index=False)\n",
    "\n",
    "print(f\"Archivo 'predicciones.csv' guardado con éxito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
