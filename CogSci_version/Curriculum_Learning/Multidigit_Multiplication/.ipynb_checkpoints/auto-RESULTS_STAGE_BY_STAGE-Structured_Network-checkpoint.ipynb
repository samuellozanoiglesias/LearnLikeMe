{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711e908c-a200-4499-a72c-e7d32a573bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad\n",
    "from jax.nn import relu, sigmoid\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytz\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479ae9ba-7455-4e6e-86a4-b87a5dd1df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network parameters\n",
    "def initialize_random_weights(mean, std, shape = ()):\n",
    "    return np.random.normal(loc=mean, scale=std, size=shape)\n",
    "    \n",
    "# We use a 2-degree polynomial function to approximate 0 and 1/2 to 0 and 1 stays in 1\n",
    "def polynomial_function(x):\n",
    "    return 2 * (x ** 2) - x\n",
    "\n",
    "# We use a sinusoidal function to approximate odd numbers by their immediately preceding even number and preserve differentiability\n",
    "def lower_even(x):\n",
    "    return x - 0.5 * (1 - jnp.cos(jnp.pi * x))\n",
    "\n",
    "# We use a sinusoidal function to approximate 0 for evens and 1 for odds while preserving differentiability\n",
    "def differentiable_even_or_odd(x):\n",
    "    return 0.5 * (1 - jnp.cos(jnp.pi * x))\n",
    "    \n",
    "# Function to generate dataset with multiplication\n",
    "def generate_dataset_with_zeros(size, n_max=10):\n",
    "    # Generate two columns of random numbers between 0 and 9\n",
    "    column_1 = np.random.randint(0, n_max, size)\n",
    "    column_2 = np.random.randint(0, n_max, size)\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_without_zeros(size, n_max=10):\n",
    "    # Generate two columns of random numbers between 1 and 9\n",
    "    column_1 = np.random.randint(1, n_max, size)\n",
    "    column_2 = np.random.randint(1, n_max, size)\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_test_dataset(n_max=10):\n",
    "    # Create the columns\n",
    "    column_1 = list(range(n_max)) * n_max  # Numbers from 0 to 9 repeated 10 times\n",
    "    column_2 = [i for i in range(n_max) for _ in range(n_max)]  # Numbers from 0 to 9 repeated sequentially 10 times\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def decimal_to_binary(n, bits):\n",
    "    if 0 <= n < 2**bits:\n",
    "        # Convert the number to a binary string and then to an array of integers (0 and 1)\n",
    "        return np.array(list(format(n, f'0{bits}b'))).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(\"Number out of range\")\n",
    "\n",
    "# Function to convert binary number to decimal\n",
    "def binary_to_decimal(binary_vector, bits):\n",
    "    # Ensure the vector has the correct number of elements\n",
    "    if len(binary_vector) != bits:\n",
    "        raise ValueError(f\"The vector must have exactly {bits} elements.\")\n",
    "\n",
    "    # Calculate the decimal number\n",
    "    decimal = 0\n",
    "    for i in range(bits):\n",
    "        decimal += binary_vector[i] * (2 ** (bits - 1 - i))\n",
    "\n",
    "    return decimal\n",
    "\n",
    "def transform_to_tridimensional_matrix(dataset, bits_init=4, bits_end=7):\n",
    "    rows, cols = dataset.shape\n",
    "    if cols != 3:\n",
    "        raise ValueError(\"The dataset must have exactly 3 columns.\")\n",
    "\n",
    "    # Initialize the three matrices\n",
    "    matrix_column_1 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_2 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_3 = np.zeros((rows, bits_end), dtype=np.int8)\n",
    "\n",
    "    # Fill the matrices with the binary representation of each column\n",
    "    for i in range(rows):\n",
    "        matrix_column_1[i] = decimal_to_binary(dataset.iloc[i, 0], bits_init)\n",
    "        matrix_column_2[i] = decimal_to_binary(dataset.iloc[i, 1], bits_init)\n",
    "        matrix_column_3[i] = decimal_to_binary(dataset.iloc[i, 2], bits_end)\n",
    "\n",
    "    return matrix_column_1, matrix_column_2, matrix_column_3\n",
    "    \n",
    "    \n",
    "def prepare_dataset(level, size=1, couples_included=[]):       \n",
    "    if level == -2:\n",
    "        dataset = generate_dataset_with_zeros(size)\n",
    "        return dataset\n",
    "        \n",
    "    elif level == -1:\n",
    "        dataset = generate_dataset_without_zeros(size)\n",
    "        return dataset\n",
    "\n",
    "    elif level == 0:\n",
    "        couples_not_included = [(3, 3), (5, 5), (6, 6), (7, 7), (9, 9), (3, 6), (3, 7), (6, 3), (7, 3), (5, 7), (7, 5), (6, 7), (7, 6)]\n",
    "        dataset = pd.DataFrame()\n",
    "        while len(dataset) < size:\n",
    "            column_1 = np.random.randint(1, 10, size)\n",
    "            column_2 = np.random.randint(1, 10, size)\n",
    "            temp_dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "            temp_dataset = temp_dataset[~temp_dataset[['Column_1', 'Column_2']].apply(tuple, axis=1).isin(couples_not_included)]\n",
    "            dataset = pd.concat([dataset, temp_dataset])\n",
    "        dataset = dataset.iloc[:size].reset_index(drop=True)\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 1:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = [(5, 5), (9, 9)]\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 2:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = [(3, 3), (6, 6), (3, 6), (6, 3), (5, 7), (7, 5)]\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = [(3, 7), (6, 7), (7, 3), (7, 6)]\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 4:\n",
    "        column_1 = [7] * size\n",
    "        column_2 = [7] * size\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 5:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = couples_included\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "def prepare_outputs(stage, inputs_1, inputs_2, outputs_prev):\n",
    "    if stage == 1:\n",
    "        return np.array([np.outer(vec2, vec1).flatten() for vec1, vec2 in zip(inputs_1, inputs_2)])\n",
    "\n",
    "    elif stage == 2:\n",
    "        outputs = []\n",
    "        matrix_step_2 = np.zeros((16, 28))\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                matrix_step_2[i*4 + j, i*8 + j] = 1\n",
    "        for vec1, vec2 in zip(inputs_1, inputs_2):\n",
    "            outer_product = np.outer(vec2, vec1)\n",
    "            flatten_vector = jnp.dot(outer_product.flatten(), matrix_step_2)\n",
    "            outputs.append(flatten_vector)\n",
    "        return np.array(outputs)\n",
    "\n",
    "    elif stage == 3:\n",
    "        outputs = []\n",
    "        for vec1, vec2 in zip(inputs_1, inputs_2):\n",
    "            outer_product = np.outer(vec2, vec1)\n",
    "            z3 = lower_even(outer_product[2,3] + outer_product[3,2])\n",
    "            z4 = lower_even(outer_product[1,3] + outer_product[2,2] + outer_product[3,1] + z3 * 1/2)\n",
    "            z5 = lower_even(outer_product[0,3] + outer_product[1,2] + outer_product[2,1] + outer_product[3,0] + z4 * 1/2)\n",
    "            z6 = lower_even(outer_product[0,2] + outer_product[1,1] + outer_product[2,0] + z5 * 1/2)\n",
    "            z7 = lower_even(outer_product[0,1] + outer_product[1,0] + z6 * 1/2)\n",
    "            outputs.append([z7, z6, z5, z4, z3, 0, 0])\n",
    "        return np.array(outputs)\n",
    "\n",
    "    elif stage == 4:\n",
    "        return outputs_prev\n",
    "\n",
    "    elif stage == 5:\n",
    "        return outputs_prev\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "        \n",
    "# Perfect parameters needed for the stages where a part of the NN performs perfectly\n",
    "\n",
    "# Create the W1_perfect matrix of zeros with dimensions (8,16)\n",
    "W1_perfect = np.zeros((8, 16))\n",
    "# Introduce the correct numbers to multiply\n",
    "for k in range(4):\n",
    "    for i in range(4):\n",
    "        W1_perfect[i, 12+i-k*4] = 1/2\n",
    "        W1_perfect[4+i, 4*i:4*i+4] = 1/2\n",
    "\n",
    "# Create the W2_perfect matrix of zeros with dimensions (16,28)\n",
    "W2_perfect = np.zeros((16, 28))\n",
    "\n",
    "# Correctly place the 7-bit vectors\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        W2_perfect[i*4 + j, i*8 + j] = 1\n",
    "\n",
    "# R vectors of dimension (28,1)\n",
    "R3_perfect = np.zeros((28))\n",
    "R4_perfect = np.zeros((28))\n",
    "R5_perfect = np.zeros((28))\n",
    "R6_perfect = np.zeros((28))\n",
    "R7_perfect = np.zeros((28))\n",
    "\n",
    "for i in range(4):\n",
    "    R3_perfect[7*i + 5] = 1\n",
    "    R4_perfect[7*i + 4] = 1\n",
    "    R5_perfect[7*i + 3] = 1\n",
    "    R6_perfect[7*i + 2] = 1\n",
    "    R7_perfect[7*i + 1] = 1\n",
    "\n",
    "# Scalar parameters v\n",
    "v3_perfect = 1/2\n",
    "v4_perfect = 1/2\n",
    "v5_perfect = 1/2\n",
    "v6_perfect = 1/2\n",
    "\n",
    "# Matrix T of dimension (28,7)\n",
    "T_perfect = np.zeros((28,7))\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(4):\n",
    "        T_perfect[7*j + i, i] = 1\n",
    "\n",
    "# Parameter v7\n",
    "v7_perfect = 1/2\n",
    "\n",
    "# Neural network in every stage\n",
    "\n",
    "def neural_network_1(params, x1, x2):\n",
    "    W1, h = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    prev_vec = polynomial_function(jnp.dot(x, W1)) # Multiplies values, prev_vec is a (1,8) matrix\n",
    "    #vec = jnp.dot(prev_vec, W2) # vec is a (1,28) dimensional vector\n",
    "    #z3 = lower_even(relu(jnp.dot(vec, R3))) # z3 is a scalar with the second carry over\n",
    "    #z4 = lower_even(relu(jnp.dot(vec, R4) + jnp.dot(z3, v3))) # z4 is a scalar with the third carry over\n",
    "    #z5 = lower_even(relu(jnp.dot(vec, R5) + jnp.dot(z4, v4))) # z5 is a scalar with the fourth carry over\n",
    "    #z6 = lower_even(relu(jnp.dot(vec, R6) + jnp.dot(z5, v5))) # z6 is a scalar with the fifth carry over\n",
    "    #z7 = lower_even(relu(jnp.dot(vec, R7) + jnp.dot(z6, v6))) # z7 is a scalar with the seventh carry over\n",
    "    #z = jnp.array([z7, z6, z5, z4, z3, 0, 0])\n",
    "    #y = differentiable_even_or_odd(relu(jnp.dot(vec, T) + jnp.dot(z, v7)))\n",
    "    return prev_vec\n",
    "\n",
    "def neural_network_2(params, x1, x2):\n",
    "    W1, W2 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    prev_vec = polynomial_function(jnp.dot(x, W1)) # Multiplies values, prev_vec is a (1,8) matrix\n",
    "    vec = jnp.dot(prev_vec, W2) # vec is a (1,28) dimensional vector\n",
    "    #z3 = lower_even(relu(jnp.dot(vec, R3))) # z3 is a scalar with the second carry over\n",
    "    #z4 = lower_even(relu(jnp.dot(vec, R4) + jnp.dot(z3, v3))) # z4 is a scalar with the third carry over\n",
    "    #z5 = lower_even(relu(jnp.dot(vec, R5) + jnp.dot(z4, v4))) # z5 is a scalar with the fourth carry over\n",
    "    #z6 = lower_even(relu(jnp.dot(vec, R6) + jnp.dot(z5, v5))) # z6 is a scalar with the fifth carry over\n",
    "    #z7 = lower_even(relu(jnp.dot(vec, R7) + jnp.dot(z6, v6))) # z7 is a scalar with the seventh carry over\n",
    "    #z = jnp.array([z7, z6, z5, z4, z3, 0, 0])\n",
    "    #y = differentiable_even_or_odd(relu(jnp.dot(vec, T) + jnp.dot(z, v7)))\n",
    "    return vec\n",
    "\n",
    "def neural_network_3(params, x1, x2):\n",
    "    W1, W2, R3, R4, R5, R6, R7, v3, v4, v5, v6 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    prev_vec = polynomial_function(jnp.dot(x, W1)) # Multiplies values, prev_vec is a (1,8) matrix\n",
    "    vec = jnp.dot(prev_vec, W2) # vec is a (1,28) dimensional vector\n",
    "    z3 = lower_even(jnp.dot(vec, R3)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(vec, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(vec, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(vec, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(vec, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    #y = differentiable_even_or_odd(relu(jnp.dot(vec, T) + jnp.dot(z, v7)))\n",
    "    return jnp.array([z7, z6, z5, z4, z3, 0, 0])\n",
    "\n",
    "def neural_network_4(params, x1, x2):\n",
    "    W1, W2, R3, R4, R5, R6, R7, v3, v4, v5, v6, T, v7 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    prev_vec = polynomial_function(jnp.dot(x, W1)) # Multiplies values, prev_vec is a (1,8) matrix\n",
    "    vec = jnp.dot(prev_vec, W2) # vec is a (1,28) dimensional vector\n",
    "    z3 = lower_even(jnp.dot(vec, R3)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(vec, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(vec, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(vec, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(vec, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z7, z6, z5, z4, z3, 0, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(vec, T) + jnp.dot(z, v7))\n",
    "    return y\n",
    "\n",
    "# Loss functions in every stage\n",
    "def loss_1(params, x1, x2, y, param_reg = 0):\n",
    "    pred = neural_network_1(params, x1, x2)\n",
    "    mse_loss = jnp.mean((pred - y)**2)\n",
    "    regularization = jnp.sum(jnp.array([jnp.mean(jnp.square(param)) for param in params]))\n",
    "    return mse_loss + param_reg * regularization\n",
    "\n",
    "def loss_2(params, x1, x2, y, param_reg = 0):\n",
    "    pred = neural_network_2(params, x1, x2)\n",
    "    mse_loss = jnp.mean((pred - y)**2)\n",
    "    regularization = jnp.sum(jnp.array([jnp.mean(jnp.square(param)) for param in params]))\n",
    "    return mse_loss + param_reg * regularization\n",
    "\n",
    "def loss_3(params, x1, x2, y, param_reg = 0):\n",
    "    pred = neural_network_3(params, x1, x2)\n",
    "    mse_loss = jnp.mean((pred - y)**2)\n",
    "    regularization = jnp.sum(jnp.array([jnp.mean(jnp.square(param)) for param in params]))\n",
    "    return mse_loss + param_reg * regularization\n",
    "\n",
    "def loss_4(params, x1, x2, y, param_reg = 0):\n",
    "    pred = neural_network_4(params, x1, x2)\n",
    "    mse_loss = jnp.mean((pred - y)**2)\n",
    "    regularization = jnp.sum(jnp.array([jnp.mean(jnp.square(param)) for param in params]))\n",
    "    return mse_loss + param_reg * regularization\n",
    "\n",
    "\n",
    "# Loss functions in every step\n",
    "@jax.jit\n",
    "def update_params_1(params, x1, x2, y, lr, param_reg = 0):\n",
    "    gradients = grad(loss_1)(params, x1, x2, y, param_reg)\n",
    "    step_loss = loss_1(params, x1, x2, y, param_reg)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_2(params, x1, x2, y, lr, param_reg = 0):\n",
    "    gradients = grad(loss_2)(params, x1, x2, y, param_reg)\n",
    "    step_loss = loss_2(params, x1, x2, y, param_reg)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_3(params, x1, x2, y, lr, param_reg = 0):\n",
    "    gradients = grad(loss_3)(params, x1, x2, y, param_reg)\n",
    "    step_loss = loss_3(params, x1, x2, y, param_reg)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_4(params, x1, x2, y, lr, param_reg = 0):\n",
    "    gradients = grad(loss_4)(params, x1, x2, y, param_reg)\n",
    "    step_loss = loss_4(params, x1, x2, y, param_reg)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "\n",
    "def decide_training(params, x1, x2, y, lr, stage, param_reg = 0):\n",
    "    if stage == 1:\n",
    "        params, step_loss = update_params_1(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 2:\n",
    "        params, step_loss = update_params_2(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 3:\n",
    "        params, step_loss = update_params_3(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 4:\n",
    "        params, step_loss = update_params_4(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "        \n",
    "# Main function to train the network\n",
    "def train_stages_neural_network(params, stage, level, param_reg = 0, lr=0.001, epochs=100, couples_included=[]):\n",
    "    decimal_dataset = prepare_dataset(level, epochs, couples_included)\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    final_loss = 0\n",
    "    # Train the network\n",
    "    for epoch in range(epochs):\n",
    "        # Update parameters at each step\n",
    "        params, step_loss = decide_training(params, inputs_1[epoch], inputs_2[epoch], outputs[epoch], lr, stage, param_reg)\n",
    "        final_loss += step_loss\n",
    "\n",
    "    final_loss = final_loss / epochs\n",
    "    #print(f\"Loss: {final_loss:.6f}\")\n",
    "    return params, final_loss\n",
    "\n",
    "\n",
    "# Main function to test the network\n",
    "def test_stages_neural_network(params, stage, visualize_errors=0, real_test=0):\n",
    "    if real_test == 1:\n",
    "        decimal_dataset = generate_test_dataset(n_max=12)\n",
    "    else:\n",
    "        decimal_dataset = generate_test_dataset()\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    correct_predictions_count = 0\n",
    "    test_size = inputs_1.shape[0]\n",
    "\n",
    "    for i in range(test_size):\n",
    "        prediction = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        #print(f'Se ha predicho {prediction} y era {outputs[i]}')\n",
    "        if jnp.all(prediction == outputs[i]):  # Check if the prediction matches the expected output\n",
    "            correct_predictions_count += 1  # Increment correct prediction count\n",
    "        elif visualize_errors == 1:\n",
    "            print(f'Ha fallado {decimal_dataset.iloc[i,0]} por {decimal_dataset.iloc[i,1]}.')\n",
    "            #print(f'Se ha predicho {prediction} y era {outputs[i]}')\n",
    "    return test_size, correct_predictions_count\n",
    "\n",
    "# Predict using the trained neural network\n",
    "def predict(params, x1, x2, stage):\n",
    "    if stage == 1:\n",
    "        binary_pred = neural_network_1(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred\n",
    "    elif stage == 2:\n",
    "        binary_pred = neural_network_2(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred\n",
    "    elif stage == 3:\n",
    "        binary_pred = neural_network_3(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred\n",
    "    elif stage == 4:\n",
    "        binary_pred = neural_network_4(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "\n",
    "# Check if two models are equal\n",
    "def are_models_equal(model_1, model_2):\n",
    "    # Check that both lists have the same length\n",
    "    if len(model_1) != len(model_2):\n",
    "        return False\n",
    "\n",
    "    # Compare each element in both lists\n",
    "    for elem1, elem2 in zip(model_1, model_2):\n",
    "        if isinstance(elem1, jnp.ndarray) and isinstance(elem2, jnp.ndarray):\n",
    "            # Compare two JAX arrays\n",
    "            if not jnp.all(jnp.isclose(elem1, elem2, atol=1e-2)):\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def generate_model(mean=0.5, std=1):\n",
    "    W1 = initialize_random_weights(mean, std, (8, 16))  # 128 neurons in the hidden layer that include element-wise multiplication\n",
    "    W2 = initialize_random_weights(mean, std, (16, 28))  # 448 neurons in the hidden layer that sort the bits\n",
    "    R3 = initialize_random_weights(mean, std, (28))  # 28 neurons that correctly calculate the carry for the second bit\n",
    "    R4 = initialize_random_weights(mean, std, (28))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R5 = initialize_random_weights(mean, std, (28))  # 28 neurons that correctly calculate the carry for the fourth bit\n",
    "    R6 = initialize_random_weights(mean, std, (28))  # 28 neurons that correctly calculate the carry for the fifth bit\n",
    "    R7 = initialize_random_weights(mean, std, (28))  # 28 neurons that correctly calculate the carry for the sixth bit\n",
    "    v3 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the second bit\n",
    "    v4 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v5 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the fourth bit\n",
    "    v6 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the fifth bit\n",
    "    T = initialize_random_weights(mean, std, (28, 7))  # 196 neurons that allow performing the sum\n",
    "    v7 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry vector for all bits\n",
    "    original_model = [W1, W2, R3, R4, R5, R6, R7, v3, v4, v5, v6, T, v7]\n",
    "    trainable_model = [W1, W2, R3, R4, R5, R6, R7, v3, v4, v5, v6, T, v7]\n",
    "    return trainable_model, original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d362f6dc-4abc-46e2-93be-45c196d34004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "\n",
    "def load_trainable_model(model, stage, fecha):\n",
    "    # Ruta dinámica basada en el stage y la fecha\n",
    "    model_path = f'Parameters/{model}_{stage}-{fecha}.pkl'\n",
    "    \n",
    "    # Cargar el archivo .pkl y asignarlo dinámicamente a trainable_model_stage_{stage}\n",
    "    with open(model_path, 'rb') as f:\n",
    "        globals()[f'trainable_model_stage_{stage}'] = pickle.load(f)\n",
    "    \n",
    "    # Confirmar la carga\n",
    "    print(f'Model trainable_model_stage_{stage} loaded successfully.')\n",
    "    return globals()[f'trainable_model_stage_{stage}']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b15af-8b33-4c50-8b2a-7702029c4745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trainable_model_stage_2024_11_08_00_24_10.pkl\n",
      "STAGE 1: Out of 100, 21 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.09245695173740387.\n",
      "STAGE 1: Out of 100, 26 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.06299810856580734.\n",
      "STAGE 1: Out of 100, 42 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.04565931484103203.\n",
      "STAGE 1: Out of 100, 63 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.03389959782361984.\n",
      "STAGE 1: Out of 100, 79 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.025456203147768974.\n",
      "STAGE 1: Out of 100, 88 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.019918130710721016.\n",
      "STAGE 1: Out of 100, 95 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.016270242631435394.\n",
      "STAGE 1: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.01240778248757124.\n",
      "STAGE 1: Out of 100, 100 were predicted correctly in the current model.\n",
      "STAGE 1: Loss is 0.010160425677895546.\n",
      "Objective completed\n",
      "Stage 1 completed in 90.0 trainings.\n",
      "Model trainable_model_stage_1 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Stage_by_stage/AP_0.05_0.05/Stage_1\\trainable_model_stage_1-2024_11_08_00_24_10.pkl\n",
      "Results of Stage 1 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Stage_by_stage/AP_0.05_0.05/Stage_1\\Stage_1_results_2024_11_08_00_24_10.txt\n",
      "STAGE 2: Out of 100, 35 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.03440234437584877.\n",
      "STAGE 2: Out of 100, 40 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.02921699918806553.\n",
      "STAGE 2: Out of 100, 45 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.029410263523459435.\n",
      "STAGE 2: Out of 100, 54 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.027131225913763046.\n",
      "STAGE 2: Out of 100, 58 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.025681495666503906.\n",
      "STAGE 2: Out of 100, 61 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.022938430309295654.\n",
      "STAGE 2: Out of 100, 65 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.021210389211773872.\n",
      "STAGE 2: Out of 100, 69 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.019556697458028793.\n",
      "STAGE 2: Out of 100, 70 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.019336005672812462.\n",
      "STAGE 2: Out of 100, 72 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01853184774518013.\n",
      "STAGE 2: Out of 100, 71 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01804477348923683.\n",
      "STAGE 2: Out of 100, 76 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01739981584250927.\n",
      "STAGE 2: Out of 100, 76 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.016396231949329376.\n",
      "STAGE 2: Out of 100, 77 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.015447824262082577.\n",
      "STAGE 2: Out of 100, 80 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.015517296269536018.\n",
      "STAGE 2: Out of 100, 81 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.014283805154263973.\n",
      "STAGE 2: Out of 100, 88 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012988359667360783.\n",
      "STAGE 2: Out of 100, 88 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013562990352511406.\n",
      "STAGE 2: Out of 100, 88 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.013250323012471199.\n",
      "STAGE 2: Out of 100, 90 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.012140064500272274.\n",
      "STAGE 2: Out of 100, 90 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01138940081000328.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01097450964152813.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.01056505087763071.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.010587148368358612.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.00984839629381895.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.009425429627299309.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.009049136191606522.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.008876847103238106.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.008462854661047459.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.008828554302453995.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.007791617419570684.\n",
      "STAGE 2: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.007925563491880894.\n",
      "STAGE 2: Out of 100, 93 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.007767188362777233.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.007025942672044039.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.007296374067664146.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.006743511650711298.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.006585743278264999.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.007174383848905563.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.006289517041295767.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.005739441141486168.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.00591927720233798.\n",
      "STAGE 2: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0060307784005999565.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.006055569741874933.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.005447016563266516.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.005551920272409916.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.005192591343075037.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004886955954134464.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.005103020928800106.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004667356610298157.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004804946016520262.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004528953228145838.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.005049372557550669.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004512401297688484.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004099506884813309.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0041949874721467495.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0038996953517198563.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004149877466261387.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.003698388347402215.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004214778076857328.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.004089355003088713.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0037452273536473513.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.00367123750038445.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0038321823813021183.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.003934551030397415.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.003318360075354576.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.003367374883964658.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0032947666477411985.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0033166389912366867.\n",
      "STAGE 2: Out of 100, 96 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.003405116032809019.\n",
      "STAGE 2: Out of 100, 97 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0035380504559725523.\n",
      "STAGE 2: Out of 100, 97 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0027806484140455723.\n",
      "STAGE 2: Out of 100, 97 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0029837710317224264.\n",
      "STAGE 2: Out of 100, 97 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0030138336587697268.\n",
      "STAGE 2: Out of 100, 97 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.003083745250478387.\n",
      "STAGE 2: Out of 100, 97 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.003154277103021741.\n",
      "STAGE 2: Out of 100, 97 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.00299916323274374.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.002751648658886552.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0028767792973667383.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.002724299905821681.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.002450188621878624.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0025886264629662037.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.00236597191542387.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.002617918886244297.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.00257613742724061.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0024491979274898767.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0025378065183758736.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0026274421252310276.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0023096688091754913.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0023950887843966484.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.002186667639762163.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.002304274355992675.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0021279235370457172.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.001855597598478198.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0021561223547905684.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0023498956579715014.\n",
      "STAGE 2: Out of 100, 98 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0024430968333035707.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0021254734601825476.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.002074112417176366.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.001994459191337228.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0020872033201158047.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0018441845895722508.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0016757784178480506.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0019724422600120306.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0020564906299114227.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0017955086659640074.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.001865560538135469.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0019010636024177074.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0018746142741292715.\n",
      "STAGE 2: Out of 100, 99 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0016440567560493946.\n",
      "STAGE 2: Out of 100, 100 were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0017894951160997152.\n",
      "Objective completed\n",
      "Stage 2 completed in 1100.0 trainings.\n",
      "Model trainable_model_stage_2 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Stage_by_stage/AP_0.05_0.05/Stage_2\\trainable_model_stage_2-2024_11_08_00_24_10.pkl\n",
      "Results of Stage 2 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Stage_by_stage/AP_0.05_0.05/Stage_2\\Stage_2_results_2024_11_08_00_24_10.txt\n",
      "STAGE 3: Out of 100, 92 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.04941234737634659.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03904680162668228.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.0468469001352787.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.030651936307549477.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.04394998401403427.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.0334617905318737.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02999562956392765.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03394239768385887.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03678015246987343.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03782501071691513.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.033581677824258804.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.027420373633503914.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.033384669572114944.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03230471536517143.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.034264665096998215.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.027071045711636543.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03826688975095749.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03715057671070099.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03094571828842163.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02769131027162075.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.024526162073016167.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02154131606221199.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03678886964917183.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.032656267285346985.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02652023918926716.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03666363283991814.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03967287763953209.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.0345265157520771.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03348679095506668.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.030396593734622.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.028322165831923485.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.04062516242265701.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.0375160351395607.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03131703659892082.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.027209900319576263.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03336821869015694.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03537712246179581.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03533007204532623.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.027117425575852394.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.030225489288568497.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02517138235270977.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03324569761753082.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.04138238728046417.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.038426369428634644.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.028091495856642723.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02796054258942604.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02399800531566143.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.0290371123701334.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03420959413051605.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03631225973367691.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.034162264317274094.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.0320918932557106.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03721385821700096.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03514384478330612.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03727315738797188.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.024919217452406883.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02071833424270153.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03815826401114464.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03101993352174759.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.029961252585053444.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.029974063858389854.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.032980915158987045.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.043245453387498856.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02280956506729126.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02890823781490326.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.024851765483617783.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.0432046577334404.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02996346354484558.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.02681853249669075.\n",
      "STAGE 3: Out of 100, 94 were predicted correctly in the current model.\n",
      "STAGE 3: Loss is 0.03608908876776695.\n"
     ]
    }
   ],
   "source": [
    "AP_name = 'AP_0.05_0.05'\n",
    "folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Parameters/{AP_name}'\n",
    "model = 'trainable_model_stage'\n",
    "\n",
    "date_pattern = r'trainable_model_stage_(\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}).pkl'\n",
    "files = sorted(\n",
    "    (f for f in os.listdir(folder_path) if not f.startswith('.')),  # Filtrar archivos ocultos\n",
    "    key=lambda x: re.search(date_pattern, x).group(1) if re.search(date_pattern, x) else ''\n",
    ")\n",
    "\n",
    "for filename in files:\n",
    "    match = re.search(date_pattern, filename)\n",
    "    if match:\n",
    "        current_time = match.group(1)\n",
    "    else:\n",
    "        print('Error')\n",
    "        break\n",
    "    \n",
    "    file_path = f\"D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Parameters/{AP_name}/{model}_{current_time}.pkl\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        trainable_model = pickle.load(file)\n",
    "\n",
    "    print(f'Loaded {model}_{current_time}.pkl')\n",
    "    h = 0.001 # Additional parameter needed for the two first stages\n",
    "    training_stages = 5\n",
    "    trainings_needed = np.zeros(training_stages)\n",
    "\n",
    "    visualizer = 10\n",
    "    lr_changer = 250\n",
    "    stage_changer = 2500\n",
    "    N=500\n",
    "\n",
    "    for stage in range(1,5): \n",
    "        if stage == 1:\n",
    "            trainable_model_stage_1 = [trainable_model[0], h]\n",
    "        elif stage == 2:\n",
    "            trainable_model_stage_2 = [trainable_model_stage_1[0], trainable_model[1]]\n",
    "        elif stage == 3:\n",
    "            trainable_model_stage_3 = [trainable_model_stage_2[0], \n",
    "                           trainable_model_stage_2[1], \n",
    "                           trainable_model[2], \n",
    "                           trainable_model[3], \n",
    "                           trainable_model[4], \n",
    "                           trainable_model[5], \n",
    "                           trainable_model[6], \n",
    "                           trainable_model[7], \n",
    "                           trainable_model[8], \n",
    "                           trainable_model[9], \n",
    "                           trainable_model[10]]\n",
    "        elif stage == 4:\n",
    "            trainable_model_stage_4 = [trainable_model_stage_3[0], \n",
    "                           trainable_model_stage_3[1], \n",
    "                           trainable_model_stage_3[2], \n",
    "                           trainable_model_stage_3[3], \n",
    "                           trainable_model_stage_3[4], \n",
    "                           trainable_model_stage_3[5], \n",
    "                           trainable_model_stage_3[6], \n",
    "                           trainable_model_stage_3[7], \n",
    "                           trainable_model_stage_3[8], \n",
    "                           trainable_model_stage_3[9], \n",
    "                           trainable_model_stage_3[10],\n",
    "                           trainable_model[11],\n",
    "                           trainable_model[12]\n",
    "                          ]\n",
    "        \n",
    "        save_dir = f\"D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Stage_by_stage/{AP_name}/Stage_{stage}\" \n",
    "        os.makedirs(save_dir, exist_ok=True) \n",
    "        results_file = os.path.join(save_dir, f\"Stage_{stage}_results_{current_time}.txt\") \n",
    "        tee = Tee(results_file, 'w') \n",
    "        sys.stdout = tee\n",
    "    \n",
    "        try:\n",
    "            test_size, correct_predictions_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "            final_loss = 1\n",
    "            lr = 0.001\n",
    "            level = -2\n",
    "            response = \"yes\"\n",
    "            while final_loss != 0:\n",
    "                prev_model = globals()[f\"{model}_{stage}\"]\n",
    "                globals()[f\"{model}_{stage}\"], final_loss = train_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage, level=level, lr=lr, epochs=N)\n",
    "                trainings_needed[stage-1] += 1\n",
    "                if math.isnan(final_loss):\n",
    "                    globals()[f\"{model}_{stage}\"] = prev_model\n",
    "                    print('Loss is NaN.')\n",
    "                    break                \n",
    "                if trainings_needed[stage-1] % visualizer == 0:\n",
    "                    if response.lower() == \"yes\":\n",
    "                        test_size, correct_predictions_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "                        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_count} were predicted correctly in the current model.\")\n",
    "                    elif response.lower() == \"no\":\n",
    "                        print(f\"STAGE {stage}: Objective completed, all are predicted correctly in the current model.\")\n",
    "                    print(f\"STAGE {stage}: Loss is {final_loss}.\")\n",
    "                #if trainings_needed[stage-1] % lr_changer == 0:\n",
    "                #    new_lr = input(f\"Change of learning rate? (Current one is {lr}, press enter if not): \")\n",
    "                #    if new_lr != \"\":\n",
    "                #        lr = float(new_lr)\n",
    "                if trainings_needed[stage-1] % stage_changer == 0:\n",
    "                    response_pre = 'yes'\n",
    "                    if response_pre.lower() == \"yes\":\n",
    "                        break\n",
    "                if correct_predictions_count == test_size:\n",
    "                    response = \"yes\"\n",
    "                    while response.lower() not in [\"yes\", \"no\"]:\n",
    "                        response = input(\"Objective completed, skip to next stage? (yes/no): \")\n",
    "                        if response.lower() not in [\"yes\", \"no\"]:\n",
    "                            print('Incorrect answer')        \n",
    "                    if response.lower() == \"yes\":\n",
    "                        print('Objective completed')\n",
    "                        break\n",
    "                    elif response.lower() == \"no\":\n",
    "                        test_size = correct_predictions_count + 1\n",
    "    \n",
    "            print(f'Stage {stage} completed in {trainings_needed[stage-1]} trainings.')\n",
    "            save_response = 'yes'\n",
    "            if save_response.lower() == 'yes':\n",
    "                save_path = os.path.join(save_dir, f\"trainable_model_stage_{stage}-{current_time}.pkl\")\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    pickle.dump(globals()[f\"{model}_{stage}\"], f)\n",
    "                print(f\"Model trainable_model_stage_{stage} saved at {save_path}\")\n",
    "\n",
    "        finally:\n",
    "            sys.stdout = tee.console\n",
    "            tee.close()\n",
    "        print(f\"Results of Stage {stage} saved in {results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daf55b-da26-4126-8c75-09dcd2915511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
