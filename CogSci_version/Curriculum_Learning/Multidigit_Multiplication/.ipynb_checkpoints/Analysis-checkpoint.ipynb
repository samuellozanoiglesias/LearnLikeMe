{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70eecdc-fa71-44b4-af34-be0a8a0a7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a000c3-2082-4253-ad74-9e17248a0fc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/OneDrive - samuloza/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/results_AP.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load the text file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/OneDrive - samuloza/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      5\u001b[0m     lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Regex patterns to capture stage, loss, and correct predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/OneDrive - samuloza/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/results_AP.txt'"
     ]
    }
   ],
   "source": [
    "name = 'results_AP'\n",
    "# Load the text file\n",
    "file_path = f'D:/OneDrive - samuloza/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/{name}.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Regex patterns to capture stage, loss, and correct predictions\n",
    "model_pattern = r'\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}'\n",
    "stage_pattern = r'STAGE (\\d+):'\n",
    "correct_pattern = r'Out of 100, (\\d+) were predicted correctly in the current model.'\n",
    "loss_pattern = r'Loss is ([\\d\\.]+).'\n",
    "loss_nan_pattern = r'Loss in NaN'\n",
    "\n",
    "# Containers for each stage's data\n",
    "all_data = []\n",
    "\n",
    "# Parse each line\n",
    "for line in lines:\n",
    "    # Detect a new stage\n",
    "    model_match = re.search(model_pattern, line)\n",
    "    if model_match:\n",
    "        current_model = model_match.group(0)\n",
    "    \n",
    "    stage_match = re.search(stage_pattern, line)\n",
    "    if stage_match:\n",
    "        current_stage = int(stage_match.group(1))\n",
    "        \n",
    "    # Capture correct predictions and loss\n",
    "    correct_match = re.search(correct_pattern, line)\n",
    "    if correct_match:\n",
    "        current_predictions = int(correct_match.group(1))\n",
    "\n",
    "    loss_match = re.search(loss_pattern, line)\n",
    "    if loss_match:\n",
    "        current_loss = float(loss_match.group(1))\n",
    "        \n",
    "        all_data.append({\n",
    "            'model': current_model,\n",
    "            'stage': current_stage,\n",
    "            'loss': current_loss,\n",
    "            'correct_predictions': current_predictions\n",
    "        })\n",
    "\n",
    "    elif re.search(loss_nan_pattern, line):\n",
    "        current_loss = float('nan')        \n",
    "        all_data.append({\n",
    "            'model': current_model,\n",
    "            'stage': current_stage,\n",
    "            'loss': current_loss,\n",
    "            'correct_predictions': current_predictions\n",
    "        })\n",
    "        \n",
    "# Convert to DataFrames and save as CSVs\n",
    "df_all_stages = pd.DataFrame(all_data)\n",
    "output_file = f'D:/OneDrive - samuloza/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/all_stage_by_stage_{name}.csv'\n",
    "df_all_stages.to_csv(output_file, sep=';', decimal=',', index=False)\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0423fc16-37cd-43a0-91a4-a14b52aaa89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Analyzed_data/all_Validation_performance_No_stages_results_AP_0.1_0.1.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_performance = 'yes'\n",
    "easy_examples = 'no'\n",
    "type_training = 'No_stages'\n",
    "name = 'AP_0.1_0.1'\n",
    "\n",
    "if easy_examples == 'yes':\n",
    "    if validation_performance == 'yes':\n",
    "        root_folder = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Validation_performance/Easy_examples/{type_training}/{name}/'\n",
    "    else:\n",
    "        root_folder = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Easy_examples/{type_training}/{name}/'\n",
    "else:\n",
    "    if validation_performance == 'yes':\n",
    "        root_folder = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/Validation_performance/{type_training}/{name}/'\n",
    "    else:\n",
    "        root_folder = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Trained_models/{type_training}/{name}/'\n",
    "\n",
    "\n",
    "model_pattern = r'\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}'\n",
    "stage_pattern = r'STAGE (\\d+):'\n",
    "if validation_performance == 'yes':\n",
    "    correct_pattern = r'Out of 144, (\\d+) were predicted correctly in the current model.'\n",
    "else:\n",
    "    correct_pattern = r'Out of 100, (\\d+) were predicted correctly in the current model.'\n",
    "loss_pattern = r'Loss is ([\\d\\.]+).'\n",
    "loss_nan_pattern = r'Loss is NaN'\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file_path in glob(os.path.join(root_folder, '**', '*.txt'), recursive=True):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    model_match = re.search(model_pattern, file_name)\n",
    "    if model_match:\n",
    "        current_model = model_match.group(0)\n",
    "            \n",
    "    for line in lines:\n",
    "        stage_match = re.search(stage_pattern, line)\n",
    "        if stage_match:\n",
    "            current_stage = int(stage_match.group(1))\n",
    "        \n",
    "        correct_match = re.search(correct_pattern, line)\n",
    "        if correct_match:\n",
    "            current_predictions = int(correct_match.group(1))\n",
    "        \n",
    "        loss_match = re.search(loss_pattern, line)\n",
    "        if loss_match:\n",
    "            current_loss = float(loss_match.group(1))\n",
    "            all_data.append({\n",
    "                'model': current_model,\n",
    "                'stage': current_stage,\n",
    "                'loss': current_loss,\n",
    "                'correct_predictions': current_predictions\n",
    "            })\n",
    "            \n",
    "        elif re.search(loss_nan_pattern, line):\n",
    "            current_loss = float('nan')  \n",
    "            all_data.append({\n",
    "                'model': current_model,\n",
    "                'stage': current_stage,\n",
    "                'loss': current_loss,\n",
    "                'correct_predictions': current_predictions\n",
    "            })\n",
    "\n",
    "df_all_stages = pd.DataFrame(all_data)\n",
    "output_dir = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Analyzed_data'\n",
    "if easy_examples == 'yes':\n",
    "    if validation_performance == 'yes':\n",
    "        output_file = f'{output_dir}/all_Validation_performance_Easy_examples_{type_training}_results_{name}.csv'\n",
    "    else:\n",
    "        output_file = f'{output_dir}/all_Easy_examples_{type_training}_results_{name}.csv'\n",
    "else:\n",
    "    if validation_performance == 'yes':\n",
    "        output_file = f'{output_dir}/all_Validation_performance_{type_training}_results_{name}.csv'    \n",
    "    else:\n",
    "        output_file = f'{output_dir}/all_{type_training}_results_{name}.csv'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df_all_stages.to_csv(output_file, sep=';', decimal=',', index=False)\n",
    "\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aabac278-2ba0-41df-915d-553cd8205436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "validation_performance = 'yes'\n",
    "easy_examples = 'no'\n",
    "type_training = 'Stage_by_stage'\n",
    "name = 'AP_0.05_0.05'\n",
    "variables = ['loss','correct_predictions']\n",
    "\n",
    "for variable in variables:\n",
    "    if easy_examples == 'yes':\n",
    "        if validation_performance == 'yes':\n",
    "            df = pd.read_csv(f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Analyzed_data/all_Validation_performance_Easy_examples_{type_training}_results_{name}.csv', delimiter=';', decimal=',')\n",
    "        else:\n",
    "            df = pd.read_csv(f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Analyzed_data/all_Easy_examples_{type_training}_results_{name}.csv', delimiter=';', decimal=',')\n",
    "\n",
    "    else:\n",
    "        if validation_performance == 'yes':\n",
    "            df = pd.read_csv(f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Analyzed_data/all_Validation_performance_{type_training}_results_{name}.csv', delimiter=';', decimal=',')\n",
    "        else: \n",
    "            df = pd.read_csv(f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Analyzed_data/all_{type_training}_results_{name}.csv', delimiter=';', decimal=',')\n",
    "    \n",
    "    \n",
    "    models = df['model'].unique()\n",
    "    stages = df['stage'].unique()\n",
    "    \n",
    "    for model in models:\n",
    "        for stage in stages:\n",
    "            # Filtrar los datos para el modelo y etapa actuales\n",
    "            filtered_df = df[(df['model'] == model) & (df['stage'] == stage)]\n",
    "            # Si no filtered_dfhay datos para esta combinación de modelo y etapa, continuar con el siguiente\n",
    "            if filtered_df.empty:\n",
    "                print('Oh oh, continue :(')\n",
    "                continue\n",
    "            \n",
    "            if easy_examples == 'yes':\n",
    "                if validation_performance == 'yes':\n",
    "                    output_dir = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Visual_results/Visual_results_Validation_performance_Easy_examples_{type_training}_{name}/Analysis_{stage}/{variable}'\n",
    "                else:\n",
    "                    output_dir = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Visual_results/Visual_results_Easy_examples_{type_training}_{name}/Analysis_{stage}/{variable}'\n",
    "            else:\n",
    "                if validation_performance == 'yes':\n",
    "                    output_dir = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Visual_results/Visual_results_Validation_performance_{type_training}_{name}/Analysis_{stage}/{variable}'\n",
    "                else:\n",
    "                    output_dir = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Visual_results/Visual_results_{type_training}_{name}/Analysis_{stage}/{variable}'\n",
    "                    \n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Configurar la figura\n",
    "            plt.figure()\n",
    "            \n",
    "            # Representar la evolución de 'loss'\n",
    "            plt.plot(range(1, len(filtered_df) + 1), filtered_df[variable], marker='o')\n",
    "            \n",
    "            # Añadir título y etiquetas\n",
    "            plt.title(f'Evolution of {variable} - Model: {model}, Stage: {stage}')\n",
    "            plt.xlabel('Training')\n",
    "            plt.ylabel(variable)\n",
    "            \n",
    "            # Guardar la gráfica en la carpeta especificada\n",
    "            output_path = os.path.join(output_dir, f'{variable}_{model}_{stage}.png')\n",
    "            plt.savefig(output_path)\n",
    "            \n",
    "            # Cerrar la figura para liberar memoria\n",
    "            plt.close()\n",
    "    \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a3a47-04c9-40a7-b857-be0623434925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
