{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e67e4db-f139-4bde-b30e-e68e37779b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad\n",
    "from jax.nn import relu, sigmoid\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pytz\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e32cf2-490d-4527-af07-dd4e51758135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random_weights(mean, std, shape = ()):\n",
    "    return np.random.normal(loc=mean, scale=std, size=shape)\n",
    "\n",
    "# We use a sinusoidal function to approximate odd numbers by their immediately preceding even number and preserve differentiability\n",
    "def lower_even(x):\n",
    "    return x - 0.5 * (1 - jnp.cos(jnp.pi * x))\n",
    "\n",
    "# We use a sinusoidal function to approximate 0 for evens and 1 for odds while preserving differentiability\n",
    "def differentiable_even_or_odd(x):\n",
    "    return ((2 * x ** 3) / 3) - 3 * x ** 2 + ((10 * x) / 3)\n",
    "\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "\n",
    "# Cargar las parejas desde el archivo\n",
    "with open(f\"{folder}/train_couples.txt\", \"r\") as file:\n",
    "    train_couples = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_with_carry_over.txt\", \"r\") as file:\n",
    "    combinations_with_carry_over = eval(file.read())  # Leer y convertir el contenido en una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset.txt\", 'r') as file:\n",
    "    real_test_dataset = eval(file.read())  # Convertir el contenido del archivo a una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_with_carry_over.txt\", 'r') as file:\n",
    "    real_test_carry_over_dataset = eval(file.read())\n",
    "    \n",
    "# Separar parejas con y sin ceros\n",
    "train_without_zeros = [pair for pair in train_couples if 0 not in pair]\n",
    "train_with_carry_over = [pair for pair in train_couples if pair in combinations_with_carry_over]\n",
    "\n",
    "# Function to generate dataset with multiplication\n",
    "def generate_dataset_with_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas con ceros\n",
    "    selected_pairs = random.choices(train_couples, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_without_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas sin ceros\n",
    "    selected_pairs = random.choices(train_without_zeros, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_test_dataset(n_max=100):\n",
    "    # Create the columns\n",
    "    column_1 = list(range(n_max)) * n_max  # Numbers from 0 to 9 repeated 10 times\n",
    "    column_2 = [i for i in range(n_max) for _ in range(n_max)]  # Numbers from 0 to 9 repeated sequentially 10 times\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_real_test_dataset():\n",
    "    # Desempaquetar las parejas (a_i, b_i)\n",
    "    column_1, column_2 = zip(*real_test_dataset)\n",
    "\n",
    "    # Crear un DataFrame con las dos primeras columnas\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna como la suma de las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def decimal_to_binary(n, bits):\n",
    "    if 0 <= n < 2**bits:\n",
    "        # Convert the number to a binary string and then to an array of integers (0 and 1)\n",
    "        return np.array(list(format(n, f'0{bits}b'))).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(\"Number out of range\")\n",
    "\n",
    "# Function to convert binary number to decimal\n",
    "def binary_to_decimal(binary_vector, bits):\n",
    "    # Ensure the vector has the correct number of elements\n",
    "    if len(binary_vector) != bits:\n",
    "        raise ValueError(f\"The vector must have exactly {bits} elements.\")\n",
    "\n",
    "    # Calculate the decimal number\n",
    "    decimal = 0\n",
    "    for i in range(bits):\n",
    "        decimal += binary_vector[i] * (2 ** (bits - 1 - i))\n",
    "\n",
    "    return decimal\n",
    "\n",
    "def transform_to_tridimensional_matrix(dataset, bits_init=7, bits_end=8):\n",
    "    rows, cols = dataset.shape\n",
    "    if cols != 3:\n",
    "        raise ValueError(\"The dataset must have exactly 3 columns.\")\n",
    "\n",
    "    # Initialize the three matrices\n",
    "    matrix_column_1 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_2 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_3 = np.zeros((rows, bits_end), dtype=np.int8)\n",
    "\n",
    "    # Fill the matrices with the binary representation of each column\n",
    "    for i in range(rows):\n",
    "        matrix_column_1[i] = decimal_to_binary(dataset.iloc[i, 0], bits_init)\n",
    "        matrix_column_2[i] = decimal_to_binary(dataset.iloc[i, 1], bits_init)\n",
    "        matrix_column_3[i] = decimal_to_binary(dataset.iloc[i, 2], bits_end)\n",
    "\n",
    "    return matrix_column_1, matrix_column_2, matrix_column_3\n",
    "    \n",
    "    \n",
    "def prepare_dataset(level, size=1, couples_included=[]):       \n",
    "    if level == -3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = couples_included\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == -2:\n",
    "        dataset = generate_dataset_with_zeros(size)\n",
    "        return dataset\n",
    "        \n",
    "    elif level == -1:\n",
    "        dataset = generate_dataset_without_zeros(size)\n",
    "        return dataset\n",
    "\n",
    "    elif level == 0:\n",
    "        dataset = pd.DataFrame()\n",
    "        while len(dataset) < size:\n",
    "            column_1 = np.random.randint(1, 10, size)\n",
    "            column_2 = np.random.randint(1, 10, size)\n",
    "            temp_dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "            temp_dataset = temp_dataset[~temp_dataset[['Column_1', 'Column_2']].apply(tuple, axis=1).isin(combinations_with_carry_over)]\n",
    "            dataset = pd.concat([dataset, temp_dataset])\n",
    "        dataset = dataset.iloc[:size].reset_index(drop=True)\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 1:\n",
    "        pairs = random.choices(train_with_carry_over, k=size)\n",
    "        column_1 = [pair[0] for pair in pairs]\n",
    "        column_2 = [pair[1] for pair in pairs]\n",
    "        dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "        dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "\n",
    "def prepare_outputs(stage, x1, x2, outputs_prev):\n",
    "    if stage == 1:\n",
    "        outputs = []\n",
    "        for vec1, vec2 in zip(x1, x2):\n",
    "            z2 = lower_even(vec1[6] + vec2[6])\n",
    "            z3 = lower_even(vec1[5] + vec2[5] + z2 * 1/2)\n",
    "            z4 = lower_even(vec1[4] + vec2[4] + z3 * 1/2)\n",
    "            z5 = lower_even(vec1[3] + vec2[3] + z4 * 1/2)\n",
    "            z6 = lower_even(vec1[2] + vec2[2] + z5 * 1/2)\n",
    "            z7 = lower_even(vec1[1] + vec2[1] + z6 * 1/2)\n",
    "            z8 = lower_even(vec1[0] + vec2[0] + z7 * 1/2)\n",
    "            outputs.append([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "        return np.array(outputs)\n",
    "\n",
    "    elif stage == 2:\n",
    "        return outputs_prev\n",
    "        \n",
    "    elif stage == 3:\n",
    "        return outputs_prev\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "\n",
    "# Perfect parameters needed for the stages where a part of the NN performs perfectly\n",
    "# R vectors of dimension (14,1)\n",
    "R2_perfect = np.zeros((14))\n",
    "R3_perfect = np.zeros((14))\n",
    "R4_perfect = np.zeros((14))\n",
    "R5_perfect = np.zeros((14))\n",
    "R6_perfect = np.zeros((14))\n",
    "R7_perfect = np.zeros((14))\n",
    "R8_perfect = np.zeros((14))\n",
    "\n",
    "for i in range(2):\n",
    "    R2_perfect[7*i + 6] = 1\n",
    "    R3_perfect[7*i + 5] = 1\n",
    "    R4_perfect[7*i + 4] = 1\n",
    "    R5_perfect[7*i + 3] = 1\n",
    "    R6_perfect[7*i + 2] = 1\n",
    "    R7_perfect[7*i + 1] = 1\n",
    "    R8_perfect[7*i + 0] = 1\n",
    "\n",
    "# Scalar parameters v\n",
    "v2_perfect = 1/2\n",
    "v3_perfect = 1/2\n",
    "v4_perfect = 1/2\n",
    "v5_perfect = 1/2\n",
    "v6_perfect = 1/2\n",
    "v7_perfect = 1/2\n",
    "\n",
    "# Matrix T of dimension (28,7)\n",
    "T_perfect = np.zeros((14,8))\n",
    "for i in range(7):\n",
    "    for j in range(2):\n",
    "        T_perfect[7*j + i, i + 1] = 1\n",
    "\n",
    "# Parameter v\n",
    "v_perfect = 1/2\n",
    "\n",
    "# Neural network in every stage\n",
    "def neural_network_1(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    #y = differentiable_even_or_odd(relu(jnp.dot(vec, T) + jnp.dot(z, v7)))\n",
    "    return z\n",
    "\n",
    "def neural_network_2(params, x1, x2):\n",
    "    T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2_perfect)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3_perfect) + jnp.dot(z2, v2_perfect)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4_perfect) + jnp.dot(z3, v3_perfect)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5_perfect) + jnp.dot(z4, v4_perfect)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6_perfect) + jnp.dot(z5, v5_perfect)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7_perfect) + jnp.dot(z6, v6_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8_perfect) + jnp.dot(z7, v7_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "    \n",
    "def neural_network_3(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "\n",
    "# Loss functions in every stage\n",
    "def loss_1(params, x1, x2, y):\n",
    "    pred = neural_network_1(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_2(params, x1, x2, y):\n",
    "    pred = neural_network_2(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_3(params, x1, x2, y):\n",
    "    pred = neural_network_3(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "# Loss functions in every step\n",
    "@jax.jit\n",
    "def update_params_1(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_1)(params, x1, x2, y)\n",
    "    step_loss = loss_1(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_2(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_2)(params, x1, x2, y)\n",
    "    step_loss = loss_2(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "    \n",
    "@jax.jit\n",
    "def update_params_3(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_3)(params, x1, x2, y)\n",
    "    step_loss = loss_3(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "def decide_training(params, x1, x2, y, lr, stage):\n",
    "    if stage == 1:\n",
    "        params, step_loss = update_params_1(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 2:\n",
    "        params, step_loss = update_params_2(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "        \n",
    "    elif stage == 3:\n",
    "        params, step_loss = update_params_3(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "        \n",
    "# Main function to train the network\n",
    "def train_stages_neural_network(params, stage, level, lr=0.01, epochs=100):\n",
    "    decimal_dataset = prepare_dataset(level, epochs)\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    final_loss = 0\n",
    "    # Train the network\n",
    "    for epoch in range(epochs):\n",
    "        # Update parameters at each step\n",
    "        params, step_loss = decide_training(params, inputs_1[epoch], inputs_2[epoch], outputs[epoch], lr, stage)\n",
    "        final_loss += step_loss\n",
    "\n",
    "    final_loss = final_loss / epochs\n",
    "    #print(f\"Loss: {final_loss:.6f}\")\n",
    "    return params, final_loss\n",
    "\n",
    "\n",
    "\n",
    "def decide_test(params, stage, real_test=0, visualize_errors=0):\n",
    "    if real_test == 1:\n",
    "        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count, carry_over_size, correct_carry_over_predictions_tested_count = real_test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {carry_over_size}, {correct_carry_over_predictions_tested_count} tested with carry-over were predicted correctly in the current model.\")      \n",
    "\n",
    "    else: \n",
    "        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "        \n",
    "\n",
    "# Main function to test the network\n",
    "def test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_test_dataset()\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    \n",
    "    correct_predictions_tested_count = 0\n",
    "    correct_predictions_trained_count = 0  # Counter for trained couples\n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_size = len(train_couples)\n",
    "    test_size = set_size - train_size\n",
    "    \n",
    "    for i in range(set_size):\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        # Check if the prediction matches the expected output\n",
    "        if jnp.all(prediction == outputs[i]):  \n",
    "            if (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1]) in train_couples:\n",
    "                correct_predictions_trained_count += 1  # Increment for trained couples\n",
    "            else:\n",
    "                correct_predictions_tested_count += 1 # Increment for tested couples\n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{decimal_dataset.iloc[i, 0]} plus {decimal_dataset.iloc[i, 1]} has failed.')\n",
    "\n",
    "    return test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count\n",
    "\n",
    "def real_test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_real_test_dataset()    \n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    \n",
    "    correct_predictions_tested_count = 0\n",
    "    correct_predictions_trained_count = 0  # Counter for trained couples\n",
    "    correct_carry_over_predictions_tested_count = 0\n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_size = len(train_couples)\n",
    "    test_size = set_size - train_size\n",
    "    carry_over_size = len(real_test_carry_over_dataset)  # Total de combinaciones con carry-over\n",
    "\n",
    "    for i in range(set_size):\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        # Check if the prediction matches the expected output\n",
    "        if jnp.all(prediction == outputs[i]):  \n",
    "            # Comprobar si la predicción acertada está en el dataset con carry-over\n",
    "            if (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1]) in real_test_carry_over_dataset:\n",
    "                correct_carry_over_predictions_tested_count += 1  # Incrementar el contador para predicciones correctas con carry-over\n",
    "            if (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1]) in train_couples:\n",
    "                correct_predictions_trained_count += 1  # Incrementar para las parejas entrenadas\n",
    "            else:\n",
    "                correct_predictions_tested_count += 1  # Incrementar para las parejas probadas\n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{decimal_dataset.iloc[i, 0]} plus {decimal_dataset.iloc[i, 1]} has failed.')\n",
    "\n",
    "    return test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count, carry_over_size, correct_carry_over_predictions_tested_count\n",
    "\n",
    "\n",
    "# Predict using the trained neural network\n",
    "def predict(params, x1, x2, stage):\n",
    "    if stage == 1:\n",
    "        binary_pred = neural_network_1(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 2:\n",
    "        binary_pred = neural_network_2(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 3:\n",
    "        binary_pred = neural_network_3(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79e9a11-6884-4c9b-94a0-e5c5243612d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_model():\n",
    "    # R vectors of dimension (14,1)\n",
    "    R2_perfect = np.zeros((14))\n",
    "    R3_perfect = np.zeros((14))\n",
    "    R4_perfect = np.zeros((14))\n",
    "    R5_perfect = np.zeros((14))\n",
    "    R6_perfect = np.zeros((14))\n",
    "    R7_perfect = np.zeros((14))\n",
    "    R8_perfect = np.zeros((14))\n",
    "    \n",
    "    for i in range(2):\n",
    "        R2_perfect[7*i + 6] = 1\n",
    "        R3_perfect[7*i + 5] = 1\n",
    "        R4_perfect[7*i + 4] = 1\n",
    "        R5_perfect[7*i + 3] = 1\n",
    "        R6_perfect[7*i + 2] = 1\n",
    "        R7_perfect[7*i + 1] = 1\n",
    "        R8_perfect[7*i + 0] = 1\n",
    "    \n",
    "    # Scalar parameters v\n",
    "    v2_perfect = 1/2\n",
    "    v3_perfect = 1/2\n",
    "    v4_perfect = 1/2\n",
    "    v5_perfect = 1/2\n",
    "    v6_perfect = 1/2\n",
    "    v7_perfect = 1/2\n",
    "    \n",
    "    # Matrix T of dimension (28,7)\n",
    "    T_perfect = np.zeros((14,8))\n",
    "    for i in range(7):\n",
    "        for j in range(2):\n",
    "            T_perfect[7*j + i, i + 1] = 1\n",
    "    \n",
    "    # Parameter v\n",
    "    v_perfect = 1/2\n",
    "    \n",
    "    original_model = [R2_perfect, R3_perfect, R4_perfect, R5_perfect, R6_perfect, R7_perfect, R8_perfect,\n",
    "            v2_perfect, v3_perfect, v4_perfect, v5_perfect, v6_perfect, v7_perfect, \n",
    "            T_perfect, v_perfect] \n",
    "    trainable_model = [R2_perfect, R3_perfect, R4_perfect, R5_perfect, R6_perfect, R7_perfect, R8_perfect,\n",
    "            v2_perfect, v3_perfect, v4_perfect, v5_perfect, v6_perfect, v7_perfect, \n",
    "            T_perfect, v_perfect] \n",
    "    return trainable_model, original_model\n",
    "\n",
    "def generate_model_random(mean=0.5, std=1):\n",
    "    R2 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the second bit\n",
    "    R3 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R4 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R5 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R6 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R7 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R8 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    v2 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v3 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v4 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v5 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v6 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v7 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    T = initialize_random_weights(mean, std, (14, 8))  # 196 neurons that allow performing the sum\n",
    "    v = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry vector for all bits\n",
    "    original_model = [R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v]\n",
    "    trainable_model = [R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v]\n",
    "    return trainable_model, original_model\n",
    "    \n",
    "def generate_model_AP(epsilon_non_zeros = 0.01, epsilon_zeros = 0.01):   \n",
    "    R2_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R3_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R4_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R5_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R6_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R7_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R8_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    for i in range(2):\n",
    "        R2_almost_perfect[7*i + 6] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R3_almost_perfect[7*i + 5] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R4_almost_perfect[7*i + 4] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R5_almost_perfect[7*i + 3] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R6_almost_perfect[7*i + 2] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R7_almost_perfect[7*i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R8_almost_perfect[7*i + 0] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v2_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v3_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v4_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v5_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v6_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v7_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    T_almost_perfect = np.zeros((14,8)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    for i in range(7):\n",
    "        for j in range(2):\n",
    "            T_almost_perfect[7*j + i, i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    original_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    trainable_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    return trainable_model, original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb1a38e-9ed3-4e9d-8e2a-d7981631eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "        \n",
    "def load_trainable_model(model, current_time, training_type, stage = 0):\n",
    "    folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "    if stage == 0:\n",
    "        model_path = f'{folder}/Parameters/{training_type}/{model}_{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'trainable_model'] = pickle.load(f)\n",
    "        print(f'Model trainable_model_{current_time} loaded successfully.')\n",
    "        return globals()[f'trainable_model']\n",
    "        \n",
    "    else:\n",
    "        model_path = f'{folder}/Trained_models/Stages/{training_type}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'{model}_{stage}'] = pickle.load(f)\n",
    "        print(f'Model {model}_{stage}_{current_time} loaded successfully.')\n",
    "        return globals()[f'{model}_{stage}']\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "030cfa0a-71d1-4080-9fa6-f71d820a5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: trainable_model_stage_2024_11_20_11_30_19.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_21.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_23.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_25.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_27.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_29.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_31.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_33.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_35.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_37.pkl\n"
     ]
    }
   ],
   "source": [
    "iters = 10\n",
    "training_type = 'Generated_model'\n",
    "\n",
    "for i in range(iters):\n",
    "    if training_type == 'Perfect_model':\n",
    "        trainable_model, original_model = perfect_model()\n",
    "    elif training_type == 'Generated_model':\n",
    "        trainable_model, original_model = generate_model_random()\n",
    "    else:\n",
    "        parts = training_type.split('_')\n",
    "        epsilon_non_zeros = float(parts[1])\n",
    "        epsilon_zeros = float(parts[2]) \n",
    "        trainable_model, original_model = generate_model_AP(epsilon_non_zeros=epsilon_non_zeros, epsilon_zeros=epsilon_zeros)\n",
    "        \n",
    "    trainable_model_stage_1 = [\n",
    "        trainable_model[0], trainable_model[1], trainable_model[2], trainable_model[3], \n",
    "        trainable_model[4], trainable_model[5], trainable_model[6], trainable_model[7], \n",
    "        trainable_model[8], trainable_model[9], trainable_model[10], trainable_model[11], \n",
    "        trainable_model[12]\n",
    "    ]\n",
    "    trainable_model_stage_2 = [trainable_model[13], trainable_model[14]]\n",
    "                                       \n",
    "    training_stages = 3\n",
    "    trainings_needed = np.zeros(training_stages)\n",
    "    folder_path = f\"D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Parameters/Pruebas/{training_type}\"\n",
    "    os.makedirs(folder_path, exist_ok=True) \n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    file_path = os.path.join(folder_path, f\"{model}_{current_time}.pkl\")\n",
    "    \n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(original_model, file)\n",
    "\n",
    "    print(f'Saved file: {model}_{current_time}.pkl')\n",
    "\n",
    "    # Añadir pausa de 2 segundos\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd36f332-63af-4dac-9970-6df9713fb387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: trainable_model_stage_2024_11_20_23_59_29.pkl\n",
      "STAGE 2: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 2000 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.0008405009866692126.\n",
      "Objective completed\n",
      "Stage 2 completed in 10.0 trainings.\n",
      "Model trainable_model_stage_2 saved at D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Pruebas/Stages/AP_0.05_0.05/Stage_2\\trainable_model_stage_2-2024_11_20_23_59_29.pkl\n",
      "Results of Stage 2 saved in D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Pruebas/Stages/AP_0.05_0.05/Stage_2\\Stage_2_results_2024_11_20_23_59_29.txt\n"
     ]
    }
   ],
   "source": [
    "iters = 1\n",
    "model = 'trainable_model_stage'\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "training_type = 'AP_0.05_0.05'\n",
    "\n",
    "for iteration in range(iters):  \n",
    "    if training_type == 'Perfect_model':\n",
    "        trainable_model, original_model = perfect_model()\n",
    "    elif training_type == 'Generated_model':\n",
    "        trainable_model, original_model = generate_model_random()\n",
    "    else:\n",
    "        parts = training_type.split('_')\n",
    "        epsilon_non_zeros = float(parts[1])\n",
    "        epsilon_zeros = float(parts[2]) \n",
    "        trainable_model, original_model = generate_model_AP(epsilon_non_zeros = epsilon_non_zeros, epsilon_zeros = epsilon_zeros)\n",
    "        \n",
    "    trainable_model_stage_1 = [trainable_model[0], trainable_model[1], trainable_model[2], trainable_model[3], trainable_model[4], trainable_model[5], trainable_model[6], trainable_model[7], trainable_model[8], trainable_model[9], trainable_model[10], trainable_model[11], trainable_model[12]]\n",
    "    trainable_model_stage_2 = [trainable_model[13], trainable_model[14]]\n",
    "                                       \n",
    "    training_stages = 3\n",
    "    trainings_needed = np.zeros(training_stages)\n",
    "\n",
    "    folder_path = f\"{folder}/Parameters/Pruebas/{training_type}\"\n",
    "    os.makedirs(folder_path, exist_ok=True) \n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    file_path = os.path.join(folder_path, f\"{model}_{current_time}.pkl\")\n",
    "    \n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(original_model, file)\n",
    "    \n",
    "    print(f'Saved file: {model}_{current_time}.pkl')\n",
    "    \n",
    "    visualizer = 10\n",
    "    lr_changer = 250\n",
    "    stage_changer = 2500\n",
    "    N = 500\n",
    "\n",
    "    for stage in range(2,3):\n",
    "        if stage == 3:\n",
    "            trainable_model_stage_3 = [trainable_model_stage_1[0], \n",
    "                                       trainable_model_stage_1[1], \n",
    "                                       trainable_model_stage_1[2], \n",
    "                                       trainable_model_stage_1[3], \n",
    "                                       trainable_model_stage_1[4], \n",
    "                                       trainable_model_stage_1[5], \n",
    "                                       trainable_model_stage_1[6], \n",
    "                                       trainable_model_stage_1[7], \n",
    "                                       trainable_model_stage_1[8], \n",
    "                                       trainable_model_stage_1[9], \n",
    "                                       trainable_model_stage_1[10],\n",
    "                                       trainable_model_stage_1[11],\n",
    "                                       trainable_model_stage_1[12],\n",
    "                                       trainable_model_stage_2[0],\n",
    "                                       trainable_model_stage_2[1]]\n",
    "        \n",
    "        save_dir = f\"{folder}/Trained_models/Pruebas/Stages/{training_type}/Stage_{stage}\" \n",
    "        os.makedirs(save_dir, exist_ok=True) \n",
    "        results_file = os.path.join(save_dir, f\"Stage_{stage}_results_{current_time}.txt\") \n",
    "        tee = Tee(results_file, 'w') \n",
    "        sys.stdout = tee\n",
    "    \n",
    "        try:\n",
    "            test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "            final_loss = 1\n",
    "            lr = 0.01\n",
    "            level = -2\n",
    "            response = \"yes\"\n",
    "            while final_loss != 0:\n",
    "                prev_model = globals()[f\"{model}_{stage}\"]\n",
    "                globals()[f\"{model}_{stage}\"], final_loss = train_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage, level=level, lr=lr, epochs=N)\n",
    "                trainings_needed[stage-1] += 1\n",
    "                if math.isnan(final_loss):\n",
    "                    globals()[f\"{model}_{stage}\"] = prev_model\n",
    "                    print('Loss is NaN.')\n",
    "                    break                \n",
    "                if trainings_needed[stage-1] % visualizer == 0:\n",
    "                    if response.lower() == \"yes\":\n",
    "                        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "                        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "                        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "                    elif response.lower() == \"no\":\n",
    "                        print(f\"STAGE {stage}: Objective completed, all are predicted correctly in the current model.\")\n",
    "                    print(f\"STAGE {stage}: Loss is {final_loss}.\")\n",
    "                #if trainings_needed[stage-1] % lr_changer == 0:\n",
    "                #    new_lr = input(f\"Change of learning rate? (Current one is {lr}, press enter if not): \")\n",
    "                #    if new_lr != \"\":\n",
    "                #        lr = float(new_lr)\n",
    "                if trainings_needed[stage-1] % stage_changer == 0:\n",
    "                    response_pre = 'yes'\n",
    "                    if response_pre.lower() == \"yes\":\n",
    "                        break\n",
    "                if correct_predictions_trained_count == train_size:\n",
    "                    response = \"yes\"\n",
    "                    while response.lower() not in [\"yes\", \"no\"]:\n",
    "                        response = input(\"Objective completed, skip to next stage? (yes/no): \")\n",
    "                        if response.lower() not in [\"yes\", \"no\"]:\n",
    "                            print('Incorrect answer')        \n",
    "                    if response.lower() == \"yes\":\n",
    "                        print('Objective completed')\n",
    "                        break\n",
    "                    elif response.lower() == \"no\":\n",
    "                        train_size = correct_predictions_trained_count + 1\n",
    "    \n",
    "            print(f'Stage {stage} completed in {trainings_needed[stage-1]} trainings.')\n",
    "            save_response = 'yes'\n",
    "            if save_response.lower() == 'yes':\n",
    "                save_path = os.path.join(save_dir, f\"trainable_model_stage_{stage}-{current_time}.pkl\")\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    pickle.dump(globals()[f\"{model}_{stage}\"], f)\n",
    "                print(f\"Model trainable_model_stage_{stage} saved at {save_path}\")\n",
    "\n",
    "        finally:\n",
    "            sys.stdout = tee.console\n",
    "            tee.close()\n",
    "        print(f\"Results of Stage {stage} saved in {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119f3987-136e-47dd-92cf-256132cf851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Array([[ 1.4521866e-07,  1.0010817e+00,  2.4887169e-05, -5.3063320e-07,\n",
      "        -1.1905707e-05, -7.9093597e-06, -1.5000695e-07,  1.9009497e-02],\n",
      "       [ 4.3020741e-08,  6.9722148e-05,  1.0003989e+00, -6.3887632e-07,\n",
      "        -8.7392382e-06, -7.2898711e-06, -1.4341472e-07,  2.3062918e-02],\n",
      "       [ 3.7021120e-08,  1.3728829e-05,  7.2603275e-06,  9.9991357e-01,\n",
      "         5.2759874e-06,  1.1131837e-05, -3.5016791e-07, -6.3215066e-03],\n",
      "       [-7.5445810e-09,  1.9604215e-05,  5.0169679e-06,  1.1190675e-06,\n",
      "         9.9943155e-01,  1.0027662e-05, -4.6959077e-08,  1.8424900e-03],\n",
      "       [-8.7447507e-09,  1.4749628e-05,  2.2037191e-06,  2.6185700e-07,\n",
      "         1.9680392e-06,  9.9896234e-01, -2.2389155e-07, -1.6322404e-03],\n",
      "       [-2.6034595e-08,  1.7774169e-06, -3.6800589e-06,  8.9416193e-07,\n",
      "        -6.7547938e-07, -5.0825533e-06,  1.0000426e+00, -7.0721041e-03],\n",
      "       [-5.1758370e-08,  1.3337871e-06, -2.0957407e-06,  6.0209226e-07,\n",
      "        -1.9700842e-06, -8.1008757e-06, -1.0739950e-06,  9.5935482e-01],\n",
      "       [ 1.5237285e-07,  9.9889439e-01, -2.3861030e-05,  1.8200799e-07,\n",
      "         9.7727643e-06,  2.9065293e-05, -8.2737962e-08,  8.6124223e-03],\n",
      "       [ 2.6443936e-09, -5.5074644e-05,  9.9959946e-01,  1.6630514e-06,\n",
      "         6.6293001e-06,  2.1458225e-06,  6.2601009e-07,  1.4836876e-02],\n",
      "       [-2.4479233e-08, -2.6659775e-06, -6.5445283e-07,  1.0000895e+00,\n",
      "        -1.0140729e-05, -1.7407132e-05,  6.6387429e-07, -1.1754007e-03],\n",
      "       [-2.1586027e-08, -1.3099475e-05, -4.9112259e-06, -1.5906619e-06,\n",
      "         1.0005666e+00, -3.4696739e-06, -3.0569191e-07, -2.6016661e-03],\n",
      "       [-8.4013365e-09, -8.8114775e-06, -2.5827405e-06, -1.6235299e-06,\n",
      "        -3.9137753e-06,  1.0010533e+00, -3.5978354e-07, -1.5326231e-03],\n",
      "       [-1.0237847e-08, -9.5014493e-06,  4.8534189e-06,  1.8056994e-07,\n",
      "         5.8968402e-07, -9.0794707e-08,  9.9997073e-01, -1.4092195e-02],\n",
      "       [-1.6630093e-08,  4.3206069e-06,  3.9169613e-06, -1.5902910e-06,\n",
      "        -1.8370438e-06, -6.6348998e-06, -6.6427259e-07,  9.5472413e-01]],      dtype=float32), Array(0.49999857, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(trainable_model_stage_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bcf69-7820-4b5b-9f29-8421ac387fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097150cc-3449-4882-a671-a686eeff498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bcfda6c-006b-4d95-b198-1cbc9f667210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trainable_model_2024_11_20_01_06_49 loaded successfully.\n",
      "STAGE 2: Out of 8000, 4503 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1095 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.23107725381851196.\n",
      "STAGE 2: Out of 8000, 4139 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1018 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.21829132735729218.\n",
      "STAGE 2: Out of 8000, 4426 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1088 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.23102140426635742.\n",
      "STAGE 2: Out of 8000, 4333 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1070 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.21148155629634857.\n",
      "STAGE 2: Out of 8000, 4320 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1064 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.21000348031520844.\n",
      "STAGE 2: Out of 8000, 4303 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1059 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.21396061778068542.\n",
      "STAGE 2: Out of 8000, 4212 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1038 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.20769721269607544.\n",
      "STAGE 2: Out of 8000, 4294 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 2000, 1060 tested were predicted correctly in the current model.\n",
      "STAGE 2: Loss is 0.20922911167144775.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainings_needed[stage\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m%\u001b[39m visualizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 82\u001b[0m         test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count \u001b[38;5;241m=\u001b[39m \u001b[43mtest_stages_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTAGE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_predictions_trained_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trained were predicted correctly in the current model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTAGE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_predictions_tested_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tested were predicted correctly in the current model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 349\u001b[0m, in \u001b[0;36mtest_stages_neural_network\u001b[1;34m(params, stage, visualize_errors)\u001b[0m\n\u001b[0;32m    346\u001b[0m test_size \u001b[38;5;241m=\u001b[39m set_size \u001b[38;5;241m-\u001b[39m train_size\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(set_size):\n\u001b[1;32m--> 349\u001b[0m     prediction, binary_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;66;03m# Check if the prediction matches the expected output\u001b[39;00m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mall(prediction \u001b[38;5;241m==\u001b[39m outputs[i]):  \n",
      "Cell \u001b[1;32mIn[18], line 369\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(params, x1, x2, stage)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rounded_pred, binary_pred\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 369\u001b[0m     binary_pred \u001b[38;5;241m=\u001b[39m \u001b[43mneural_network_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m     rounded_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(binary_pred)\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rounded_pred, binary_pred\n",
      "Cell \u001b[1;32mIn[18], line 251\u001b[0m, in \u001b[0;36mneural_network_2\u001b[1;34m(params, x1, x2)\u001b[0m\n\u001b[0;32m    249\u001b[0m z7 \u001b[38;5;241m=\u001b[39m lower_even(jnp\u001b[38;5;241m.\u001b[39mdot(x, R7_perfect) \u001b[38;5;241m+\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(z6, v6_perfect)) \u001b[38;5;66;03m# z7 is a scalar with the seventh carry over\u001b[39;00m\n\u001b[0;32m    250\u001b[0m z8 \u001b[38;5;241m=\u001b[39m lower_even(jnp\u001b[38;5;241m.\u001b[39mdot(x, R8_perfect) \u001b[38;5;241m+\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(z7, v7_perfect)) \u001b[38;5;66;03m# z7 is a scalar with the seventh carry over\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m y \u001b[38;5;241m=\u001b[39m differentiable_even_or_odd(jnp\u001b[38;5;241m.\u001b[39mdot(x, T) \u001b[38;5;241m+\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(z, v))\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:5417\u001b[0m, in \u001b[0;36marray\u001b[1;34m(object, dtype, copy, order, ndmin, device)\u001b[0m\n\u001b[0;32m   5415\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m   5416\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m-> 5417\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43melt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5418\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5419\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:4475\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[0;32m   4473\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape(a) \u001b[38;5;241m!=\u001b[39m shape0:\n\u001b[0;32m   4474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll input arrays must have the same shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4475\u001b[0m   new_arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   4476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate(new_arrays, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:2521\u001b[0m, in \u001b[0;36mexpand_dims\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   2519\u001b[0m util\u001b[38;5;241m.\u001b[39mcheck_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[0;32m   2520\u001b[0m axis \u001b[38;5;241m=\u001b[39m _ensure_index_tuple(axis)\n\u001b[1;32m-> 2521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\lax\\lax.py:1792\u001b[0m, in \u001b[0;36mexpand_dims\u001b[1;34m(array, dimensions)\u001b[0m\n\u001b[0;32m   1790\u001b[0m   result_shape\u001b[38;5;241m.\u001b[39minsert(i, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1791\u001b[0m broadcast_dims \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim_out) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dims_set]\n\u001b[1;32m-> 1792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbroadcast_in_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbroadcast_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\lax\\lax.py:1185\u001b[0m, in \u001b[0;36mbroadcast_in_dim\u001b[1;34m(operand, shape, broadcast_dimensions)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1184\u001b[0m   dyn_shape, static_shape \u001b[38;5;241m=\u001b[39m [], shape  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 1185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbroadcast_in_dim_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstatic_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbroadcast_dimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbroadcast_dimensions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\core.py:438\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    436\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    437\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\core.py:442\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m    441\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[1;32m--> 442\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\core.py:955\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    953\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jax\\_src\\dispatch.py:91\u001b[0m, in \u001b[0;36mapply_primitive\u001b[1;34m(prim, *args, **params)\u001b[0m\n\u001b[0;32m     89\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iters = 1\n",
    "model = 'trainable_model_stage'\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "training_type = 'AP_0.05_0.05'\n",
    "current_time = '2024_11_20_01_06_49'\n",
    "\n",
    "for iteration in range(iters):  \n",
    "    #if training_type == 'Perfect_model':\n",
    "    #    trainable_model, original_model = perfect_model()\n",
    "    #elif training_type == 'Generated_model':\n",
    "    #    trainable_model, original_model = generate_model_random()\n",
    "    #else:\n",
    "    #    parts = training_type.split('_')\n",
    "    #    epsilon_non_zeros = float(parts[1])\n",
    "    #    epsilon_zeros = float(parts[2]) \n",
    "    #    trainable_model, original_model = generate_model_AP(epsilon_non_zeros = epsilon_non_zeros, epsilon_zeros = epsilon_zeros)\n",
    "\n",
    "    trainable_model = load_trainable_model(model, current_time, training_type, stage = 0)\n",
    "    \n",
    "    trainable_model_stage_1 = [trainable_model[0], trainable_model[1], trainable_model[2], trainable_model[3], trainable_model[4], trainable_model[5], trainable_model[6], trainable_model[7], trainable_model[8], trainable_model[9], trainable_model[10], trainable_model[11], trainable_model[12]]\n",
    "    #trainable_model_stage_2 = [trainable_model[13], trainable_model[14]]\n",
    "                                       \n",
    "    training_stages = 3\n",
    "    trainings_needed = np.zeros(training_stages)\n",
    "\n",
    "    #folder_path = f\"{folder}/Parameters/{training_type}\"\n",
    "    #os.makedirs(folder_path, exist_ok=True) \n",
    "    #\n",
    "    #current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    #file_path = os.path.join(folder_path, f\"{model}_{current_time}.pkl\")\n",
    "    #\n",
    "    #with open(file_path, 'wb') as file:\n",
    "    #    pickle.dump(original_model, file)\n",
    "    #\n",
    "    #print(f'Saved file: {model}_{current_time}.pkl')\n",
    "    \n",
    "    visualizer = 10\n",
    "    lr_changer = 250\n",
    "    stage_changer = 2500\n",
    "    N = 500\n",
    "\n",
    "    for stage in range(2,4):\n",
    "        if stage == 3:\n",
    "            trainable_model_stage_3 = [trainable_model_stage_1[0], \n",
    "                                       trainable_model_stage_1[1], \n",
    "                                       trainable_model_stage_1[2], \n",
    "                                       trainable_model_stage_1[3], \n",
    "                                       trainable_model_stage_1[4], \n",
    "                                       trainable_model_stage_1[5], \n",
    "                                       trainable_model_stage_1[6], \n",
    "                                       trainable_model_stage_1[7], \n",
    "                                       trainable_model_stage_1[8], \n",
    "                                       trainable_model_stage_1[9], \n",
    "                                       trainable_model_stage_1[10],\n",
    "                                       trainable_model_stage_1[11],\n",
    "                                       trainable_model_stage_1[12],\n",
    "                                       trainable_model_stage_2[0],\n",
    "                                       trainable_model_stage_2[1]]\n",
    "        \n",
    "        save_dir = f\"{folder}/Trained_models/Stages/{training_type}/Stage_{stage}\" \n",
    "        os.makedirs(save_dir, exist_ok=True) \n",
    "        results_file = os.path.join(save_dir, f\"Stage_{stage}_results_{current_time}.txt\") \n",
    "        tee = Tee(results_file, 'w') \n",
    "        sys.stdout = tee\n",
    "    \n",
    "        try:\n",
    "            test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "            final_loss = 1\n",
    "            lr = 0.001\n",
    "            level = -2\n",
    "            response = \"yes\"\n",
    "            while final_loss != 0:\n",
    "                prev_model = globals()[f\"{model}_{stage}\"]\n",
    "                globals()[f\"{model}_{stage}\"], final_loss = train_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage, level=level, lr=lr, epochs=N)\n",
    "                trainings_needed[stage-1] += 1\n",
    "                if math.isnan(final_loss):\n",
    "                    globals()[f\"{model}_{stage}\"] = prev_model\n",
    "                    print('Loss is NaN.')\n",
    "                    break                \n",
    "                if trainings_needed[stage-1] % visualizer == 0:\n",
    "                    if response.lower() == \"yes\":\n",
    "                        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "                        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "                        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "                    elif response.lower() == \"no\":\n",
    "                        print(f\"STAGE {stage}: Objective completed, all are predicted correctly in the current model.\")\n",
    "                    print(f\"STAGE {stage}: Loss is {final_loss}.\")\n",
    "                #if trainings_needed[stage-1] % lr_changer == 0:\n",
    "                #    new_lr = input(f\"Change of learning rate? (Current one is {lr}, press enter if not): \")\n",
    "                #    if new_lr != \"\":\n",
    "                #        lr = float(new_lr)\n",
    "                if trainings_needed[stage-1] % stage_changer == 0:\n",
    "                    response_pre = 'yes'\n",
    "                    if response_pre.lower() == \"yes\":\n",
    "                        break\n",
    "                if correct_predictions_trained_count == train_size:\n",
    "                    response = \"yes\"\n",
    "                    while response.lower() not in [\"yes\", \"no\"]:\n",
    "                        response = input(\"Objective completed, skip to next stage? (yes/no): \")\n",
    "                        if response.lower() not in [\"yes\", \"no\"]:\n",
    "                            print('Incorrect answer')        \n",
    "                    if response.lower() == \"yes\":\n",
    "                        print('Objective completed')\n",
    "                        break\n",
    "                    elif response.lower() == \"no\":\n",
    "                        train_size = correct_predictions_trained_count + 1\n",
    "    \n",
    "            print(f'Stage {stage} completed in {trainings_needed[stage-1]} trainings.')\n",
    "            save_response = 'yes'\n",
    "            if save_response.lower() == 'yes':\n",
    "                save_path = os.path.join(save_dir, f\"trainable_model_stage_{stage}-{current_time}.pkl\")\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    pickle.dump(globals()[f\"{model}_{stage}\"], f)\n",
    "                print(f\"Model trainable_model_stage_{stage} saved at {save_path}\")\n",
    "\n",
    "        finally:\n",
    "            sys.stdout = tee.console\n",
    "            tee.close()\n",
    "        print(f\"Results of Stage {stage} saved in {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fdd820-1d01-4e25-bc4b-c3e058675534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48c1b0-9772-4c7c-8fe2-6caa7bf80a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b9deb-a90a-4e2d-be42-8396f93ac9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b103bd4-73af-4234-a011-13297cf86c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE 2: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 2: Out of 8384, 8384 tested were predicted correctly in the current model.\n",
      "STAGE 2: Out of 14197, 14197 tested with carry-over were predicted correctly in the current model.\n"
     ]
    }
   ],
   "source": [
    "model = 'trainable_model_stage'\n",
    "visualize_errors = 0\n",
    "stage = 2\n",
    "real_test = 1\n",
    "\n",
    "decide_test(params=globals()[f\"{model}_{stage}\"], stage=stage, real_test=real_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740eb898-649f-4cff-b15a-5138580f97ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
