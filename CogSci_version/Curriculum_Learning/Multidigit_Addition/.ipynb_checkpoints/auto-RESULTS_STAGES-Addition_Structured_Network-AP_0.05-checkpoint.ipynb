{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e67e4db-f139-4bde-b30e-e68e37779b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad\n",
    "from jax.nn import relu, sigmoid\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pytz\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e32cf2-490d-4527-af07-dd4e51758135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random_weights(mean, std, shape = ()):\n",
    "    return np.random.normal(loc=mean, scale=std, size=shape)\n",
    "\n",
    "# We use a sinusoidal function to approximate odd numbers by their immediately preceding even number and preserve differentiability\n",
    "def lower_even(x):\n",
    "    return x - 0.5 * (1 - jnp.cos(jnp.pi * x))\n",
    "\n",
    "# We use a sinusoidal function to approximate 0 for evens and 1 for odds while preserving differentiability\n",
    "def differentiable_even_or_odd(x):\n",
    "    return ((2 * x ** 3) / 3) - 3 * x ** 2 + ((10 * x) / 3)\n",
    "\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "\n",
    "# Cargar las parejas desde el archivo\n",
    "with open(f\"{folder}/train_couples.txt\", \"r\") as file:\n",
    "    train_couples = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_with_carry_over.txt\", \"r\") as file:\n",
    "    combinations_with_carry_over = eval(file.read())  # Leer y convertir el contenido en una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset.txt\", 'r') as file:\n",
    "    real_test_dataset = eval(file.read())  # Convertir el contenido del archivo a una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_with_carry_over.txt\", 'r') as file:\n",
    "    real_test_carry_over_dataset = eval(file.read())\n",
    "    \n",
    "# Separar parejas con y sin ceros\n",
    "train_without_zeros = [pair for pair in train_couples if 0 not in pair]\n",
    "train_with_carry_over = [pair for pair in train_couples if pair in combinations_with_carry_over]\n",
    "\n",
    "# Function to generate dataset with multiplication\n",
    "def generate_dataset_with_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas con ceros\n",
    "    selected_pairs = random.choices(train_couples, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_without_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas sin ceros\n",
    "    selected_pairs = random.choices(train_without_zeros, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_test_dataset(n_max=100):\n",
    "    # Create the columns\n",
    "    column_1 = list(range(n_max)) * n_max  # Numbers from 0 to 9 repeated 10 times\n",
    "    column_2 = [i for i in range(n_max) for _ in range(n_max)]  # Numbers from 0 to 9 repeated sequentially 10 times\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_real_test_dataset():\n",
    "    # Desempaquetar las parejas (a_i, b_i)\n",
    "    column_1, column_2 = zip(*real_test_dataset)\n",
    "\n",
    "    # Crear un DataFrame con las dos primeras columnas\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna como la suma de las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def decimal_to_binary(n, bits):\n",
    "    if 0 <= n < 2**bits:\n",
    "        # Convert the number to a binary string and then to an array of integers (0 and 1)\n",
    "        return np.array(list(format(n, f'0{bits}b'))).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(\"Number out of range\")\n",
    "\n",
    "# Function to convert binary number to decimal\n",
    "def binary_to_decimal(binary_vector, bits):\n",
    "    # Ensure the vector has the correct number of elements\n",
    "    if len(binary_vector) != bits:\n",
    "        raise ValueError(f\"The vector must have exactly {bits} elements.\")\n",
    "\n",
    "    # Calculate the decimal number\n",
    "    decimal = 0\n",
    "    for i in range(bits):\n",
    "        decimal += binary_vector[i] * (2 ** (bits - 1 - i))\n",
    "\n",
    "    return decimal\n",
    "\n",
    "def transform_to_tridimensional_matrix(dataset, bits_init=7, bits_end=8):\n",
    "    rows, cols = dataset.shape\n",
    "    if cols != 3:\n",
    "        raise ValueError(\"The dataset must have exactly 3 columns.\")\n",
    "\n",
    "    # Initialize the three matrices\n",
    "    matrix_column_1 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_2 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_3 = np.zeros((rows, bits_end), dtype=np.int8)\n",
    "\n",
    "    # Fill the matrices with the binary representation of each column\n",
    "    for i in range(rows):\n",
    "        matrix_column_1[i] = decimal_to_binary(dataset.iloc[i, 0], bits_init)\n",
    "        matrix_column_2[i] = decimal_to_binary(dataset.iloc[i, 1], bits_init)\n",
    "        matrix_column_3[i] = decimal_to_binary(dataset.iloc[i, 2], bits_end)\n",
    "\n",
    "    return matrix_column_1, matrix_column_2, matrix_column_3\n",
    "    \n",
    "    \n",
    "def prepare_dataset(level, size=1, couples_included=[]):       \n",
    "    if level == -3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = couples_included\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == -2:\n",
    "        dataset = generate_dataset_with_zeros(size)\n",
    "        return dataset\n",
    "        \n",
    "    elif level == -1:\n",
    "        dataset = generate_dataset_without_zeros(size)\n",
    "        return dataset\n",
    "\n",
    "    elif level == 0:\n",
    "        dataset = pd.DataFrame()\n",
    "        while len(dataset) < size:\n",
    "            column_1 = np.random.randint(1, 10, size)\n",
    "            column_2 = np.random.randint(1, 10, size)\n",
    "            temp_dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "            temp_dataset = temp_dataset[~temp_dataset[['Column_1', 'Column_2']].apply(tuple, axis=1).isin(combinations_with_carry_over)]\n",
    "            dataset = pd.concat([dataset, temp_dataset])\n",
    "        dataset = dataset.iloc[:size].reset_index(drop=True)\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 1:\n",
    "        pairs = random.choices(train_with_carry_over, k=size)\n",
    "        column_1 = [pair[0] for pair in pairs]\n",
    "        column_2 = [pair[1] for pair in pairs]\n",
    "        dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "        dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "\n",
    "def prepare_outputs(stage, x1, x2, outputs_prev):\n",
    "    if stage == 1:\n",
    "        outputs = []\n",
    "        for vec1, vec2 in zip(x1, x2):\n",
    "            z2 = lower_even(vec1[6] + vec2[6])\n",
    "            z3 = lower_even(vec1[5] + vec2[5] + z2 * 1/2)\n",
    "            z4 = lower_even(vec1[4] + vec2[4] + z3 * 1/2)\n",
    "            z5 = lower_even(vec1[3] + vec2[3] + z4 * 1/2)\n",
    "            z6 = lower_even(vec1[2] + vec2[2] + z5 * 1/2)\n",
    "            z7 = lower_even(vec1[1] + vec2[1] + z6 * 1/2)\n",
    "            z8 = lower_even(vec1[0] + vec2[0] + z7 * 1/2)\n",
    "            outputs.append([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "        return np.array(outputs)\n",
    "\n",
    "    elif stage == 2:\n",
    "        return outputs_prev\n",
    "        \n",
    "    elif stage == 3:\n",
    "        return outputs_prev\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "\n",
    "# Perfect parameters needed for the stages where a part of the NN performs perfectly\n",
    "# R vectors of dimension (14,1)\n",
    "R2_perfect = np.zeros((14))\n",
    "R3_perfect = np.zeros((14))\n",
    "R4_perfect = np.zeros((14))\n",
    "R5_perfect = np.zeros((14))\n",
    "R6_perfect = np.zeros((14))\n",
    "R7_perfect = np.zeros((14))\n",
    "R8_perfect = np.zeros((14))\n",
    "\n",
    "for i in range(2):\n",
    "    R2_perfect[7*i + 6] = 1\n",
    "    R3_perfect[7*i + 5] = 1\n",
    "    R4_perfect[7*i + 4] = 1\n",
    "    R5_perfect[7*i + 3] = 1\n",
    "    R6_perfect[7*i + 2] = 1\n",
    "    R7_perfect[7*i + 1] = 1\n",
    "    R8_perfect[7*i + 0] = 1\n",
    "\n",
    "# Scalar parameters v\n",
    "v2_perfect = 1/2\n",
    "v3_perfect = 1/2\n",
    "v4_perfect = 1/2\n",
    "v5_perfect = 1/2\n",
    "v6_perfect = 1/2\n",
    "v7_perfect = 1/2\n",
    "\n",
    "# Matrix T of dimension (28,7)\n",
    "T_perfect = np.zeros((14,8))\n",
    "for i in range(7):\n",
    "    for j in range(2):\n",
    "        T_perfect[7*j + i, i + 1] = 1\n",
    "\n",
    "# Parameter v\n",
    "v_perfect = 1/2\n",
    "\n",
    "# Neural network in every stage\n",
    "def neural_network_1(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    #y = differentiable_even_or_odd(relu(jnp.dot(vec, T) + jnp.dot(z, v7)))\n",
    "    return z\n",
    "\n",
    "def neural_network_2(params, x1, x2):\n",
    "    T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2_perfect)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3_perfect) + jnp.dot(z2, v2_perfect)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4_perfect) + jnp.dot(z3, v3_perfect)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5_perfect) + jnp.dot(z4, v4_perfect)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6_perfect) + jnp.dot(z5, v5_perfect)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7_perfect) + jnp.dot(z6, v6_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8_perfect) + jnp.dot(z7, v7_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "    \n",
    "def neural_network_3(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "\n",
    "# Loss functions in every stage\n",
    "def loss_1(params, x1, x2, y):\n",
    "    pred = neural_network_1(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_2(params, x1, x2, y):\n",
    "    pred = neural_network_2(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_3(params, x1, x2, y):\n",
    "    pred = neural_network_3(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "# Loss functions in every step\n",
    "@jax.jit\n",
    "def update_params_1(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_1)(params, x1, x2, y)\n",
    "    step_loss = loss_1(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_2(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_2)(params, x1, x2, y)\n",
    "    step_loss = loss_2(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "    \n",
    "@jax.jit\n",
    "def update_params_3(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_3)(params, x1, x2, y)\n",
    "    step_loss = loss_3(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "def decide_training(params, x1, x2, y, lr, stage):\n",
    "    if stage == 1:\n",
    "        params, step_loss = update_params_1(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 2:\n",
    "        params, step_loss = update_params_2(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "        \n",
    "    elif stage == 3:\n",
    "        params, step_loss = update_params_3(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "        \n",
    "# Main function to train the network\n",
    "def train_stages_neural_network(params, stage, level, lr=0.01, epochs=100):\n",
    "    decimal_dataset = prepare_dataset(level, epochs)\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    final_loss = 0\n",
    "    # Train the network\n",
    "    for epoch in range(epochs):\n",
    "        # Update parameters at each step\n",
    "        params, step_loss = decide_training(params, inputs_1[epoch], inputs_2[epoch], outputs[epoch], lr, stage)\n",
    "        final_loss += step_loss\n",
    "\n",
    "    final_loss = final_loss / epochs\n",
    "    #print(f\"Loss: {final_loss:.6f}\")\n",
    "    return params, final_loss\n",
    "\n",
    "\n",
    "\n",
    "def decide_test(params, stage, real_test=0, visualize_errors=0):\n",
    "    if real_test == 1:\n",
    "        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count, carry_over_size, correct_carry_over_predictions_tested_count = real_test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {carry_over_size}, {correct_carry_over_predictions_tested_count} tested with carry-over were predicted correctly in the current model.\")      \n",
    "\n",
    "    else: \n",
    "        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "        \n",
    "\n",
    "# Main function to test the network\n",
    "def test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_test_dataset()\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "\n",
    "    correct_predictions_count = 0\n",
    "    correct_predictions_tested_count = 0\n",
    "    correct_predictions_trained_count = 0  # Counter for trained couples\n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_size = len(train_couples)\n",
    "    test_size = set_size - train_size\n",
    "    \n",
    "    for i in range(set_size):\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        # Check if the prediction matches the expected output\n",
    "        if jnp.all(prediction == outputs[i]):  \n",
    "            if (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1]) in train_couples:\n",
    "                correct_predictions_trained_count += 1  # Increment for trained couples\n",
    "            else:\n",
    "                correct_predictions_tested_count += 1 # Increment for tested couples\n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{decimal_dataset.iloc[i, 0]} plus {decimal_dataset.iloc[i, 1]} has failed.')\n",
    "\n",
    "    return test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count\n",
    "\n",
    "# Predict using the trained neural network\n",
    "def predict(params, x1, x2, stage):\n",
    "    if stage == 1:\n",
    "        binary_pred = neural_network_1(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 2:\n",
    "        binary_pred = neural_network_2(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 3:\n",
    "        binary_pred = neural_network_3(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79e9a11-6884-4c9b-94a0-e5c5243612d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_model():\n",
    "    # R vectors of dimension (14,1)\n",
    "    R2_perfect = np.zeros((14))\n",
    "    R3_perfect = np.zeros((14))\n",
    "    R4_perfect = np.zeros((14))\n",
    "    R5_perfect = np.zeros((14))\n",
    "    R6_perfect = np.zeros((14))\n",
    "    R7_perfect = np.zeros((14))\n",
    "    R8_perfect = np.zeros((14))\n",
    "    \n",
    "    for i in range(2):\n",
    "        R2_perfect[7*i + 6] = 1\n",
    "        R3_perfect[7*i + 5] = 1\n",
    "        R4_perfect[7*i + 4] = 1\n",
    "        R5_perfect[7*i + 3] = 1\n",
    "        R6_perfect[7*i + 2] = 1\n",
    "        R7_perfect[7*i + 1] = 1\n",
    "        R8_perfect[7*i + 0] = 1\n",
    "    \n",
    "    # Scalar parameters v\n",
    "    v2_perfect = 1/2\n",
    "    v3_perfect = 1/2\n",
    "    v4_perfect = 1/2\n",
    "    v5_perfect = 1/2\n",
    "    v6_perfect = 1/2\n",
    "    v7_perfect = 1/2\n",
    "    \n",
    "    # Matrix T of dimension (28,7)\n",
    "    T_perfect = np.zeros((14,8))\n",
    "    for i in range(7):\n",
    "        for j in range(2):\n",
    "            T_perfect[7*j + i, i + 1] = 1\n",
    "    \n",
    "    # Parameter v\n",
    "    v_perfect = 1/2\n",
    "    \n",
    "    original_model = [R2_perfect, R3_perfect, R4_perfect, R5_perfect, R6_perfect, R7_perfect, R8_perfect,\n",
    "            v2_perfect, v3_perfect, v4_perfect, v5_perfect, v6_perfect, v7_perfect, \n",
    "            T_perfect, v_perfect] \n",
    "    trainable_model = [R2_perfect, R3_perfect, R4_perfect, R5_perfect, R6_perfect, R7_perfect, R8_perfect,\n",
    "            v2_perfect, v3_perfect, v4_perfect, v5_perfect, v6_perfect, v7_perfect, \n",
    "            T_perfect, v_perfect] \n",
    "    return trainable_model, original_model\n",
    "\n",
    "def generate_model_random(mean=0.5, std=1):\n",
    "    R2 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the second bit\n",
    "    R3 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R4 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R5 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R6 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R7 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    R8 = initialize_random_weights(mean, std, (14))  # 28 neurons that correctly calculate the carry for the third bit\n",
    "    v2 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v3 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v4 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v5 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v6 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    v7 = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry for the third bit\n",
    "    T = initialize_random_weights(mean, std, (14, 8))  # 196 neurons that allow performing the sum\n",
    "    v = initialize_random_weights(mean, std)  # 1 neuron that calculates the contribution of the carry vector for all bits\n",
    "    original_model = [R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v]\n",
    "    trainable_model = [R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v]\n",
    "    return trainable_model, original_model\n",
    "    \n",
    "def generate_model_AP(epsilon_non_zeros = 0.01, epsilon_zeros = 0.01):   \n",
    "    R2_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R3_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R4_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R5_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R6_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R7_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    R8_almost_perfect = np.zeros((14)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    for i in range(2):\n",
    "        R2_almost_perfect[7*i + 6] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R3_almost_perfect[7*i + 5] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R4_almost_perfect[7*i + 4] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R5_almost_perfect[7*i + 3] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R6_almost_perfect[7*i + 2] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R7_almost_perfect[7*i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "        R8_almost_perfect[7*i + 0] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v2_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v3_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v4_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v5_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v6_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    v7_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "\n",
    "    T_almost_perfect = np.zeros((14,8)) + epsilon_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    for i in range(7):\n",
    "        for j in range(2):\n",
    "            T_almost_perfect[7*j + i, i + 1] = 1 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    v_almost_perfect = 1/2 + epsilon_non_zeros * np.random.randint(-10, 10)\n",
    "    \n",
    "    original_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    trainable_model = [R2_almost_perfect, R3_almost_perfect, R4_almost_perfect, R5_almost_perfect, R6_almost_perfect, R7_almost_perfect, R8_almost_perfect,\n",
    "                      v2_almost_perfect, v3_almost_perfect, v4_almost_perfect, v5_almost_perfect, v6_almost_perfect, v7_almost_perfect,\n",
    "                      T_almost_perfect, v_almost_perfect]\n",
    "    return trainable_model, original_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb1a38e-9ed3-4e9d-8e2a-d7981631eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "        \n",
    "def load_trainable_model(model, current_time, training_type, stage = 0):\n",
    "    folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "    if stage == 0:\n",
    "        model_path = f'{folder}/Parameters/{training_type}/{model}_{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'trainable_model'] = pickle.load(f)\n",
    "        print(f'Model trainable_model_{current_time} loaded successfully.')\n",
    "        return globals()[f'trainable_model']\n",
    "        \n",
    "    else:\n",
    "        model_path = f'{folder}/Trained_models/Stages/{training_type}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'{model}_{stage}'] = pickle.load(f)\n",
    "        print(f'Model {model}_{stage}_{current_time} loaded successfully.')\n",
    "        return globals()[f'{model}_{stage}']\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "030cfa0a-71d1-4080-9fa6-f71d820a5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: trainable_model_stage_2024_11_20_11_30_19.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_21.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_23.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_25.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_27.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_29.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_31.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_33.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_35.pkl\n",
      "Saved file: trainable_model_stage_2024_11_20_11_30_37.pkl\n"
     ]
    }
   ],
   "source": [
    "model = 'trainable_model_stage'\n",
    "training_type = 'AP_0.05_0.05'\n",
    "\n",
    "folder = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "folder_path = f'{folder}/Parameters/{training_type}'\n",
    "date_pattern = r'trainable_model_stage_(\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}).pkl'\n",
    "files = sorted(\n",
    "    (f for f in os.listdir(folder_path) if not f.startswith('.')),  # Filtrar archivos ocultos\n",
    "    key=lambda x: re.search(date_pattern, x).group(1) if re.search(date_pattern, x) else ''\n",
    ")\n",
    "\n",
    "for filename in files:\n",
    "    match = re.search(date_pattern, filename)\n",
    "    if match:\n",
    "        current_time = match.group(1)\n",
    "    else:\n",
    "        print('Error')\n",
    "        break\n",
    "    \n",
    "    file_path = f\"{folder_path}/{model}_{current_time}.pkl\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        trainable_model = pickle.load(file)\n",
    "\n",
    "    print(f'Loaded {model}_{current_time}.pkl')\n",
    "    \n",
    "    training_stages = 3\n",
    "    trainings_needed = np.zeros(training_stages)    \n",
    "    visualizer = 10\n",
    "    lr_changer = 250\n",
    "    stage_changer = 2500\n",
    "    N = 500\n",
    "\n",
    "    for stage in range(1,4):\n",
    "        if stage == 1:\n",
    "            trainable_model_stage_1 = [trainable_model[0],\n",
    "                                       trainable_model[1],\n",
    "                                       trainable_model[2],\n",
    "                                       trainable_model[3],\n",
    "                                       trainable_model[4],\n",
    "                                       trainable_model[5],\n",
    "                                       trainable_model[6],\n",
    "                                       trainable_model[7],\n",
    "                                       trainable_model[8],\n",
    "                                       trainable_model[9],\n",
    "                                       trainable_model[10],\n",
    "                                       trainable_model[11],\n",
    "                                       trainable_model[12]]\n",
    "        elif stage == 2:\n",
    "            trainable_model_stage_2 = [trainable_model[13], \n",
    "                                       trainable_model[14]]\n",
    "        elif stage == 3:\n",
    "            trainable_model_stage_3 = [trainable_model_stage_1[0], \n",
    "                                       trainable_model_stage_1[1], \n",
    "                                       trainable_model_stage_1[2], \n",
    "                                       trainable_model_stage_1[3], \n",
    "                                       trainable_model_stage_1[4], \n",
    "                                       trainable_model_stage_1[5], \n",
    "                                       trainable_model_stage_1[6], \n",
    "                                       trainable_model_stage_1[7], \n",
    "                                       trainable_model_stage_1[8], \n",
    "                                       trainable_model_stage_1[9], \n",
    "                                       trainable_model_stage_1[10],\n",
    "                                       trainable_model_stage_1[11],\n",
    "                                       trainable_model_stage_1[12],\n",
    "                                       trainable_model_stage_2[0],\n",
    "                                       trainable_model_stage_2[1]]\n",
    "        \n",
    "        save_dir = f\"{folder}/Trained_models/Stages/{training_type}/Stage_{stage}\" \n",
    "        os.makedirs(save_dir, exist_ok=True) \n",
    "        results_file = os.path.join(save_dir, f\"Stage_{stage}_results_{current_time}.txt\") \n",
    "        tee = Tee(results_file, 'w') \n",
    "        sys.stdout = tee\n",
    "    \n",
    "        try:\n",
    "            test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "            final_loss = 1\n",
    "            lr = 0.001\n",
    "            level = -2\n",
    "            response = \"yes\"\n",
    "            while final_loss != 0:\n",
    "                prev_model = globals()[f\"{model}_{stage}\"]\n",
    "                globals()[f\"{model}_{stage}\"], final_loss = train_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage, level=level, lr=lr, epochs=N)\n",
    "                trainings_needed[stage-1] += 1\n",
    "                if math.isnan(final_loss):\n",
    "                    globals()[f\"{model}_{stage}\"] = prev_model\n",
    "                    print('Loss is NaN.')\n",
    "                    break                \n",
    "                if trainings_needed[stage-1] % visualizer == 0:\n",
    "                    if response.lower() == \"yes\":\n",
    "                        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params=globals()[f\"{model}_{stage}\"], stage=stage)\n",
    "                        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "                        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "                    elif response.lower() == \"no\":\n",
    "                        print(f\"STAGE {stage}: Objective completed, all are predicted correctly in the current model.\")\n",
    "                    print(f\"STAGE {stage}: Loss is {final_loss}.\")\n",
    "                #if trainings_needed[stage-1] % lr_changer == 0:\n",
    "                #    new_lr = input(f\"Change of learning rate? (Current one is {lr}, press enter if not): \")\n",
    "                #    if new_lr != \"\":\n",
    "                #        lr = float(new_lr)\n",
    "                if trainings_needed[stage-1] % stage_changer == 0:\n",
    "                    response_pre = 'yes'\n",
    "                    if response_pre.lower() == \"yes\":\n",
    "                        break\n",
    "                if correct_predictions_trained_count == train_size:\n",
    "                    response = \"yes\"\n",
    "                    while response.lower() not in [\"yes\", \"no\"]:\n",
    "                        response = input(\"Objective completed, skip to next stage? (yes/no): \")\n",
    "                        if response.lower() not in [\"yes\", \"no\"]:\n",
    "                            print('Incorrect answer')        \n",
    "                    if response.lower() == \"yes\":\n",
    "                        print('Objective completed')\n",
    "                        break\n",
    "                    elif response.lower() == \"no\":\n",
    "                        train_size = correct_predictions_trained_count + 1\n",
    "    \n",
    "            print(f'Stage {stage} completed in {trainings_needed[stage-1]} trainings.')\n",
    "            save_response = 'yes'\n",
    "            if save_response.lower() == 'yes':\n",
    "                save_path = os.path.join(save_dir, f\"trainable_model_stage_{stage}-{current_time}.pkl\")\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    pickle.dump(globals()[f\"{model}_{stage}\"], f)\n",
    "                print(f\"Model trainable_model_stage_{stage} saved at {save_path}\")\n",
    "\n",
    "        finally:\n",
    "            sys.stdout = tee.console\n",
    "            tee.close()\n",
    "        print(f\"Results of Stage {stage} saved in {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
