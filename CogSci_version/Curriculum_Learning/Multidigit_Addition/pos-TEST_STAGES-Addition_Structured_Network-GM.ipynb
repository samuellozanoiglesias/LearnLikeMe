{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711e908c-a200-4499-a72c-e7d32a573bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad\n",
    "from jax.nn import relu, sigmoid\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pytz\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb56570c-4104-46b7-8925-2cbdbfdebb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_random_weights(mean, std, shape = ()):\n",
    "    return np.random.normal(loc=mean, scale=std, size=shape)\n",
    "\n",
    "# We use a sinusoidal function to approximate odd numbers by their immediately preceding even number and preserve differentiability\n",
    "def lower_even(x):\n",
    "    return x - 0.5 * (1 - jnp.cos(jnp.pi * x))\n",
    "\n",
    "# We use a sinusoidal function to approximate 0 for evens and 1 for odds while preserving differentiability\n",
    "def differentiable_even_or_odd(x):\n",
    "    return ((2 * x ** 3) / 3) - 3 * x ** 2 + ((10 * x) / 3)\n",
    "\n",
    "folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "\n",
    "# Cargar las parejas desde el archivo\n",
    "with open(f\"{folder}/train_couples.txt\", \"r\") as file:\n",
    "    train_couples = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_with_carry_over.txt\", \"r\") as file:\n",
    "    combinations_with_carry_over = eval(file.read())  # Leer y convertir el contenido en una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset.txt\", 'r') as file:\n",
    "    real_test_dataset = eval(file.read())  # Convertir el contenido del archivo a una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/test_dataset.txt\", 'r') as file:\n",
    "    test_dataset = eval(file.read())  # Convertir el contenido del archivo a una lista de tuplas\n",
    "\n",
    "with open(f\"{folder}/combinations_small_problem_size.txt\", 'r') as file:\n",
    "    combinations_small_problem_size = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_small_problem_size_binary.txt\", 'r') as file:\n",
    "    combinations_small_problem_size_binary = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/combinations_with_carry_over_decimal.txt\", 'r') as file:\n",
    "    combinations_with_carry_over_decimal = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_small_problem_size.txt\", 'r') as file:\n",
    "    real_test_dataset_small_problem_size = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_small_problem_size_binary.txt\", 'r') as file:\n",
    "    real_test_dataset_small_problem_size_binary = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_with_carry_over.txt\", 'r') as file:\n",
    "    real_test_dataset_with_carry_over = eval(file.read())\n",
    "\n",
    "with open(f\"{folder}/real_test_dataset_with_carry_over_decimal.txt\", 'r') as file:\n",
    "    real_test_dataset_with_carry_over_decimal = eval(file.read())\n",
    "    \n",
    "\n",
    "# Separar parejas con y sin ceros\n",
    "train_without_zeros = [pair for pair in train_couples if 0 not in pair]\n",
    "train_with_carry_over = [pair for pair in train_couples if pair in combinations_with_carry_over]\n",
    "train_with_carry_over_decimal = [pair for pair in train_couples if pair in combinations_with_carry_over_decimal]\n",
    "\n",
    "# Function to generate dataset with multiplication\n",
    "def generate_dataset_with_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas con ceros\n",
    "    selected_pairs = random.choices(train_couples, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "    return dataset\n",
    "\n",
    "def generate_dataset_without_zeros(size):\n",
    "    # Seleccionar aleatoriamente parejas sin ceros\n",
    "    selected_pairs = random.choices(train_without_zeros, k=size)\n",
    "    \n",
    "    # Separar las columnas de las parejas seleccionadas\n",
    "    column_1 = [pair[0] for pair in selected_pairs]\n",
    "    column_2 = [pair[1] for pair in selected_pairs]\n",
    "\n",
    "    # Crear el DataFrame\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna sumando las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_test_dataset(n_max=100):\n",
    "    # Create the columns\n",
    "    column_1 = list(range(n_max)) * n_max  # Numbers from 0 to 9 repeated 10 times\n",
    "    column_2 = [i for i in range(n_max) for _ in range(n_max)]  # Numbers from 0 to 9 repeated sequentially 10 times\n",
    "\n",
    "    # Create a DataFrame with the two columns\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Create the third column by multiplying the first two\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def generate_real_test_dataset():\n",
    "    # Desempaquetar las parejas (a_i, b_i)\n",
    "    column_1, column_2 = zip(*real_test_dataset)\n",
    "    #column_1, column_2 = zip(*test_dataset)\n",
    "    \n",
    "    # Crear un DataFrame con las dos primeras columnas\n",
    "    dataset = pd.DataFrame({\n",
    "        'Column_1': column_1,\n",
    "        'Column_2': column_2,\n",
    "    })\n",
    "\n",
    "    # Crear la tercera columna como la suma de las dos primeras\n",
    "    dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def decimal_to_binary(n, bits):\n",
    "    if 0 <= n < 2**bits:\n",
    "        # Convert the number to a binary string and then to an array of integers (0 and 1)\n",
    "        return np.array(list(format(n, f'0{bits}b'))).astype(np.int8)\n",
    "    else:\n",
    "        raise ValueError(\"Number out of range\")\n",
    "\n",
    "# Function to convert binary number to decimal\n",
    "def binary_to_decimal(binary_vector, bits):\n",
    "    # Ensure the vector has the correct number of elements\n",
    "    if len(binary_vector) != bits:\n",
    "        raise ValueError(f\"The vector must have exactly {bits} elements.\")\n",
    "\n",
    "    # Calculate the decimal number\n",
    "    decimal = 0\n",
    "    for i in range(bits):\n",
    "        decimal += binary_vector[i] * (2 ** (bits - 1 - i))\n",
    "\n",
    "    return decimal\n",
    "\n",
    "def transform_to_tridimensional_matrix(dataset, bits_init=7, bits_end=8):\n",
    "    rows, cols = dataset.shape\n",
    "    if cols != 3:\n",
    "        raise ValueError(\"The dataset must have exactly 3 columns.\")\n",
    "\n",
    "    # Initialize the three matrices\n",
    "    matrix_column_1 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_2 = np.zeros((rows, bits_init), dtype=np.int8)\n",
    "    matrix_column_3 = np.zeros((rows, bits_end), dtype=np.int8)\n",
    "\n",
    "    # Fill the matrices with the binary representation of each column\n",
    "    for i in range(rows):\n",
    "        matrix_column_1[i] = decimal_to_binary(dataset.iloc[i, 0], bits_init)\n",
    "        matrix_column_2[i] = decimal_to_binary(dataset.iloc[i, 1], bits_init)\n",
    "        matrix_column_3[i] = decimal_to_binary(dataset.iloc[i, 2], bits_end)\n",
    "\n",
    "    return matrix_column_1, matrix_column_2, matrix_column_3\n",
    "    \n",
    "def prepare_dataset(level, size=1, couples_included=[]):       \n",
    "    if level == -3:\n",
    "        column_1 = []\n",
    "        column_2 = []\n",
    "        pairs = couples_included\n",
    "        while len(column_1) < size:\n",
    "            choice = pairs[np.random.choice(len(pairs))]\n",
    "            column_1.append(choice[0])\n",
    "            column_2.append(choice[1])\n",
    "        dataset = pd.DataFrame({'Column_1': column_1,'Column_2': column_2,})\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == -2:\n",
    "        dataset = generate_dataset_with_zeros(size)\n",
    "        return dataset\n",
    "        \n",
    "    elif level == -1:\n",
    "        dataset = generate_dataset_without_zeros(size)\n",
    "        return dataset\n",
    "\n",
    "    elif level == 0:\n",
    "        dataset = pd.DataFrame()\n",
    "        while len(dataset) < size:\n",
    "            column_1 = np.random.randint(1, 10, size)\n",
    "            column_2 = np.random.randint(1, 10, size)\n",
    "            temp_dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "            temp_dataset = temp_dataset[~temp_dataset[['Column_1', 'Column_2']].apply(tuple, axis=1).isin(combinations_with_carry_over)]\n",
    "            dataset = pd.concat([dataset, temp_dataset])\n",
    "        dataset = dataset.iloc[:size].reset_index(drop=True)\n",
    "        dataset['Column_3'] = dataset['Column_1'] * dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    elif level == 1:\n",
    "        pairs = random.choices(train_with_carry_over, k=size)\n",
    "        column_1 = [pair[0] for pair in pairs]\n",
    "        column_2 = [pair[1] for pair in pairs]\n",
    "        dataset = pd.DataFrame({'Column_1': column_1, 'Column_2': column_2})\n",
    "        dataset['Column_3'] = dataset['Column_1'] + dataset['Column_2']\n",
    "        return dataset\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "def prepare_outputs(stage, x1, x2, outputs_prev):\n",
    "    if stage == 1:\n",
    "        outputs = []\n",
    "        for vec1, vec2 in zip(x1, x2):\n",
    "            z2 = lower_even(vec1[6] + vec2[6])\n",
    "            z3 = lower_even(vec1[5] + vec2[5] + z2 * 1/2)\n",
    "            z4 = lower_even(vec1[4] + vec2[4] + z3 * 1/2)\n",
    "            z5 = lower_even(vec1[3] + vec2[3] + z4 * 1/2)\n",
    "            z6 = lower_even(vec1[2] + vec2[2] + z5 * 1/2)\n",
    "            z7 = lower_even(vec1[1] + vec2[1] + z6 * 1/2)\n",
    "            z8 = lower_even(vec1[0] + vec2[0] + z7 * 1/2)\n",
    "            outputs.append([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "        return np.array(outputs)\n",
    "\n",
    "    elif stage == 2:\n",
    "        return outputs_prev\n",
    "        \n",
    "    elif stage == 3:\n",
    "        return outputs_prev\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "\n",
    "# Perfect parameters needed for the stages where a part of the NN performs perfectly\n",
    "# R vectors of dimension (14,1)\n",
    "R2_perfect = np.zeros((14))\n",
    "R3_perfect = np.zeros((14))\n",
    "R4_perfect = np.zeros((14))\n",
    "R5_perfect = np.zeros((14))\n",
    "R6_perfect = np.zeros((14))\n",
    "R7_perfect = np.zeros((14))\n",
    "R8_perfect = np.zeros((14))\n",
    "\n",
    "for i in range(2):\n",
    "    R2_perfect[7*i + 6] = 1\n",
    "    R3_perfect[7*i + 5] = 1\n",
    "    R4_perfect[7*i + 4] = 1\n",
    "    R5_perfect[7*i + 3] = 1\n",
    "    R6_perfect[7*i + 2] = 1\n",
    "    R7_perfect[7*i + 1] = 1\n",
    "    R8_perfect[7*i + 0] = 1\n",
    "\n",
    "# Scalar parameters v\n",
    "v2_perfect = 1/2\n",
    "v3_perfect = 1/2\n",
    "v4_perfect = 1/2\n",
    "v5_perfect = 1/2\n",
    "v6_perfect = 1/2\n",
    "v7_perfect = 1/2\n",
    "\n",
    "# Matrix T of dimension (28,7)\n",
    "T_perfect = np.zeros((14,8))\n",
    "for i in range(7):\n",
    "    for j in range(2):\n",
    "        T_perfect[7*j + i, i + 1] = 1\n",
    "\n",
    "# Parameter v\n",
    "v_perfect = 1/2\n",
    "\n",
    "# Neural network in every stage\n",
    "def neural_network_1(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7 = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    #y = differentiable_even_or_odd(relu(jnp.dot(vec, T) + jnp.dot(z, v7)))\n",
    "    return z\n",
    "\n",
    "def neural_network_2(params, x1, x2):\n",
    "    T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2_perfect)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3_perfect) + jnp.dot(z2, v2_perfect)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4_perfect) + jnp.dot(z3, v3_perfect)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5_perfect) + jnp.dot(z4, v4_perfect)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6_perfect) + jnp.dot(z5, v5_perfect)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7_perfect) + jnp.dot(z6, v6_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8_perfect) + jnp.dot(z7, v7_perfect)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "    \n",
    "def neural_network_3(params, x1, x2):\n",
    "    R2, R3, R4, R5, R6, R7, R8, v2, v3, v4, v5, v6, v7, T, v = params\n",
    "    x = jnp.concatenate((x1, x2), axis=0)\n",
    "    z2 = lower_even(jnp.dot(x, R2)) # z2 is a scalar with the first carry over\n",
    "    z3 = lower_even(jnp.dot(x, R3) + jnp.dot(z2, v2)) # z3 is a scalar with the second carry over\n",
    "    z4 = lower_even(jnp.dot(x, R4) + jnp.dot(z3, v3)) # z4 is a scalar with the third carry over\n",
    "    z5 = lower_even(jnp.dot(x, R5) + jnp.dot(z4, v4)) # z5 is a scalar with the fourth carry over\n",
    "    z6 = lower_even(jnp.dot(x, R6) + jnp.dot(z5, v5)) # z6 is a scalar with the fifth carry over\n",
    "    z7 = lower_even(jnp.dot(x, R7) + jnp.dot(z6, v6)) # z7 is a scalar with the seventh carry over\n",
    "    z8 = lower_even(jnp.dot(x, R8) + jnp.dot(z7, v7)) # z7 is a scalar with the seventh carry over\n",
    "    z = jnp.array([z8, z7, z6, z5, z4, z3, z2, 0])\n",
    "    y = differentiable_even_or_odd(jnp.dot(x, T) + jnp.dot(z, v))\n",
    "    return y\n",
    "\n",
    "# Loss functions in every stage\n",
    "def loss_1(params, x1, x2, y):\n",
    "    pred = neural_network_1(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_2(params, x1, x2, y):\n",
    "    pred = neural_network_2(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "def loss_3(params, x1, x2, y):\n",
    "    pred = neural_network_3(params, x1, x2)\n",
    "    return jnp.mean((pred - y)**2)\n",
    "\n",
    "# Loss functions in every step\n",
    "@jax.jit\n",
    "def update_params_1(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_1)(params, x1, x2, y)\n",
    "    step_loss = loss_1(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "@jax.jit\n",
    "def update_params_2(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_2)(params, x1, x2, y)\n",
    "    step_loss = loss_2(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "    \n",
    "@jax.jit\n",
    "def update_params_3(params, x1, x2, y, lr):\n",
    "    gradients = grad(loss_3)(params, x1, x2, y)\n",
    "    step_loss = loss_3(params, x1, x2, y)\n",
    "    return [(p - lr * g) for p, g in zip(params, gradients)], step_loss\n",
    "\n",
    "def decide_training(params, x1, x2, y, lr, stage):\n",
    "    if stage == 1:\n",
    "        params, step_loss = update_params_1(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    elif stage == 2:\n",
    "        params, step_loss = update_params_2(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "        \n",
    "    elif stage == 3:\n",
    "        params, step_loss = update_params_3(params, x1, x2, y, lr)\n",
    "        return params, step_loss\n",
    "\n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None\n",
    "        \n",
    "# Main function to train the network\n",
    "def train_stages_neural_network(params, stage, level, lr=0.01, epochs=100):\n",
    "    decimal_dataset = prepare_dataset(level, epochs)\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    final_loss = 0\n",
    "    # Train the network\n",
    "    for epoch in range(epochs):\n",
    "        # Update parameters at each step\n",
    "        params, step_loss = decide_training(params, inputs_1[epoch], inputs_2[epoch], outputs[epoch], lr, stage)\n",
    "        final_loss += step_loss\n",
    "\n",
    "    final_loss = final_loss / epochs\n",
    "    #print(f\"Loss: {final_loss:.6f}\")\n",
    "    return params, final_loss\n",
    "\n",
    "\n",
    "\n",
    "def decide_test(params, stage, real_test=0, visualize_errors=0):\n",
    "    if real_test == 1:\n",
    "        test_count, correct_predictions_test_count, train_count, correct_predictions_train_count, test_carry_over_count, correct_carry_over_predictions_test_count, train_carry_over_count, correct_carry_over_predictions_train_count, small_train_count, correct_predictions_small_train_count, small_test_count, correct_predictions_small_test_count, small_train_carry_count, correct_predictions_small_train_carry_count, small_test_carry_count, correct_predictions_small_test_carry_count, test_carry_over_decimal_count, correct_carry_over_decimal_predictions_test_count, train_carry_over_decimal_count, correct_carry_over_decimal_predictions_train_count, small_train_carry_decimal_count, correct_predictions_small_train_carry_decimal_count, small_test_carry_decimal_count, correct_predictions_small_test_carry_decimal_count, small_binary_train_count, correct_predictions_small_binary_train_count, small_binary_test_count, correct_predictions_small_binary_test_count, small_binary_train_carry_count, correct_predictions_small_binary_train_carry_count, small_binary_test_carry_count, correct_predictions_small_binary_test_carry_count, small_binary_train_carry_decimal_count, correct_predictions_small_binary_train_carry_decimal_count, small_binary_test_carry_decimal_count, correct_predictions_small_binary_test_carry_decimal_count, reaction_time_carry, reaction_time_carry_decimal, reaction_time_train,reaction_time_test, reaction_time_train_carry, reaction_time_train_carry_decimal, reaction_time_small_train, reaction_time_small_test, reaction_time_small_train_carry, reaction_time_small_test_carry, reaction_time_small_train_carry_decimal, reaction_time_small_test_carry_decimal, reaction_time_small_binary_train, reaction_time_small_binary_test, reaction_time_small_binary_train_carry, reaction_time_small_binary_test_carry, reaction_time_small_binary_train_carry_decimal, reaction_time_small_binary_test_carry_decimal = real_test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_count}, {correct_predictions_train_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_count}, {correct_predictions_test_count} tested were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {train_carry_over_count}, {correct_carry_over_predictions_train_count} trained with carry-over were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {test_carry_over_count}, {correct_carry_over_predictions_test_count} tested with carry-over were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_train_count}, {correct_predictions_small_train_count} trained with small problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_test_count}, {correct_predictions_small_test_count} tested with small problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_train_carry_count}, {correct_predictions_small_train_carry_count} trained with small problem size and with carry-over were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_test_carry_count}, {correct_predictions_small_test_carry_count} tested with small problem size and with carry-over were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {train_carry_over_decimal_count}, {correct_carry_over_decimal_predictions_train_count} trained with carry-over decimal were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {test_carry_over_decimal_count}, {correct_carry_over_decimal_predictions_test_count} tested with carry-over decimal were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_train_carry_decimal_count}, {correct_predictions_small_train_carry_decimal_count} trained with small problem size and with carry-over decimal were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_test_carry_decimal_count}, {correct_predictions_small_test_carry_decimal_count} tested with small problem size and with carry-over decimal were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_train_count}, {correct_predictions_small_binary_train_count} trained with small binary problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_test_count}, {correct_predictions_small_binary_test_count} tested with small binary problem size were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_train_carry_count}, {correct_predictions_small_binary_train_carry_count} trained with small binary problem size and with carry-over were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_binary_test_carry_count}, {correct_predictions_small_binary_test_carry_count} tested with small binary problem size and with carry-over were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {small_binary_train_carry_decimal_count}, {correct_predictions_small_binary_train_carry_decimal_count} trained with small binary problem size and with carry-over decimal were predicted correctly in the current model.\")      \n",
    "        print(f\"STAGE {stage}: Out of {small_binary_test_carry_decimal_count}, {correct_predictions_small_binary_test_carry_decimal_count} tested with small binary problem size and with carry-over decimal were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_carry} reaction time with carry over.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_carry_decimal} reaction time with carry over decimal.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_train} reaction time for train.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_test} reaction time for test.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_train_carry} reaction time for train with carry over .\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_train_carry_decimal} reaction time for train with carry over decimal.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_train} reaction time for train small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_test} reaction time for test small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_train_carry} reaction time for train with carry over and small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_test_carry} reaction time for test with carry over and small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_train_carry_decimal} reaction time for train with carry over decimal and small.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_test_carry_decimal} reaction time for test with carry over decimal and small.\") \n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_train} reaction time for train small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_test} reaction time for test small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_train_carry} reaction time for train with carry over and small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_test_carry} reaction time for test with carry over and small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_train_carry_decimal} reaction time for train with carry over decimal and small binary.\")\n",
    "        print(f\"STAGE {stage}: {reaction_time_small_binary_test_carry_decimal} reaction time for test with carry over decimal and small binary.\") \n",
    "            \n",
    "    else: \n",
    "        test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count = test_stages_neural_network(params, stage, visualize_errors=0)\n",
    "        print(f\"STAGE {stage}: Out of {train_size}, {correct_predictions_trained_count} trained were predicted correctly in the current model.\")\n",
    "        print(f\"STAGE {stage}: Out of {test_size}, {correct_predictions_tested_count} tested were predicted correctly in the current model.\")\n",
    "        \n",
    "\n",
    "# Main function to test the network\n",
    "def test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_test_dataset()\n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    \n",
    "    correct_predictions_tested_count = 0\n",
    "    correct_predictions_trained_count = 0  # Counter for trained couples\n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_size = len(train_couples)\n",
    "    test_size = set_size - train_size\n",
    "    \n",
    "    for i in range(set_size):\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        # Check if the prediction matches the expected output\n",
    "        if jnp.all(prediction == outputs[i]):  \n",
    "            if (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1]) in train_couples:\n",
    "                correct_predictions_trained_count += 1  # Increment for trained couples\n",
    "            else:\n",
    "                correct_predictions_tested_count += 1 # Increment for tested couples\n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{decimal_dataset.iloc[i, 0]} plus {decimal_dataset.iloc[i, 1]} has failed.')\n",
    "\n",
    "    return test_size, correct_predictions_tested_count, train_size, correct_predictions_trained_count\n",
    "\n",
    "def real_test_stages_neural_network(params, stage, visualize_errors=0):\n",
    "    decimal_dataset = generate_real_test_dataset()    \n",
    "    inputs_1, inputs_2, outputs_prev = transform_to_tridimensional_matrix(decimal_dataset)\n",
    "    outputs = prepare_outputs(stage, inputs_1, inputs_2, outputs_prev)\n",
    "    \n",
    "    correct_predictions_test_count = 0\n",
    "    correct_predictions_train_count = 0\n",
    "    correct_carry_over_predictions_count = 0\n",
    "    correct_carry_over_predictions_test_count = 0\n",
    "    correct_carry_over_predictions_train_count = 0\n",
    "    correct_predictions_small_train_count = 0\n",
    "    correct_predictions_small_test_count = 0\n",
    "    correct_predictions_small_train_carry_count = 0\n",
    "    correct_predictions_small_test_carry_count = 0\n",
    "    correct_carry_over_decimal_predictions_count = 0\n",
    "    correct_carry_over_decimal_predictions_test_count = 0\n",
    "    correct_carry_over_decimal_predictions_train_count = 0\n",
    "    correct_predictions_small_train_carry_decimal_count = 0\n",
    "    correct_predictions_small_test_carry_decimal_count = 0\n",
    "    correct_predictions_small_binary_train_count = 0\n",
    "    correct_predictions_small_binary_test_count = 0\n",
    "    correct_predictions_small_binary_train_carry_count = 0\n",
    "    correct_predictions_small_binary_test_carry_count = 0\n",
    "    correct_predictions_small_binary_train_carry_decimal_count = 0\n",
    "    correct_predictions_small_binary_test_carry_decimal_count = 0\n",
    "    \n",
    "    set_size = inputs_1.shape[0]\n",
    "    train_count = len(train_couples)\n",
    "    test_count = set_size - train_count\n",
    "    carry_over_count = len(real_test_dataset_with_carry_over) \n",
    "    carry_over_decimal_count = len(real_test_dataset_with_carry_over_decimal) \n",
    "    train_carry_over_count = len(train_with_carry_over)\n",
    "    test_carry_over_count = carry_over_count - train_carry_over_count\n",
    "    small_count = len(real_test_dataset_small_problem_size)\n",
    "    small_binary_count = len(real_test_dataset_small_problem_size_binary)\n",
    "    train_carry_over_decimal_count = len(train_with_carry_over_decimal)\n",
    "    test_carry_over_decimal_count = carry_over_decimal_count - train_carry_over_decimal_count\n",
    "\n",
    "    # Contadores adicionales\n",
    "    small_train_count = 0\n",
    "    small_test_count = 0\n",
    "    small_train_carry_count = 0\n",
    "    small_test_carry_count = 0\n",
    "    small_train_carry_decimal_count = 0\n",
    "    small_test_carry_decimal_count = 0\n",
    "    small_binary_train_count = 0\n",
    "    small_binary_test_count = 0\n",
    "    small_binary_train_carry_count = 0\n",
    "    small_binary_test_carry_count = 0\n",
    "    small_binary_train_carry_decimal_count = 0\n",
    "    small_binary_test_carry_decimal_count = 0\n",
    "    \n",
    "    reaction_time_carry = 0\n",
    "    reaction_time_carry_decimal = 0\n",
    "    reaction_time_train = 0\n",
    "    reaction_time_test = 0\n",
    "    reaction_time_train_carry = 0\n",
    "    reaction_time_train_carry_decimal = 0\n",
    "    reaction_time_small_train = 0\n",
    "    reaction_time_small_test = 0\n",
    "    reaction_time_small_train_carry = 0\n",
    "    reaction_time_small_test_carry = 0\n",
    "    reaction_time_small_train_carry_decimal = 0\n",
    "    reaction_time_small_test_carry_decimal = 0\n",
    "    reaction_time_small_binary_train = 0\n",
    "    reaction_time_small_binary_test = 0\n",
    "    reaction_time_small_binary_train_carry = 0\n",
    "    reaction_time_small_binary_test_carry = 0\n",
    "    reaction_time_small_binary_train_carry_decimal = 0\n",
    "    reaction_time_small_binary_test_carry_decimal = 0\n",
    "\n",
    "    for i in range(set_size):\n",
    "        pair = (decimal_dataset.iloc[i, 0], decimal_dataset.iloc[i, 1])\n",
    "\n",
    "        start_time = time.perf_counter_ns()\n",
    "        prediction, binary_pred = predict(params, inputs_1[i], inputs_2[i], stage)\n",
    "        elapsed_time = time.perf_counter_ns() - start_time\n",
    "        \n",
    "        #is_small = pair in combinations_small_problem_size\n",
    "        #is_small_binary = pair in combinations_small_problem_size_binary\n",
    "        #is_train = pair in train_couples\n",
    "        #is_carry = pair in combinations_with_carry_over\n",
    "        #is_carry_decimal = pair in combinations_with_carry_over_decimal\n",
    "\n",
    "        is_small = pair in real_test_dataset_small_problem_size\n",
    "        is_small_binary = pair in real_test_dataset_small_problem_size_binary\n",
    "        is_train = pair in train_couples\n",
    "        is_carry = pair in real_test_dataset_with_carry_over\n",
    "        is_carry_decimal = pair in real_test_dataset_with_carry_over_decimal\n",
    "\n",
    "        # Actualizar tiempos de reacción y contadores totales\n",
    "        if is_small:\n",
    "            if is_train:\n",
    "                small_train_count += 1\n",
    "                reaction_time_small_train += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_train_carry_count += 1\n",
    "                    reaction_time_small_train_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_train_carry_decimal_count += 1\n",
    "                    reaction_time_small_train_carry_decimal += elapsed_time\n",
    "            else:\n",
    "                small_test_count += 1\n",
    "                reaction_time_small_test += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_test_carry_count += 1\n",
    "                    reaction_time_small_test_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_test_carry_decimal_count += 1\n",
    "                    reaction_time_small_test_carry_decimal += elapsed_time\n",
    "\n",
    "        # Actualizar tiempos de reacción y contadores totales\n",
    "        if is_small_binary:\n",
    "            if is_train:\n",
    "                small_binary_train_count += 1\n",
    "                reaction_time_small_binary_train += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_binary_train_carry_count += 1\n",
    "                    reaction_time_small_binary_train_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_binary_train_carry_decimal_count += 1\n",
    "                    reaction_time_small_binary_train_carry_decimal += elapsed_time\n",
    "            else:\n",
    "                small_binary_test_count += 1\n",
    "                reaction_time_small_binary_test += elapsed_time\n",
    "                if is_carry:\n",
    "                    small_binary_test_carry_count += 1\n",
    "                    reaction_time_small_binary_test_carry += elapsed_time\n",
    "                if is_carry_decimal:\n",
    "                    small_binary_test_carry_decimal_count += 1\n",
    "                    reaction_time_small_binary_test_carry_decimal += elapsed_time\n",
    "\n",
    "        if is_carry:\n",
    "            reaction_time_carry += elapsed_time\n",
    "        if is_carry_decimal:\n",
    "            reaction_time_carry_decimal += elapsed_time\n",
    "        if is_train:\n",
    "            reaction_time_train += elapsed_time\n",
    "        else:\n",
    "            reaction_time_test += elapsed_time\n",
    "        if is_train and is_carry:\n",
    "            reaction_time_train_carry += elapsed_time\n",
    "        if is_train and is_carry_decimal:\n",
    "            reaction_time_train_carry_decimal += elapsed_time\n",
    "\n",
    "        # Contar predicciones correctas\n",
    "        if jnp.all(prediction == outputs[i]):\n",
    "            if is_small:\n",
    "                if is_train:\n",
    "                    correct_predictions_small_train_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_train_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_train_carry_decimal_count += 1\n",
    "                else:\n",
    "                    correct_predictions_small_test_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_test_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_test_carry_decimal_count += 1\n",
    "\n",
    "            if is_small_binary:\n",
    "                if is_train:\n",
    "                    correct_predictions_small_binary_train_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_binary_train_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_binary_train_carry_decimal_count += 1\n",
    "                else:\n",
    "                    correct_predictions_small_binary_test_count += 1\n",
    "                    if is_carry:\n",
    "                        correct_predictions_small_binary_test_carry_count += 1\n",
    "                    if is_carry_decimal:\n",
    "                        correct_predictions_small_binary_test_carry_decimal_count += 1\n",
    "\n",
    "            # Actualizar contadores previos\n",
    "            if is_carry:\n",
    "                correct_carry_over_predictions_count += 1 \n",
    "            if is_carry_decimal:\n",
    "                correct_carry_over_decimal_predictions_count += 1 \n",
    "            if is_train:\n",
    "                correct_predictions_train_count += 1 \n",
    "            else:\n",
    "                correct_predictions_test_count += 1\n",
    "            if is_train and is_carry:\n",
    "                correct_carry_over_predictions_train_count += 1   \n",
    "            if is_train and is_carry_decimal:\n",
    "                correct_carry_over_decimal_predictions_train_count += 1 \n",
    "                \n",
    "        elif visualize_errors == 1:\n",
    "            print(f'{pair[0]} plus {pair[1]} has failed.')\n",
    "\n",
    "    correct_carry_over_predictions_test_count = correct_carry_over_predictions_count - correct_carry_over_predictions_train_count\n",
    "    correct_carry_over_decimal_predictions_test_count = correct_carry_over_decimal_predictions_count - correct_carry_over_decimal_predictions_train_count\n",
    "    \n",
    "    return (\n",
    "        test_count,\n",
    "        correct_predictions_test_count,\n",
    "        train_count,\n",
    "        correct_predictions_train_count,\n",
    "        test_carry_over_count,\n",
    "        correct_carry_over_predictions_test_count,\n",
    "        train_carry_over_count,\n",
    "        correct_carry_over_predictions_train_count,\n",
    "        small_train_count,\n",
    "        correct_predictions_small_train_count,\n",
    "        small_test_count,\n",
    "        correct_predictions_small_test_count,\n",
    "        small_train_carry_count,\n",
    "        correct_predictions_small_train_carry_count,\n",
    "        small_test_carry_count,\n",
    "        correct_predictions_small_test_carry_count,\n",
    "        test_carry_over_decimal_count,\n",
    "        correct_carry_over_decimal_predictions_test_count,\n",
    "        train_carry_over_decimal_count,\n",
    "        correct_carry_over_decimal_predictions_train_count,\n",
    "        small_train_carry_decimal_count,\n",
    "        correct_predictions_small_train_carry_decimal_count,\n",
    "        small_test_carry_decimal_count,\n",
    "        correct_predictions_small_test_carry_decimal_count,\n",
    "        small_binary_train_count,\n",
    "        correct_predictions_small_binary_train_count,\n",
    "        small_binary_test_count,\n",
    "        correct_predictions_small_binary_test_count,\n",
    "        small_binary_train_carry_count,\n",
    "        correct_predictions_small_binary_train_carry_count,\n",
    "        small_binary_test_carry_count,\n",
    "        correct_predictions_small_binary_test_carry_count,\n",
    "        small_binary_train_carry_decimal_count,\n",
    "        correct_predictions_small_binary_train_carry_decimal_count,\n",
    "        small_binary_test_carry_decimal_count,\n",
    "        correct_predictions_small_binary_test_carry_decimal_count,\n",
    "        reaction_time_carry,\n",
    "        reaction_time_carry_decimal,\n",
    "        reaction_time_train,\n",
    "        reaction_time_test,\n",
    "        reaction_time_train_carry,\n",
    "        reaction_time_train_carry_decimal,\n",
    "        reaction_time_small_train,\n",
    "        reaction_time_small_test,\n",
    "        reaction_time_small_train_carry,\n",
    "        reaction_time_small_test_carry,\n",
    "        reaction_time_small_train_carry_decimal,\n",
    "        reaction_time_small_test_carry_decimal,\n",
    "        reaction_time_small_binary_train,\n",
    "        reaction_time_small_binary_test,\n",
    "        reaction_time_small_binary_train_carry,\n",
    "        reaction_time_small_binary_test_carry,\n",
    "        reaction_time_small_binary_train_carry_decimal,\n",
    "        reaction_time_small_binary_test_carry_decimal\n",
    "    )\n",
    "\n",
    "# Predict using the trained neural network\n",
    "def predict(params, x1, x2, stage):\n",
    "    if stage == 1:\n",
    "        binary_pred = neural_network_1(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 2:\n",
    "        binary_pred = neural_network_2(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    elif stage == 3:\n",
    "        binary_pred = neural_network_3(params, x1, x2)\n",
    "        rounded_pred = np.round(binary_pred)\n",
    "        return rounded_pred, binary_pred\n",
    "        \n",
    "    else:\n",
    "        print('Bad index for the training stage.')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d362f6dc-4abc-46e2-93be-45c196d34004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, file, mode='w'):\n",
    "        self.file = open(file, mode)\n",
    "        self.console = sys.stdout  \n",
    "\n",
    "    def write(self, data):\n",
    "        self.console.write(data)   \n",
    "        self.file.write(data)    \n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        self.file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "        \n",
    "def load_trainable_model(model, current_time, training_type, stage = 0):\n",
    "    folder = 'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition'\n",
    "    if stage == 0:\n",
    "        model_path = f'{folder}/Parameters/{training_type}/{model}_{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'trainable_model'] = pickle.load(f)\n",
    "        print(f'Model trainable_model_{current_time} loaded successfully.')\n",
    "        return globals()[f'trainable_model']\n",
    "        \n",
    "    else:\n",
    "        model_path = f'{folder}/Trained_models/Stages/{training_type}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            globals()[f'{model}_{stage}'] = pickle.load(f)\n",
    "        print(f'Model {model}_{stage}_{current_time} loaded successfully.')\n",
    "        return globals()[f'{model}_{stage}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a718a27d-647a-4517-98bb-684dc1364b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trainable_model_stage_1-2024_11_19_13_22_02.pkl\n",
      "STAGE 1: Out of 8000, 8000 trained were predicted correctly in the current model.\n",
      "STAGE 1: Out of 8384, 8379 tested were predicted correctly in the current model.\n",
      "STAGE 1: Out of 6524, 6524 trained with carry-over were predicted correctly in the current model.\n",
      "STAGE 1: Out of 7673, 7668 tested with carry-over were predicted correctly in the current model.\n",
      "STAGE 1: Out of 1614, 1614 trained with small problem size were predicted correctly in the current model.\n",
      "STAGE 1: Out of 946, 946 tested with small problem size were predicted correctly in the current model.\n",
      "STAGE 1: Out of 963, 963 trained with small problem size and with carry-over were predicted correctly in the current model.\n",
      "STAGE 1: Out of 568, 568 tested with small problem size and with carry-over were predicted correctly in the current model.\n",
      "STAGE 1: Out of 5576, 5576 trained with carry-over decimal were predicted correctly in the current model.\n",
      "STAGE 1: Out of 4384, 4383 tested with carry-over decimal were predicted correctly in the current model.\n",
      "STAGE 1: Out of 724, 724 trained with small problem size and with carry-over decimal were predicted correctly in the current model.\n",
      "STAGE 1: Out of 412, 412 tested with small problem size and with carry-over decimal were predicted correctly in the current model.\n",
      "STAGE 1: Out of 6986, 6986 trained with small binary problem size were predicted correctly in the current model.\n",
      "STAGE 1: Out of 5302, 5301 tested with small binary problem size were predicted correctly in the current model.\n",
      "STAGE 1: Out of 5510, 5510 trained with small binary problem size and with carry-over were predicted correctly in the current model.\n",
      "STAGE 1: Out of 4591, 4590 tested with small binary problem size and with carry-over were predicted correctly in the current model.\n",
      "STAGE 1: Out of 4562, 4562 trained with small binary problem size and with carry-over decimal were predicted correctly in the current model.\n",
      "STAGE 1: Out of 2559, 2559 tested with small binary problem size and with carry-over decimal were predicted correctly in the current model.\n",
      "STAGE 1: 14181452700 reaction time with carry over.\n",
      "STAGE 1: 9948234000 reaction time with carry over decimal.\n",
      "STAGE 1: 7997965700 reaction time for train.\n",
      "STAGE 1: 8387181000 reaction time for test.\n",
      "STAGE 1: 6508373500 reaction time for train with carry over .\n",
      "STAGE 1: 5565704400 reaction time for train with carry over decimal.\n",
      "STAGE 1: 1619163500 reaction time for train small.\n",
      "STAGE 1: 946104300 reaction time for test small.\n",
      "STAGE 1: 956645300 reaction time for train with carry over and small.\n",
      "STAGE 1: 563555500 reaction time for test with carry over and small.\n",
      "STAGE 1: 718314200 reaction time for train with carry over decimal and small.\n",
      "STAGE 1: 408977500 reaction time for test with carry over decimal and small.\n",
      "STAGE 1: 6985918800 reaction time for train small binary.\n",
      "STAGE 1: 5311434300 reaction time for test small binary.\n",
      "STAGE 1: 5496326600 reaction time for train with carry over and small binary.\n",
      "STAGE 1: 4597332500 reaction time for test with carry over and small binary.\n",
      "STAGE 1: 4553657500 reaction time for train with carry over decimal and small binary.\n",
      "STAGE 1: 2561472500 reaction time for test with carry over decimal and small binary.\n",
      "Loaded trainable_model_stage_2-2024_11_19_13_22_02.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m             real_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 64\u001b[0m             \u001b[43mdecide_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreal_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;241m=\u001b[39m tee\u001b[38;5;241m.\u001b[39mconsole\n",
      "Cell \u001b[1;32mIn[10], line 379\u001b[0m, in \u001b[0;36mdecide_test\u001b[1;34m(params, stage, real_test, visualize_errors)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecide_test\u001b[39m(params, stage, real_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, visualize_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m real_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 379\u001b[0m         test_count, correct_predictions_test_count, train_count, correct_predictions_train_count, test_carry_over_count, correct_carry_over_predictions_test_count, train_carry_over_count, correct_carry_over_predictions_train_count, small_train_count, correct_predictions_small_train_count, small_test_count, correct_predictions_small_test_count, small_train_carry_count, correct_predictions_small_train_carry_count, small_test_carry_count, correct_predictions_small_test_carry_count, test_carry_over_decimal_count, correct_carry_over_decimal_predictions_test_count, train_carry_over_decimal_count, correct_carry_over_decimal_predictions_train_count, small_train_carry_decimal_count, correct_predictions_small_train_carry_decimal_count, small_test_carry_decimal_count, correct_predictions_small_test_carry_decimal_count, small_binary_train_count, correct_predictions_small_binary_train_count, small_binary_test_count, correct_predictions_small_binary_test_count, small_binary_train_carry_count, correct_predictions_small_binary_train_carry_count, small_binary_test_carry_count, correct_predictions_small_binary_test_carry_count, small_binary_train_carry_decimal_count, correct_predictions_small_binary_train_carry_decimal_count, small_binary_test_carry_decimal_count, correct_predictions_small_binary_test_carry_decimal_count, reaction_time_carry, reaction_time_carry_decimal, reaction_time_train,reaction_time_test, reaction_time_train_carry, reaction_time_train_carry_decimal, reaction_time_small_train, reaction_time_small_test, reaction_time_small_train_carry, reaction_time_small_test_carry, reaction_time_small_train_carry_decimal, reaction_time_small_test_carry_decimal, reaction_time_small_binary_train, reaction_time_small_binary_test, reaction_time_small_binary_train_carry, reaction_time_small_binary_test_carry, reaction_time_small_binary_train_carry_decimal, reaction_time_small_binary_test_carry_decimal \u001b[38;5;241m=\u001b[39m \u001b[43mreal_test_stages_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTAGE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_predictions_train_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trained were predicted correctly in the current model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTAGE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_predictions_test_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tested were predicted correctly in the current model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 523\u001b[0m, in \u001b[0;36mreal_test_stages_neural_network\u001b[1;34m(params, stage, visualize_errors)\u001b[0m\n\u001b[0;32m    520\u001b[0m pair \u001b[38;5;241m=\u001b[39m (decimal_dataset\u001b[38;5;241m.\u001b[39miloc[i, \u001b[38;5;241m0\u001b[39m], decimal_dataset\u001b[38;5;241m.\u001b[39miloc[i, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    522\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\n\u001b[1;32m--> 523\u001b[0m prediction, binary_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m#is_small = pair in combinations_small_problem_size\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m#is_small_binary = pair in combinations_small_problem_size_binary\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m#is_train = pair in train_couples\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m#is_carry = pair in combinations_with_carry_over\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m#is_carry_decimal = pair in combinations_with_carry_over_decimal\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 708\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(params, x1, x2, stage)\u001b[0m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rounded_pred, binary_pred\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 708\u001b[0m     binary_pred \u001b[38;5;241m=\u001b[39m \u001b[43mneural_network_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     rounded_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(binary_pred)\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rounded_pred, binary_pred\n",
      "Cell \u001b[1;32mIn[10], line 287\u001b[0m, in \u001b[0;36mneural_network_2\u001b[1;34m(params, x1, x2)\u001b[0m\n\u001b[0;32m    285\u001b[0m z2 \u001b[38;5;241m=\u001b[39m lower_even(jnp\u001b[38;5;241m.\u001b[39mdot(x, R2_perfect)) \u001b[38;5;66;03m# z2 is a scalar with the first carry over\u001b[39;00m\n\u001b[0;32m    286\u001b[0m z3 \u001b[38;5;241m=\u001b[39m lower_even(jnp\u001b[38;5;241m.\u001b[39mdot(x, R3_perfect) \u001b[38;5;241m+\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(z2, v2_perfect)) \u001b[38;5;66;03m# z3 is a scalar with the second carry over\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m z4 \u001b[38;5;241m=\u001b[39m lower_even(\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR4_perfect\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(z3, v3_perfect)) \u001b[38;5;66;03m# z4 is a scalar with the third carry over\u001b[39;00m\n\u001b[0;32m    288\u001b[0m z5 \u001b[38;5;241m=\u001b[39m lower_even(jnp\u001b[38;5;241m.\u001b[39mdot(x, R5_perfect) \u001b[38;5;241m+\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(z4, v4_perfect)) \u001b[38;5;66;03m# z5 is a scalar with the fourth carry over\u001b[39;00m\n\u001b[0;32m    289\u001b[0m z6 \u001b[38;5;241m=\u001b[39m lower_even(jnp\u001b[38;5;241m.\u001b[39mdot(x, R6_perfect) \u001b[38;5;241m+\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(z5, v5_perfect)) \u001b[38;5;66;03m# z6 is a scalar with the fifth carry over\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_performance = 'no'\n",
    "easy_examples = 'no'\n",
    "type_training = 'Stages'\n",
    "file_name = 'Generated_model'\n",
    "\n",
    "if easy_examples == 'yes':\n",
    "    if validation_performance == 'yes':\n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/Validation_performance/tests-Easy_examples_{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/Easy_examples/{type_training}/{file_name}/Stage_3'\n",
    "    else:\n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/tests-Easy_examples_{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Easy_examples/{type_training}/{file_name}/Stage_3'\n",
    "    \n",
    "else:\n",
    "    if validation_performance == 'yes':    \n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/Validation_performance/tests-{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/{type_training}/{file_name}/Stage_3'\n",
    "    else:\n",
    "        output_file = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Tests/PRUEBA-tests-{type_training}-{file_name}.txt'\n",
    "        folder_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/{type_training}/{file_name}/Stage_3'\n",
    "\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "tee = Tee(output_file, 'w') \n",
    "sys.stdout = tee\n",
    "\n",
    "try:\n",
    "    visualize_errors = 0\n",
    "    model = 'trainable_model_stage'\n",
    "    \n",
    "    date_pattern = r'trainable_model_stage_3-(\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}).pkl'\n",
    "    files = sorted(\n",
    "        (f for f in os.listdir(folder_path) if f.endswith('.pkl') and not f.startswith('.')),  # Filtrar archivos .pkl y ocultos\n",
    "        key=lambda x: re.search(date_pattern, x).group(0) if re.search(date_pattern, x) else ''\n",
    "    )\n",
    "    \n",
    "    for filename in files:\n",
    "        match = re.search(date_pattern, filename)\n",
    "        if match:\n",
    "            current_time = match.group(1)\n",
    "        else:\n",
    "            print('Error')\n",
    "            break\n",
    "    \n",
    "        for stage in range(1, 4):\n",
    "            if easy_examples == 'yes':\n",
    "                if validation_performance == 'yes':    \n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/Easy_examples/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "                else:\n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Easy_examples/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "                    \n",
    "            else:\n",
    "                if validation_performance == 'yes':   \n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/Validation_performance/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "                else:\n",
    "                    file_path = f'D:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado/Curriculum_Learning/Multidigit_Addition/Trained_models/{type_training}/{file_name}/Stage_{stage}/{model}_{stage}-{current_time}.pkl'\n",
    "\n",
    "            with open(file_path, 'rb') as file:\n",
    "                globals()[f\"{model}_{stage}\"] = pickle.load(file)\n",
    "    \n",
    "            print(f'Loaded {model}_{stage}-{current_time}.pkl')\n",
    "\n",
    "            real_test = 1\n",
    "            decide_test(params=globals()[f\"{model}_{stage}\"], stage=stage, real_test=real_test, visualize_errors=visualize_errors)\n",
    "                \n",
    "finally:\n",
    "    sys.stdout = tee.console\n",
    "    tee.close()\n",
    "    \n",
    "print(f'Finished, file {file_name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daf55b-da26-4126-8c75-09dcd2915511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
